{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ∞Ô∏è GeoVeil CN0 Analysis Widget\n",
    "\n",
    "**Interactive GNSS C/N‚ÇÄ Analysis powered by the Rust `geoveil-cn0` library**\n",
    "\n",
    "- **90% Rust** - All parsing, analysis, anomaly detection in compiled Rust\n",
    "- **10% Python** - Only UI widgets and Plotly visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build Rust Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LINUX/MAC BUILD ===\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import glob\n",
    "\n",
    "print(\"üêß Linux/Mac Build for geoveil_cn0\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    print(\"‚ö†Ô∏è This cell is for Linux/Mac. Use the Windows build cell instead.\")\n",
    "else:\n",
    "    NOTEBOOK_DIR = os.getcwd()\n",
    "    \n",
    "    # Setup PATH for cargo/maturin\n",
    "    cargo_bin = os.path.expanduser(\"~/.cargo/bin\")\n",
    "    local_bin = os.path.expanduser(\"~/.local/bin\")\n",
    "    os.environ[\"PATH\"] = f\"{cargo_bin}:{local_bin}:\" + os.environ.get(\"PATH\", \"\")\n",
    "    \n",
    "    # Find or extract library\n",
    "    LIB_PATH = None\n",
    "    for candidate in [\n",
    "        os.path.join(NOTEBOOK_DIR, 'geoveil-cn0'),\n",
    "        os.path.join(NOTEBOOK_DIR, 'geoveil_cn0'),\n",
    "    ]:\n",
    "        if os.path.exists(os.path.join(candidate, 'Cargo.toml')):\n",
    "            LIB_PATH = candidate\n",
    "            break\n",
    "    \n",
    "    if not LIB_PATH:\n",
    "        tar_file = os.path.join(NOTEBOOK_DIR, 'geoveil-cn0.tar.gz')\n",
    "        if os.path.exists(tar_file):\n",
    "            print(\"üì¶ Extracting geoveil-cn0.tar.gz...\")\n",
    "            import tarfile\n",
    "            with tarfile.open(tar_file, 'r:gz') as tar:\n",
    "                tar.extractall(NOTEBOOK_DIR)\n",
    "            LIB_PATH = os.path.join(NOTEBOOK_DIR, 'geoveil-cn0')\n",
    "    \n",
    "    if not LIB_PATH:\n",
    "        raise FileNotFoundError(\"geoveil-cn0 directory not found\")\n",
    "    \n",
    "    print(f\"üìÅ Library: {LIB_PATH}\")\n",
    "    print(f\"üêç Python: {sys.version.split()[0]}\")\n",
    "    \n",
    "    # Check Rust\n",
    "    print(\"\\nüîß Checking Rust...\")\n",
    "    result = subprocess.run(['rustc', '--version'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"‚úÖ {result.stdout.strip()}\")\n",
    "    else:\n",
    "        print(\"‚ùå Rust not found. Install: curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\")\n",
    "        raise RuntimeError(\"Rust not installed\")\n",
    "    \n",
    "    # Check maturin\n",
    "    print(\"\\nüì¶ Checking maturin...\")\n",
    "    result = subprocess.run([sys.executable, '-m', 'maturin', '--version'], capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"   Installing maturin...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'maturin>=1.4'])\n",
    "    result = subprocess.run([sys.executable, '-m', 'maturin', '--version'], capture_output=True, text=True)\n",
    "    print(f\"‚úÖ {result.stdout.strip()}\")\n",
    "    \n",
    "    # Build\n",
    "    print(\"\\nüî® Building (this may take 2-5 minutes)...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    wheel_dir = os.path.join(LIB_PATH, 'target', 'wheels')\n",
    "    \n",
    "    # Set environment for Python 3.13+ compatibility\n",
    "    env = os.environ.copy()\n",
    "    env['PYO3_USE_ABI3_FORWARD_COMPATIBILITY'] = '1'\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        [sys.executable, '-m', 'maturin', 'build', '--release'],\n",
    "        cwd=LIB_PATH,\n",
    "        env=env,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    print(result.stdout[-2000:] if result.stdout else \"\")\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(f\"‚ùå Build failed:\\n{result.stderr[-1500:]}\")\n",
    "        raise RuntimeError(\"Build failed\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Find and install wheel\n",
    "    wheels = glob.glob(os.path.join(wheel_dir, 'geoveil_cn0*.whl'))\n",
    "    \n",
    "    if wheels:\n",
    "        wheel = max(wheels, key=os.path.getctime)\n",
    "        print(f\"\\nüì• Installing {os.path.basename(wheel)}...\")\n",
    "        \n",
    "        result = subprocess.run([\n",
    "            sys.executable, '-m', 'pip', 'install',\n",
    "            '--force-reinstall', '--no-deps', '-q', wheel\n",
    "        ], capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ Installed!\")\n",
    "        else:\n",
    "            print(f\"‚ùå Install failed: {result.stderr}\")\n",
    "            raise RuntimeError(\"Install failed\")\n",
    "    else:\n",
    "        print(\"‚ùå No wheel found\")\n",
    "        raise RuntimeError(\"Build failed - no wheel produced\")\n",
    "    \n",
    "    # Test import\n",
    "    print(\"\\nüß™ Testing import...\")\n",
    "    if 'geoveil_cn0' in sys.modules:\n",
    "        del sys.modules['geoveil_cn0']\n",
    "    \n",
    "    import geoveil_cn0 as gcn0\n",
    "    print(f\"‚úÖ geoveil_cn0 v{gcn0.VERSION} loaded!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Build Rust Library on WIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === WINDOWS BUILD with Python 3.13 Compatibility ===\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import glob\n",
    "\n",
    "print(\"ü™ü Windows Build for geoveil_cn0 (Python 3.13 compat)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if platform.system() != 'Windows':\n",
    "    print(\"‚ö†Ô∏è This cell is for Windows only\")\n",
    "else:\n",
    "    NOTEBOOK_DIR = os.getcwd()\n",
    "    \n",
    "    # Find library\n",
    "    LIB_PATH = None\n",
    "    for candidate in [\n",
    "        os.path.join(NOTEBOOK_DIR, 'geoveil-cn0'),\n",
    "        os.path.join(NOTEBOOK_DIR, 'geoveil_cn0'),\n",
    "    ]:\n",
    "        if os.path.exists(os.path.join(candidate, 'Cargo.toml')):\n",
    "            LIB_PATH = candidate\n",
    "            break\n",
    "    \n",
    "    if not LIB_PATH:\n",
    "        tar_file = os.path.join(NOTEBOOK_DIR, 'geoveil-cn0.tar.gz')\n",
    "        if os.path.exists(tar_file):\n",
    "            import tarfile\n",
    "            with tarfile.open(tar_file, 'r:gz') as tar:\n",
    "                tar.extractall(NOTEBOOK_DIR)\n",
    "            LIB_PATH = os.path.join(NOTEBOOK_DIR, 'geoveil-cn0')\n",
    "    \n",
    "    if not LIB_PATH:\n",
    "        raise FileNotFoundError(\"geoveil-cn0 directory not found\")\n",
    "    \n",
    "    print(f\"üìÅ Library: {LIB_PATH}\")\n",
    "    print(f\"üêç Python: {sys.version}\")\n",
    "    \n",
    "    # Find vcvars64.bat\n",
    "    VS_PATHS = [\n",
    "        r\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\Build\\vcvars64.bat\",\n",
    "        r\"C:\\Program Files\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\Build\\vcvars64.bat\",\n",
    "        r\"C:\\Program Files\\Microsoft Visual Studio\\2022\\Professional\\VC\\Auxiliary\\Build\\vcvars64.bat\",\n",
    "    ]\n",
    "    \n",
    "    VCVARS = None\n",
    "    for path in VS_PATHS:\n",
    "        if os.path.exists(path):\n",
    "            VCVARS = path\n",
    "            break\n",
    "    \n",
    "    if not VCVARS:\n",
    "        raise FileNotFoundError(\"VS Build Tools not found\")\n",
    "    \n",
    "    print(f\"üîß VS Tools: Found\")\n",
    "    \n",
    "    # Create build script with PYO3_USE_ABI3_FORWARD_COMPATIBILITY\n",
    "    build_script = os.path.join(NOTEBOOK_DIR, '_build_geoveil.bat')\n",
    "    wheel_dir = os.path.join(LIB_PATH, 'target', 'wheels')\n",
    "    \n",
    "    script_content = f'''@echo off\n",
    "call \"{VCVARS}\" >nul 2>&1\n",
    "cd /d \"{LIB_PATH}\"\n",
    "set PYO3_USE_ABI3_FORWARD_COMPATIBILITY=1\n",
    "\"{sys.executable}\" -m maturin build --release\n",
    "'''\n",
    "    \n",
    "    with open(build_script, 'w') as f:\n",
    "        f.write(script_content)\n",
    "    \n",
    "    print(f\"\\nüî® Building with ABI3 forward compatibility...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    result = subprocess.run(['cmd', '/c', build_script], cwd=LIB_PATH)\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    try:\n",
    "        os.remove(build_script)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Find and install wheel\n",
    "    wheels = glob.glob(os.path.join(wheel_dir, 'geoveil_cn0*.whl'))\n",
    "    \n",
    "    if wheels:\n",
    "        wheel = max(wheels, key=os.path.getctime)\n",
    "        print(f\"\\nüì• Installing {os.path.basename(wheel)}...\")\n",
    "        \n",
    "        result = subprocess.run([\n",
    "            sys.executable, '-m', 'pip', 'install', \n",
    "            '--force-reinstall', '--no-deps', wheel\n",
    "        ], capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"‚úÖ Installed!\")\n",
    "        else:\n",
    "            print(f\"‚ùå Install failed: {result.stderr}\")\n",
    "            raise RuntimeError(\"Install failed\")\n",
    "    else:\n",
    "        print(\"‚ùå No wheel found\")\n",
    "        raise RuntimeError(\"Build failed\")\n",
    "    \n",
    "    # Test import\n",
    "    print(\"\\nüß™ Testing import...\")\n",
    "    if 'geoveil_cn0' in sys.modules:\n",
    "        del sys.modules['geoveil_cn0']\n",
    "    \n",
    "    import geoveil_cn0 as gcn0\n",
    "    print(f\"‚úÖ geoveil_cn0 v{gcn0.VERSION} loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install library from Pypi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install geoveil-cn0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoveil_cn0 as gcn0\n",
    "print(f'‚úÖ geoveil_cn0 v{gcn0.VERSION}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly pandas numpy ipywidgets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, tempfile, base64\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import numpy as np, pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import geoveil_cn0 as gcn0\n",
    "print('‚úÖ Imports ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualization Functions\n",
    "\n",
    "All data comes from Rust: `result.get_skyplot_data()`, `result.get_timeseries_data()`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = {'GPS':'#3b82f6','Galileo':'#22c55e','GLONASS':'#ef4444','BeiDou':'#f59e0b','QZSS':'#8b5cf6','IRNSS':'#06b6d4'}\n",
    "RATING = {'excellent':'#22c55e','good':'#84cc16','fair':'#eab308','poor':'#f97316','critical':'#ef4444'}\n",
    "SEVERITY = {'Critical':'#ef4444','High':'#f97316','Medium':'#eab308','Low':'#22c55e'}\n",
    "def get_const(sv): return {'G':'GPS','E':'Galileo','R':'GLONASS','C':'BeiDou','J':'QZSS','I':'IRNSS'}.get(sv[0] if sv else '','Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_skyplot(r):\n",
    "    data = r.get_skyplot_data()\n",
    "    traces = data.get('traces', [])\n",
    "    if not traces: return go.Figure().add_annotation(text='No position data',xref='paper',yref='paper',x=0.5,y=0.5,showarrow=False)\n",
    "    fig = go.Figure()\n",
    "    for i,tr in enumerate(traces):\n",
    "        fig.add_trace(go.Scatterpolar(r=tr['r'],theta=tr['theta'],mode='markers',name=tr['constellation'],\n",
    "            marker=dict(size=9,color=tr['cn0'],colorscale='Viridis',cmin=25,cmax=55,colorbar=dict(title='CN0') if i==0 else None,showscale=(i==0)),\n",
    "            text=tr.get('text',[]),hoverinfo='text'))\n",
    "    cov = data.get('coverage',{}).get('coverage_percent',0)\n",
    "    fig.update_layout(title=f'CN0 Skyplot ({cov:.1f}%)',width=620,height=620,\n",
    "        polar=dict(radialaxis=dict(range=[0,90],tickvals=[0,30,60,90],ticktext=['90¬∞','60¬∞','30¬∞','0¬∞']),\n",
    "                  angularaxis=dict(tickvals=[0,45,90,135,180,225,270,315],ticktext=['N','NE','E','SE','S','SW','W','NW'],direction='clockwise',rotation=90)))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timeseries(r):\n",
    "    d = r.get_timeseries_data()\n",
    "    ts = pd.to_datetime(d.get('timestamps',[]))\n",
    "    if len(ts)==0: return go.Figure().add_annotation(text='No data',xref='paper',yref='paper',x=0.5,y=0.5,showarrow=False)\n",
    "    fig = make_subplots(rows=2,cols=1,shared_xaxes=True,vertical_spacing=0.08,row_heights=[0.7,0.3])\n",
    "    fig.add_trace(go.Scatter(x=ts,y=d.get('cn0_mean',[]),name='Overall',line=dict(color='black',width=2.5)),row=1,col=1)\n",
    "    for c,cd in d.get('by_constellation',{}).items():\n",
    "        fig.add_trace(go.Scatter(x=pd.to_datetime(cd['timestamps']),y=cd['cn0'],name=c,line=dict(color=COLORS.get(c,'#888'))),row=1,col=1)\n",
    "    fig.add_trace(go.Bar(x=ts,y=d.get('satellite_counts',[]),marker_color='#6b7280',showlegend=False),row=2,col=1)\n",
    "    fig.add_hline(y=35,line_dash='dash',line_color='orange',row=1,col=1)\n",
    "    fig.update_layout(height=500,title='CN0 Timeseries',legend=dict(orientation='h',y=1.1))\n",
    "    fig.update_yaxes(title_text='CN0 (dB-Hz)',row=1,col=1)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(r):\n",
    "    hm = r.get_skyplot_data().get('heatmap',{})\n",
    "    if not hm.get('cn0_grid'): return go.Figure().add_annotation(text='No heatmap',xref='paper',yref='paper',x=0.5,y=0.5,showarrow=False)\n",
    "    fig = go.Figure(go.Heatmap(z=hm['cn0_grid'],x=hm['azimuth_bins'],y=hm['elevation_bins'],colorscale='Viridis',colorbar=dict(title='CN0')))\n",
    "    fig.update_layout(title='CN0 Heatmap',xaxis_title='Azimuth (¬∞)',yaxis_title='Elevation (¬∞)',width=700,height=450)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_elevation_plot(r):\n",
    "    traces = r.get_skyplot_data().get('traces',[])\n",
    "    if not traces: return go.Figure().add_annotation(text='No data',xref='paper',yref='paper',x=0.5,y=0.5,showarrow=False)\n",
    "    fig = go.Figure()\n",
    "    for tr in traces:\n",
    "        elevs = [90-x for x in tr.get('r',[])]\n",
    "        fig.add_trace(go.Scatter(x=elevs,y=tr.get('cn0',[]),mode='markers',name=tr['constellation'],marker=dict(color=COLORS.get(tr['constellation'],'#888'),size=5,opacity=0.5)))\n",
    "    elev = np.linspace(5,90,50)\n",
    "    fig.add_trace(go.Scatter(x=elev,y=35+15*(elev/90),mode='lines',name='Expected',line=dict(color='black',dash='dash')))\n",
    "    fig.add_hline(y=35,line_dash='dot',line_color='orange')\n",
    "    fig.update_layout(title='CN0 vs Elevation',xaxis_title='Elevation (¬∞)',yaxis_title='CN0 (dB-Hz)',width=700,height=450)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_satellite_bars(r):\n",
    "    stats = r.get_satellite_stats()\n",
    "    if not stats: return go.Figure().add_annotation(text='No data',xref='paper',yref='paper',x=0.5,y=0.5,showarrow=False)\n",
    "    by_c = defaultdict(list)\n",
    "    for sv,s in stats.items(): by_c[get_const(sv)].append((sv,s['mean'],s['std_dev']))\n",
    "    fig = go.Figure()\n",
    "    for c in sorted(by_c):\n",
    "        d = sorted(by_c[c])\n",
    "        fig.add_trace(go.Bar(x=[x[0] for x in d],y=[x[1] for x in d],name=c,marker_color=COLORS.get(c,'#888'),error_y=dict(type='data',array=[x[2] for x in d],visible=True)))\n",
    "    fig.add_hline(y=40,line_dash='dash',line_color='green')\n",
    "    fig.update_layout(title='CN0 by Satellite',barmode='group',height=400,legend=dict(orientation='h',y=1.1))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_constellation_pie(r):\n",
    "    stats = r.get_satellite_stats()\n",
    "    if not stats: return go.Figure()\n",
    "    by_c = defaultdict(int)\n",
    "    for sv,s in stats.items(): by_c[get_const(sv)] += s['count']\n",
    "    fig = go.Figure(go.Pie(labels=list(by_c.keys()),values=list(by_c.values()),marker_colors=[COLORS.get(c,'#888') for c in by_c],hole=0.4,textinfo='label+percent'))\n",
    "    fig.update_layout(title=f'Observations ({sum(by_c.values()):,})',height=380)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quality_gauge(r):\n",
    "    fig = go.Figure(go.Indicator(mode='gauge+number',value=r.score,title={'text':f'Quality: {r.rating.upper()}'},\n",
    "        gauge={'axis':{'range':[0,100]},'bar':{'color':RATING.get(r.rating,'#888')},\n",
    "               'steps':[{'range':[0,30],'color':'#fee2e2'},{'range':[30,50],'color':'#fef3c7'},{'range':[50,70],'color':'#fef9c3'},{'range':[70,85],'color':'#dcfce7'},{'range':[85,100],'color':'#bbf7d0'}],\n",
    "               'threshold':{'line':{'color':'black','width':3},'thickness':0.8,'value':70}}))\n",
    "    fig.update_layout(height=300,width=380)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quality_radar(r):\n",
    "    q = r.quality_score\n",
    "    cats = ['CN0','Availability','Continuity','Stability','Diversity','CN0']\n",
    "    vals = [q.cn0_quality,q.availability,q.continuity,q.stability,q.diversity,q.cn0_quality]\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatterpolar(r=vals,theta=cats,fill='toself',fillcolor='rgba(59,130,246,0.3)',line=dict(color='#3b82f6',width=2),name='Quality'))\n",
    "    fig.add_trace(go.Scatterpolar(r=[70]*6,theta=cats,fill='none',line=dict(color='green',dash='dash'),name='Good'))\n",
    "    fig.update_layout(title='Quality Breakdown',polar=dict(radialaxis=dict(range=[0,100])),height=400,width=420)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create_anomaly_timeline function\n",
    "\n",
    "def create_anomaly_timeline(r):\n",
    "    \"\"\"Create anomaly timeline plot from Rust analysis result\"\"\"\n",
    "    anomalies = r.get_anomalies()\n",
    "    \n",
    "    if not anomalies:\n",
    "        fig = go.Figure()\n",
    "        fig.add_annotation(\n",
    "            text='‚úÖ No anomalies detected',\n",
    "            xref='paper', yref='paper',\n",
    "            x=0.5, y=0.5,\n",
    "            showarrow=False,\n",
    "            font=dict(size=18, color='green')\n",
    "        )\n",
    "        fig.update_layout(title='Anomaly Timeline', height=300)\n",
    "        return fig\n",
    "    \n",
    "    # Parse data - handle missing keys gracefully\n",
    "    parsed_data = []\n",
    "    for a in anomalies:\n",
    "        try:\n",
    "            # Get timestamp - try multiple keys\n",
    "            ts_str = a.get('start_time') or a.get('timestamp') or ''\n",
    "            if ts_str:\n",
    "                ts = pd.to_datetime(ts_str)\n",
    "            else:\n",
    "                continue  # Skip if no timestamp\n",
    "            \n",
    "            parsed_data.append({\n",
    "                'time': ts,\n",
    "                'type': a.get('anomaly_type', a.get('type', 'Unknown')),\n",
    "                'severity': a.get('severity', 'Low'),\n",
    "                'cn0_drop': float(a.get('cn0_drop', a.get('cn0_drop_db', 0)) or 0),\n",
    "                'description': a.get('description', ''),\n",
    "                'satellites': a.get('affected_satellites', ''),\n",
    "            })\n",
    "        except Exception as e:\n",
    "            continue  # Skip malformed anomalies\n",
    "    \n",
    "    if not parsed_data:\n",
    "        fig = go.Figure()\n",
    "        fig.add_annotation(\n",
    "            text='‚ö†Ô∏è Anomalies found but timestamps invalid',\n",
    "            xref='paper', yref='paper',\n",
    "            x=0.5, y=0.5,\n",
    "            showarrow=False,\n",
    "            font=dict(size=14, color='orange')\n",
    "        )\n",
    "        fig.update_layout(title='Anomaly Timeline', height=300)\n",
    "        return fig\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Plot by severity\n",
    "    severity_colors = {\n",
    "        'Critical': '#ef4444',  # Red\n",
    "        'High': '#f97316',      # Orange  \n",
    "        'Medium': '#eab308',    # Yellow\n",
    "        'Low': '#22c55e',       # Green\n",
    "        'critical': '#ef4444',\n",
    "        'high': '#f97316',\n",
    "        'medium': '#eab308',\n",
    "        'low': '#22c55e',\n",
    "    }\n",
    "    \n",
    "    for severity in ['Critical', 'High', 'Medium', 'Low', 'critical', 'high', 'medium', 'low']:\n",
    "        sev_data = [d for d in parsed_data if d['severity'] == severity]\n",
    "        if sev_data:\n",
    "            # Normalize severity name for display\n",
    "            display_name = severity.capitalize()\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[d['time'] for d in sev_data],\n",
    "                y=[d['cn0_drop'] for d in sev_data],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=10,\n",
    "                    color=severity_colors.get(severity, '#888'),\n",
    "                    opacity=0.7\n",
    "                ),\n",
    "                name=f\"{display_name} ({len(sev_data)})\",\n",
    "                text=[f\"{d['type']}<br>{d['description']}\" for d in sev_data],\n",
    "                hovertemplate=\"Time: %{x}<br>CN0 Drop: %{y:.1f} dB<br>%{text}<extra></extra>\"\n",
    "            ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'Anomaly Timeline ({len(parsed_data)} events)',\n",
    "        xaxis_title='Time (UTC)',\n",
    "        xaxis=dict(type='date'),  # Force date axis\n",
    "        yaxis_title='CN0 Drop (dB)',\n",
    "        height=400,\n",
    "        legend=dict(orientation='h', y=1.1)\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "print('‚úÖ Fixed create_anomaly_timeline function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Widget\n",
    "\n",
    "Complete widget with 5 presets and 9 visualization tabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5f1e1ccd9a4c3a97657758c5218691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üì° CN0 Analysis - GNSS Signal Quality with Presets</h3>'), HTML(value='<hr>'), H‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CN0 Widget Ready with Presets\n",
      "   Presets: Full | Quick | Interference | Jamming | Spoofing\n",
      "   Features: Lock Integrity, Fixed Anomaly Graph, Research-based Thresholds\n"
     ]
    }
   ],
   "source": [
    "# CN0 Analysis Widget with Presets, Lock Integrity & Fixed Anomaly Graph\n",
    "# =========================================================================\n",
    "# Features:\n",
    "# - Research-based preset configurations (ITU, Stanford GPS Lab, GPS Solutions)\n",
    "# - Lock Integrity metric (cycle slips + data gaps)\n",
    "# - Fixed anomaly graph using pd.to_datetime for robust timestamp parsing\n",
    "# - Quick mode for fast analysis\n",
    "# - File path support + auto-download navigation\n",
    "# =========================================================================\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import os\n",
    "import gzip\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "# Storage for loaded data\n",
    "loaded_data = {\n",
    "    'obs_content': None,\n",
    "    'obs_filename': None,\n",
    "    'obs_path': None,\n",
    "    'nav_content': None,\n",
    "    'nav_filename': None,\n",
    "    'nav_path': None,\n",
    "}\n",
    "\n",
    "# ============ NAVIGATION DOWNLOADER ============\n",
    "class NavDownloader:\n",
    "    \"\"\"Multi-GNSS Navigation/Ephemeris Downloader\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def gps_week_from_date(year, doy):\n",
    "        \"\"\"Calculate GPS week and day-of-week from year and DOY\"\"\"\n",
    "        from datetime import date, timedelta\n",
    "        gps_epoch = date(1980, 1, 6)\n",
    "        target = date(year, 1, 1) + timedelta(days=doy - 1)\n",
    "        delta = (target - gps_epoch).days\n",
    "        return delta // 7, delta % 7\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_rinex_header(filepath):\n",
    "        \"\"\"Extract year, doy from RINEX file header\"\"\"\n",
    "        from datetime import date\n",
    "        try:\n",
    "            with open(filepath, 'r', errors='ignore') as f:\n",
    "                for line in f:\n",
    "                    if 'TIME OF FIRST OBS' in line:\n",
    "                        parts = line.split()\n",
    "                        if len(parts) >= 6:\n",
    "                            year = int(float(parts[0]))\n",
    "                            month = int(float(parts[1]))\n",
    "                            day = int(float(parts[2]))\n",
    "                            doy = date(year, month, day).timetuple().tm_yday\n",
    "                            return year, doy\n",
    "                    if 'END OF HEADER' in line:\n",
    "                        break\n",
    "        except Exception as e:\n",
    "            print(f\"   Header parse error: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    @staticmethod\n",
    "    def count_nav_satellites(content):\n",
    "        \"\"\"Count satellites per constellation in navigation file content\"\"\"\n",
    "        if isinstance(content, bytes):\n",
    "            content = content.decode('utf-8', errors='ignore')\n",
    "        \n",
    "        sats = {'G': set(), 'R': set(), 'E': set(), 'C': set(), 'J': set(), 'I': set()}\n",
    "        \n",
    "        for line in content.split('\\n'):\n",
    "            if len(line) >= 3:\n",
    "                first_char = line[0]\n",
    "                if first_char in sats:\n",
    "                    try:\n",
    "                        prn = line[1:3].strip()\n",
    "                        if prn.isdigit():\n",
    "                            sats[first_char].add(int(prn))\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        return {k: len(v) for k, v in sats.items()}\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_sat_summary(counts):\n",
    "        \"\"\"Format satellite count summary\"\"\"\n",
    "        names = {'G': 'GPS', 'R': 'GLO', 'E': 'GAL', 'C': 'BDS', 'J': 'QZS', 'I': 'NAV'}\n",
    "        parts = []\n",
    "        for sys, count in counts.items():\n",
    "            if count > 0:\n",
    "                parts.append(f\"{names.get(sys, sys)}:{count}\")\n",
    "        return \", \".join(parts)\n",
    "    \n",
    "    @staticmethod\n",
    "    def download(year, doy, output_dir, log_func=print, prefer_sp3=False):\n",
    "        \"\"\"Download ephemeris - tries multiple sources\"\"\"\n",
    "        if prefer_sp3:\n",
    "            result = NavDownloader.download_sp3(year, doy, output_dir, log_func)\n",
    "            if result:\n",
    "                return result\n",
    "            log_func(\"   SP3 not available, trying BRDC...\")\n",
    "        \n",
    "        result = NavDownloader.download_brdc_best(year, doy, output_dir, log_func)\n",
    "        if result:\n",
    "            return result\n",
    "        \n",
    "        if not prefer_sp3:\n",
    "            log_func(\"   BRDC not available, trying SP3...\")\n",
    "            return NavDownloader.download_sp3(year, doy, output_dir, log_func)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def download_brdc_best(year, doy, output_dir, log_func=print):\n",
    "        \"\"\"Download BRDC - tries multiple sources and picks the most complete\"\"\"\n",
    "        import ssl\n",
    "        \n",
    "        ctx = ssl.create_default_context()\n",
    "        ctx.check_hostname = False\n",
    "        ctx.verify_mode = ssl.CERT_NONE\n",
    "        \n",
    "        brdc_sources = [\n",
    "            {\"name\": \"BKG IGS\", \"url\": f\"https://igs.bkg.bund.de/root_ftp/IGS/BRDC/{year}/{doy:03d}/BRDC00IGS_R_{year}{doy:03d}0000_01D_MN.rnx.gz\",\n",
    "             \"filename\": f\"BRDC00IGS_R_{year}{doy:03d}0000_01D_MN.rnx\"},\n",
    "            {\"name\": \"DLR MGEX\", \"url\": f\"https://igs.bkg.bund.de/root_ftp/MGEX/BRDC/{year}/{doy:03d}/BRDM00DLR_S_{year}{doy:03d}0000_01D_MN.rnx.gz\",\n",
    "             \"filename\": f\"BRDM00DLR_S_{year}{doy:03d}0000_01D_MN.rnx\"},\n",
    "            {\"name\": \"IGN France\", \"url\": f\"https://igs.ign.fr/pub/igs/data/{year}/{doy:03d}/BRDC00IGS_R_{year}{doy:03d}0000_01D_MN.rnx.gz\",\n",
    "             \"filename\": f\"BRDC00IGS_R_{year}{doy:03d}0000_01D_MN_ign.rnx\"},\n",
    "        ]\n",
    "        \n",
    "        out_path = Path(output_dir)\n",
    "        candidates = []\n",
    "        \n",
    "        log_func(\"   Checking BRDC sources...\")\n",
    "        \n",
    "        for source in brdc_sources:\n",
    "            log_func(f\"   ‚è≥ {source['name']}...\")\n",
    "            \n",
    "            try:\n",
    "                req = urllib.request.Request(source[\"url\"])\n",
    "                req.add_header('User-Agent', 'Mozilla/5.0 GNSS-Analysis')\n",
    "                \n",
    "                with urllib.request.urlopen(req, timeout=45, context=ctx) as resp:\n",
    "                    data = resp.read()\n",
    "                \n",
    "                if len(data) < 1000:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    decompressed = gzip.decompress(data)\n",
    "                except:\n",
    "                    decompressed = data\n",
    "                \n",
    "                counts = NavDownloader.count_nav_satellites(decompressed)\n",
    "                total = sum(counts.values())\n",
    "                \n",
    "                if total == 0:\n",
    "                    continue\n",
    "                \n",
    "                summary = NavDownloader.format_sat_summary(counts)\n",
    "                log_func(f\"      ‚úì {total} sats: {summary}\")\n",
    "                \n",
    "                candidates.append({\n",
    "                    'source': source,\n",
    "                    'content': decompressed,\n",
    "                    'counts': counts,\n",
    "                    'total': total,\n",
    "                    'summary': summary\n",
    "                })\n",
    "                \n",
    "            except urllib.error.HTTPError as e:\n",
    "                log_func(f\"      ‚úó HTTP {e.code}\")\n",
    "            except Exception as e:\n",
    "                log_func(f\"      ‚úó {str(e)[:30]}\")\n",
    "        \n",
    "        if not candidates:\n",
    "            log_func(\"   ‚ùå No BRDC sources available\")\n",
    "            return None\n",
    "        \n",
    "        def score(c):\n",
    "            num_systems = sum(1 for v in c['counts'].values() if v > 0)\n",
    "            return (num_systems, c['total'])\n",
    "        \n",
    "        best = max(candidates, key=score)\n",
    "        \n",
    "        out_file = out_path / best['source']['filename']\n",
    "        with open(out_file, 'wb') as f:\n",
    "            f.write(best['content'])\n",
    "        \n",
    "        log_func(f\"   ‚úÖ Selected: {best['source']['name']}\")\n",
    "        log_func(f\"   üìä Ephemeris: {best['summary']}\")\n",
    "        \n",
    "        return out_file\n",
    "    \n",
    "    @staticmethod\n",
    "    def download_sp3(year, doy, output_dir, log_func=print):\n",
    "        \"\"\"Download Multi-GNSS SP3 precise ephemeris\"\"\"\n",
    "        import ssl\n",
    "        \n",
    "        week, dow = NavDownloader.gps_week_from_date(year, doy)\n",
    "        \n",
    "        ctx = ssl.create_default_context()\n",
    "        ctx.check_hostname = False\n",
    "        ctx.verify_mode = ssl.CERT_NONE\n",
    "        \n",
    "        sp3_sources = [\n",
    "            {\"name\": \"ESA Final\", \"url\": f\"http://navigation-office.esa.int/products/gnss-products/{week}/ESA0MGNFIN_{year}{doy:03d}0000_01D_05M_ORB.SP3.gz\"},\n",
    "            {\"name\": \"GFZ Final\", \"url\": f\"https://igs.bkg.bund.de/root_ftp/IGS/products/mgex/{week}/GFZ0MGXFIN_{year}{doy:03d}0000_01D_05M_ORB.SP3.gz\"},\n",
    "        ]\n",
    "        \n",
    "        out_path = Path(output_dir)\n",
    "        log_func(f\"   üîç Looking for SP3 (Week {week})...\")\n",
    "        \n",
    "        for source in sp3_sources:\n",
    "            try:\n",
    "                req = urllib.request.Request(source[\"url\"])\n",
    "                req.add_header('User-Agent', 'Mozilla/5.0 GNSS-Analysis')\n",
    "                \n",
    "                with urllib.request.urlopen(req, timeout=60, context=ctx) as resp:\n",
    "                    data = resp.read()\n",
    "                \n",
    "                if len(data) < 10000:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    decompressed = gzip.decompress(data)\n",
    "                except:\n",
    "                    decompressed = data\n",
    "                \n",
    "                out_file = out_path / f\"{source['name'].replace(' ', '_')}_{year}{doy:03d}.sp3\"\n",
    "                with open(out_file, 'wb') as f:\n",
    "                    f.write(decompressed)\n",
    "                \n",
    "                log_func(f\"   ‚úÖ {source['name']}\")\n",
    "                return out_file\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        log_func(\"   ‚ùå SP3 not available\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ============ FILE INPUT WIDGETS ============\n",
    "header = widgets.HTML(\"<h3>üì° CN0 Analysis - GNSS Signal Quality with Presets</h3>\")\n",
    "\n",
    "# === OBSERVATION FILE ===\n",
    "obs_section = widgets.HTML(\"<b>Observation File</b> (required)\")\n",
    "\n",
    "obs_upload = widgets.FileUpload(\n",
    "    accept='.obs,.rnx,.crx,.24o,.23o,.22o,.21o,.20o,.25o,.gz,.Z,*',\n",
    "    multiple=False,\n",
    "    description='Upload OBS',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "obs_path_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='/path/to/observation.rnx',\n",
    "    description='OBS Path:',\n",
    "    style={'description_width': '70px'},\n",
    "    layout=widgets.Layout(width='450px')\n",
    ")\n",
    "\n",
    "# === NAVIGATION FILE ===\n",
    "nav_section = widgets.HTML(\"<b>Navigation/Ephemeris</b> (for elevation & skyplots)\")\n",
    "\n",
    "nav_upload = widgets.FileUpload(\n",
    "    accept='.nav,.rnx,.24n,.24g,.25n,.sp3,.SP3,.gz,.Z,*',\n",
    "    multiple=False,\n",
    "    description='Upload NAV',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "nav_path_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='/path/to/navigation.rnx or .sp3',\n",
    "    description='NAV Path:',\n",
    "    style={'description_width': '70px'},\n",
    "    layout=widgets.Layout(width='450px')\n",
    ")\n",
    "\n",
    "auto_download_nav = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Auto-download BRDC if missing',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='250px')\n",
    ")\n",
    "\n",
    "load_btn = widgets.Button(\n",
    "    description='üì• Load Files',\n",
    "    button_style='warning',\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "\n",
    "# === ANALYSIS CONFIG ===\n",
    "config_section = widgets.HTML(\"<b>Analysis Configuration</b>\")\n",
    "\n",
    "# Preset dropdown with research-based configurations\n",
    "preset_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('üî¨ Full Analysis', 'full'),\n",
    "        ('‚ö° Quick Summary', 'quick'),\n",
    "        ('üìä Interference Focus', 'interference'),\n",
    "        ('üéØ Jamming Detection', 'jamming'),\n",
    "        ('üõ°Ô∏è Spoofing Check', 'spoofing'),\n",
    "    ],\n",
    "    value='full',\n",
    "    description='Preset:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "# Preset help text with research-based thresholds\n",
    "preset_help = widgets.HTML(value=\"\"\"\n",
    "<div style=\"font-size:11px; color:#666; margin-top:5px; padding:10px; background:#f8f9fa; border-radius:4px; border-left:3px solid #3182ce;\">\n",
    "<b>Preset Configurations (research-based thresholds):</b><br><br>\n",
    "‚Ä¢ <b>Full Analysis</b>: Complete analysis with all plots (sensitivity: 0.3, threshold: 8 dB)<br>\n",
    "‚Ä¢ <b>Quick Summary</b>: Fast overview, skips heavy plots (sensitivity: 0.5, threshold: 10 dB)<br>\n",
    "‚Ä¢ <b>Interference Focus</b>: Detect subtle interference &gt;4 dB (<i>ITU I/N=-6dB criterion</i>)<br>\n",
    "‚Ä¢ <b>Jamming Detection</b>: Rapid drops &gt;6 dB in &lt;3s (<i>Stanford GPS Lab</i>)<br>\n",
    "‚Ä¢ <b>Spoofing Check</b>: CN0 uniformity &amp; elevation anomalies (<i>GPS Solutions</i>)<br><br>\n",
    "<i>Thresholds from: ITU-R M.1902-1, Stanford GPS Lab, GPS Solutions journal</i>\n",
    "</div>\n",
    "\"\"\")\n",
    "\n",
    "elevation_slider = widgets.FloatSlider(\n",
    "    value=5.0, min=0.0, max=30.0, step=1.0,\n",
    "    description='Elevation Cutoff (¬∞):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "time_bin_slider = widgets.IntSlider(\n",
    "    value=60, min=10, max=300, step=10,\n",
    "    description='Time Bin (sec):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "system_checks = {\n",
    "    'G': widgets.Checkbox(value=True, description='GPS', layout=widgets.Layout(width='100px')),\n",
    "    'R': widgets.Checkbox(value=True, description='GLONASS', layout=widgets.Layout(width='100px')),\n",
    "    'E': widgets.Checkbox(value=True, description='Galileo', layout=widgets.Layout(width='100px')),\n",
    "    'C': widgets.Checkbox(value=True, description='BeiDou', layout=widgets.Layout(width='100px')),\n",
    "}\n",
    "\n",
    "# === BUTTONS ===\n",
    "analyze_btn = widgets.Button(\n",
    "    description='üî¨ Run CN0 Analysis',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "export_btn = widgets.Button(\n",
    "    description='üì• Export Results',\n",
    "    button_style='success',\n",
    "    disabled=True,\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "\n",
    "clear_btn = widgets.Button(\n",
    "    description='üóëÔ∏è Clear',\n",
    "    button_style='danger',\n",
    "    layout=widgets.Layout(width='100px')\n",
    ")\n",
    "\n",
    "# Progress & Status\n",
    "progress = widgets.FloatProgress(\n",
    "    value=0, min=0, max=1.0,\n",
    "    description='Progress:',\n",
    "    layout=widgets.Layout(width='400px', visibility='hidden')\n",
    ")\n",
    "\n",
    "status = widgets.HTML(value=\"<b>Status:</b> Ready - load files to begin\")\n",
    "\n",
    "# Output areas\n",
    "info_out = widgets.Output()\n",
    "results_out = widgets.Output()\n",
    "\n",
    "# Store analysis results\n",
    "analysis_results = {'data': None, 'figures': {}, 'report_html': '', 'lock_integrity': {}}\n",
    "\n",
    "\n",
    "# ============ PRESET CONFIGURATIONS ============\n",
    "# Research-based thresholds from:\n",
    "# - ITU-R M.1902-1: I/N = -6 dB (1 dB noise floor increase) \n",
    "# - Stanford GPS Lab: CN0 min 27 dB-Hz, >6 dB drop in <3s = jamming\n",
    "# - GPS Solutions: CN0 uniformity <2 dB std = spoofing indicator\n",
    "# - MDPI Sensors: Multi-parameter detection\n",
    "\n",
    "PRESET_CONFIGS = {\n",
    "    'full': {\n",
    "        'sensitivity': 0.3,\n",
    "        'threshold': 8.0,\n",
    "        'description': 'Complete analysis with all plots',\n",
    "        'skip_heavy_plots': False,\n",
    "    },\n",
    "    'quick': {\n",
    "        'sensitivity': 0.5,\n",
    "        'threshold': 10.0,\n",
    "        'description': 'Fast overview - skips heatmaps and per-satellite plots',\n",
    "        'skip_heavy_plots': True,\n",
    "    },\n",
    "    'interference': {\n",
    "        'sensitivity': 0.15,\n",
    "        'threshold': 4.0,\n",
    "        'description': 'Detect subtle interference >4 dB (ITU criterion)',\n",
    "        'skip_heavy_plots': False,\n",
    "    },\n",
    "    'jamming': {\n",
    "        'sensitivity': 0.2,\n",
    "        'threshold': 6.0,\n",
    "        'description': 'Optimized for jamming: rapid CN0 drops >6 dB',\n",
    "        'skip_heavy_plots': False,\n",
    "    },\n",
    "    'spoofing': {\n",
    "        'sensitivity': 0.1,\n",
    "        'threshold': 5.0,\n",
    "        'description': 'Focus on CN0 uniformity and elevation anomalies',\n",
    "        'skip_heavy_plots': False,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# ============ HTML REPORT GENERATOR ============\n",
    "def generate_html_report(result, const_data, anomalies, lock_integrity_data=None):\n",
    "    \"\"\"Generate a comprehensive HTML report\"\"\"\n",
    "    qs = result.quality_score\n",
    "    \n",
    "    # Unpack lock integrity data\n",
    "    if lock_integrity_data:\n",
    "        lock_score = lock_integrity_data.get('score', 0)\n",
    "        total_cycle_slips = lock_integrity_data.get('total_cycle_slips', 0)\n",
    "        total_data_gaps = lock_integrity_data.get('total_data_gaps', 0)\n",
    "        slips_per_hour = lock_integrity_data.get('slips_per_hour', 0)\n",
    "    else:\n",
    "        lock_score = total_cycle_slips = total_data_gaps = slips_per_hour = 0\n",
    "    \n",
    "    html = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>CN0 Analysis Report - {result.filename}</title>\n",
    "    <style>\n",
    "        body {{ font-family: Arial, sans-serif; margin: 40px; background: #f5f5f5; }}\n",
    "        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}\n",
    "        h1 {{ color: #1a365d; border-bottom: 3px solid #3182ce; padding-bottom: 10px; }}\n",
    "        h2 {{ color: #2c5282; margin-top: 30px; }}\n",
    "        .score-box {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; text-align: center; margin: 20px 0; }}\n",
    "        .score-value {{ font-size: 48px; font-weight: bold; }}\n",
    "        .score-rating {{ font-size: 24px; opacity: 0.9; }}\n",
    "        .metric-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(180px, 1fr)); gap: 15px; margin: 20px 0; }}\n",
    "        .metric-card {{ background: #f7fafc; padding: 15px; border-radius: 8px; border-left: 4px solid #3182ce; }}\n",
    "        .metric-value {{ font-size: 24px; font-weight: bold; color: #2d3748; }}\n",
    "        .metric-label {{ color: #718096; font-size: 14px; }}\n",
    "        .status-ok {{ color: #38a169; }}\n",
    "        .status-warning {{ color: #d69e2e; }}\n",
    "        .status-danger {{ color: #e53e3e; }}\n",
    "        .anomaly {{ background: #fff5f5; border-left: 4px solid #e53e3e; padding: 10px; margin: 5px 0; border-radius: 4px; }}\n",
    "        .footer {{ margin-top: 40px; padding-top: 20px; border-top: 1px solid #e2e8f0; color: #718096; font-size: 12px; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "<div class=\"container\">\n",
    "    <h1>üì° CN0 Analysis Report</h1>\n",
    "    \n",
    "    <h2>üìÅ File Information</h2>\n",
    "    <div class=\"metric-grid\">\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Filename</div><div class=\"metric-value\" style=\"font-size:14px;\">{result.filename}</div></div>\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">RINEX Version</div><div class=\"metric-value\">{result.rinex_version}</div></div>\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Duration</div><div class=\"metric-value\">{result.duration_hours:.2f} h</div></div>\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Epochs</div><div class=\"metric-value\">{result.epoch_count:,}</div></div>\n",
    "    </div>\n",
    "    \n",
    "    <h2>üèÜ Quality Score</h2>\n",
    "    <div class=\"score-box\">\n",
    "        <div class=\"score-value\">{qs.overall:.0f}/100</div>\n",
    "        <div class=\"score-rating\">{qs.rating}</div>\n",
    "    </div>\n",
    "    <div class=\"metric-grid\">\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">CN0 Quality</div><div class=\"metric-value\">{qs.cn0_quality:.0f}</div></div>\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Availability</div><div class=\"metric-value\">{qs.availability:.0f}</div></div>\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Continuity</div><div class=\"metric-value\">{qs.continuity:.0f}</div></div>\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Stability</div><div class=\"metric-value\">{qs.stability:.0f}</div></div>\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Diversity</div><div class=\"metric-value\">{qs.diversity:.0f}</div></div>\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Lock Integrity</div><div class=\"metric-value\">{lock_score:.0f}</div></div>\n",
    "    </div>\n",
    "    \n",
    "    <h2>üì∂ Signal Quality</h2>\n",
    "    <div class=\"metric-grid\">\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Average CN0</div><div class=\"metric-value\">{result.avg_cn0:.1f} dB-Hz</div></div>\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Std Deviation</div><div class=\"metric-value\">{result.cn0_std_dev:.1f} dB-Hz</div></div>\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Range</div><div class=\"metric-value\">{result.min_cn0:.1f} - {result.max_cn0:.1f}</div></div>\n",
    "    </div>\n",
    "    \n",
    "    <h2>üîì Lock Integrity</h2>\n",
    "    <div class=\"metric-grid\">\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Cycle Slips</div><div class=\"metric-value\">{total_cycle_slips}</div><div style=\"font-size:11px;\">{slips_per_hour:.1f}/hour</div></div>\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Data Gaps</div><div class=\"metric-value\">{total_data_gaps}</div></div>\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Lock Score</div><div class=\"metric-value {'status-ok' if lock_score >= 70 else 'status-warning' if lock_score >= 50 else 'status-danger'}\">{lock_score:.0f}/100</div></div>\n",
    "    </div>\n",
    "    \n",
    "    <h2>üõ°Ô∏è Threat Assessment</h2>\n",
    "    <div class=\"metric-grid\">\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Jamming</div><div class=\"metric-value {'status-danger' if result.jamming_detected else 'status-ok'}\">{'üö® DETECTED' if result.jamming_detected else '‚úÖ None'}</div></div>\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Spoofing</div><div class=\"metric-value {'status-danger' if result.spoofing_detected else 'status-ok'}\">{'üö® DETECTED' if result.spoofing_detected else '‚úÖ None'}</div></div>\n",
    "        <div class=\"metric-card\"><div class=\"metric-label\">Interference</div><div class=\"metric-value {'status-warning' if result.interference_detected else 'status-ok'}\">{'‚ö†Ô∏è Yes' if result.interference_detected else '‚úÖ None'}</div></div>\n",
    "    </div>\n",
    "    \n",
    "    <h2>‚ö†Ô∏è Anomalies ({len(anomalies) if anomalies else 0})</h2>\n",
    "    {'<p>No anomalies detected.</p>' if not anomalies else ''.join([f\"<div class='anomaly'><b>{a.get('anomaly_type', 'Unknown')}</b> ({a.get('severity', 'low')}) - {a.get('start_time', '')}</div>\" for a in anomalies[:20]])}\n",
    "    \n",
    "    <h2>üìù Summary</h2>\n",
    "    <p>{result.summary}</p>\n",
    "    \n",
    "    <div class=\"footer\">\n",
    "        <p>Generated by CN0 Analysis Widget | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "    </div>\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "    \"\"\"\n",
    "    \n",
    "    return html\n",
    "\n",
    "\n",
    "# ============ HANDLERS ============\n",
    "def load_files(btn):\n",
    "    \"\"\"Load files from paths OR upload widgets\"\"\"\n",
    "    with info_out:\n",
    "        clear_output()\n",
    "        print(\"üì• Loading files...\")\n",
    "        \n",
    "        obs_loaded = False\n",
    "        nav_loaded = False\n",
    "        \n",
    "        # ===== OBSERVATION FILE =====\n",
    "        if obs_path_input.value.strip():\n",
    "            path = obs_path_input.value.strip()\n",
    "            print(f\"\\nüìÇ Loading OBS from path: {path}\")\n",
    "            \n",
    "            if os.path.exists(path):\n",
    "                try:\n",
    "                    with open(path, 'rb') as f:\n",
    "                        content = f.read()\n",
    "                    \n",
    "                    name = os.path.basename(path)\n",
    "                    if name.lower().endswith('.gz'):\n",
    "                        content = gzip.decompress(content)\n",
    "                    \n",
    "                    loaded_data['obs_content'] = content\n",
    "                    loaded_data['obs_filename'] = name\n",
    "                    loaded_data['obs_path'] = path\n",
    "                    print(f\"‚úÖ Loaded: {name} ({len(content)/1024/1024:.1f} MB)\")\n",
    "                    obs_loaded = True\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error: {e}\")\n",
    "            else:\n",
    "                print(f\"‚ùå File not found: {path}\")\n",
    "        \n",
    "        if not obs_loaded and obs_upload.value:\n",
    "            print(f\"\\nüì§ Loading OBS from upload widget...\")\n",
    "            try:\n",
    "                if len(obs_upload.value) > 0:\n",
    "                    if isinstance(obs_upload.value, dict):\n",
    "                        name = list(obs_upload.value.keys())[0]\n",
    "                        content = obs_upload.value[name]['content']\n",
    "                    else:\n",
    "                        fi = obs_upload.value[0]\n",
    "                        name = getattr(fi, 'name', fi.get('name', 'unknown'))\n",
    "                        content = getattr(fi, 'content', fi.get('content', b''))\n",
    "                    \n",
    "                    if content:\n",
    "                        if name.lower().endswith('.gz'):\n",
    "                            content = gzip.decompress(content)\n",
    "                        \n",
    "                        loaded_data['obs_content'] = content\n",
    "                        loaded_data['obs_filename'] = name\n",
    "                        print(f\"‚úÖ Loaded: {name} ({len(content)/1024/1024:.1f} MB)\")\n",
    "                        obs_loaded = True\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Upload error: {e}\")\n",
    "        \n",
    "        if not obs_loaded:\n",
    "            print(\"\\n‚ùå No observation file loaded!\")\n",
    "            status.value = \"<b>Status:</b> <span style='color:red'>Missing observation file</span>\"\n",
    "            return\n",
    "        \n",
    "        # ===== NAVIGATION FILE =====\n",
    "        if nav_path_input.value.strip():\n",
    "            path = nav_path_input.value.strip()\n",
    "            print(f\"\\nüìÇ Loading NAV from path: {path}\")\n",
    "            \n",
    "            if os.path.exists(path):\n",
    "                try:\n",
    "                    with open(path, 'rb') as f:\n",
    "                        content = f.read()\n",
    "                    \n",
    "                    name = os.path.basename(path)\n",
    "                    if name.lower().endswith('.gz'):\n",
    "                        content = gzip.decompress(content)\n",
    "                    \n",
    "                    loaded_data['nav_content'] = content\n",
    "                    loaded_data['nav_filename'] = name\n",
    "                    loaded_data['nav_path'] = path\n",
    "                    print(f\"‚úÖ Loaded: {name}\")\n",
    "                    nav_loaded = True\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error: {e}\")\n",
    "        \n",
    "        if not nav_loaded and nav_upload.value:\n",
    "            try:\n",
    "                if len(nav_upload.value) > 0:\n",
    "                    if isinstance(nav_upload.value, dict):\n",
    "                        name = list(nav_upload.value.keys())[0]\n",
    "                        content = nav_upload.value[name]['content']\n",
    "                    else:\n",
    "                        fi = nav_upload.value[0]\n",
    "                        name = getattr(fi, 'name', fi.get('name', 'unknown'))\n",
    "                        content = getattr(fi, 'content', fi.get('content', b''))\n",
    "                    \n",
    "                    if content:\n",
    "                        if name.lower().endswith('.gz'):\n",
    "                            content = gzip.decompress(content)\n",
    "                        \n",
    "                        loaded_data['nav_content'] = content\n",
    "                        loaded_data['nav_filename'] = name\n",
    "                        print(f\"‚úÖ Loaded: {name}\")\n",
    "                        nav_loaded = True\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Upload error: {e}\")\n",
    "        \n",
    "        # Try auto-download\n",
    "        if not nav_loaded and auto_download_nav.value and obs_loaded:\n",
    "            print(\"\\nüåê Auto-downloading navigation file...\")\n",
    "            year, doy = None, None\n",
    "            if loaded_data.get('obs_path'):\n",
    "                year, doy = NavDownloader.parse_rinex_header(loaded_data['obs_path'])\n",
    "            elif loaded_data.get('obs_content'):\n",
    "                header = loaded_data['obs_content'][:8000].decode('utf-8', errors='ignore')\n",
    "                for line in header.split('\\n'):\n",
    "                    if 'TIME OF FIRST OBS' in line:\n",
    "                        from datetime import date\n",
    "                        parts = line.split()\n",
    "                        if len(parts) >= 6:\n",
    "                            year = int(float(parts[0]))\n",
    "                            month = int(float(parts[1]))\n",
    "                            day = int(float(parts[2]))\n",
    "                            doy = date(year, month, day).timetuple().tm_yday\n",
    "                        break\n",
    "            \n",
    "            if year and doy:\n",
    "                print(f\"   Date: Year {year}, DOY {doy}\")\n",
    "                temp_dir = tempfile.gettempdir()\n",
    "                nav_path = NavDownloader.download(year, doy, temp_dir, log_func=print)\n",
    "                \n",
    "                if nav_path and nav_path.exists():\n",
    "                    with open(nav_path, 'rb') as f:\n",
    "                        loaded_data['nav_content'] = f.read()\n",
    "                    loaded_data['nav_filename'] = nav_path.name\n",
    "                    loaded_data['nav_path'] = str(nav_path)\n",
    "                    nav_loaded = True\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"üìä LOADED FILES:\")\n",
    "        print(f\"   OBS: {loaded_data['obs_filename'] or 'None'}\")\n",
    "        print(f\"   NAV: {loaded_data['nav_filename'] or 'None (elevations estimated)'}\")\n",
    "        \n",
    "        if nav_loaded:\n",
    "            status.value = \"<b>Status:</b> <span style='color:green'>‚úì Files loaded with ephemeris</span>\"\n",
    "        else:\n",
    "            status.value = \"<b>Status:</b> <span style='color:orange'>‚ö† No NAV - elevations estimated</span>\"\n",
    "        \n",
    "        analyze_btn.disabled = False\n",
    "\n",
    "\n",
    "def run_analysis(btn):\n",
    "    \"\"\"Run CN0 analysis with preset configuration\"\"\"\n",
    "    if not loaded_data['obs_content']:\n",
    "        with info_out:\n",
    "            print(\"‚ùå No observation file loaded!\")\n",
    "        return\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "    \n",
    "    progress.layout.visibility = 'visible'\n",
    "    progress.value = 0.05\n",
    "    status.value = \"<b>Status:</b> <span style='color:blue'>‚è≥ Starting analysis...</span>\"\n",
    "    analyze_btn.disabled = True\n",
    "    \n",
    "    with results_out:\n",
    "        print(\"üî¨ Starting CN0 Analysis...\")\n",
    "        \n",
    "        # Get config\n",
    "        elev_cutoff = elevation_slider.value\n",
    "        time_bin = int(time_bin_slider.value)\n",
    "        systems = [k for k, v in system_checks.items() if v.value]\n",
    "        preset = preset_dropdown.value\n",
    "        \n",
    "        # Get preset configuration\n",
    "        preset_cfg = PRESET_CONFIGS.get(preset, PRESET_CONFIGS['full'])\n",
    "        \n",
    "        print(f\"\\nüìã Preset: {preset.upper()}\")\n",
    "        print(f\"   {preset_cfg['description']}\")\n",
    "        print(f\"   Sensitivity: {preset_cfg['sensitivity']}\")\n",
    "        print(f\"   Threshold: {preset_cfg['threshold']} dB\")\n",
    "        print(f\"\\nüìã Configuration:\")\n",
    "        print(f\"   Elevation cutoff: {elev_cutoff}¬∞\")\n",
    "        print(f\"   Time bin: {time_bin}s\")\n",
    "        print(f\"   Systems: {', '.join(systems)}\")\n",
    "        \n",
    "        progress.value = 0.1\n",
    "        status.value = \"<b>Status:</b> <span style='color:blue'>‚è≥ Preparing files...</span>\"\n",
    "        \n",
    "        # Write temp files\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        obs_path = os.path.join(temp_dir, loaded_data['obs_filename'])\n",
    "        \n",
    "        with open(obs_path, 'wb') as f:\n",
    "            f.write(loaded_data['obs_content'])\n",
    "        \n",
    "        nav_path = None\n",
    "        if loaded_data['nav_content']:\n",
    "            nav_path = os.path.join(temp_dir, loaded_data['nav_filename'])\n",
    "            with open(nav_path, 'wb') as f:\n",
    "                f.write(loaded_data['nav_content'])\n",
    "        \n",
    "        progress.value = 0.3\n",
    "        \n",
    "        # Try Rust library\n",
    "        try:\n",
    "            import geoveil_cn0 as gcn0\n",
    "            print(f\"\\nü¶Ä Using geoveil_cn0 v{gcn0.VERSION}\")\n",
    "            \n",
    "            status.value = \"<b>Status:</b> <span style='color:blue'>‚è≥ Running Rust analysis...</span>\"\n",
    "            \n",
    "            # Create config with preset-based parameters\n",
    "            config = gcn0.AnalysisConfig(\n",
    "                min_elevation=elev_cutoff,\n",
    "                time_bin=int(time_bin),\n",
    "                detect_anomalies=True,\n",
    "                anomaly_sensitivity=preset_cfg['sensitivity'],\n",
    "                interference_threshold_db=preset_cfg['threshold'],\n",
    "                verbose=True,\n",
    "                nav_file=nav_path if nav_path else None,\n",
    "            )\n",
    "            \n",
    "            analyzer = gcn0.CN0Analyzer(config)\n",
    "            \n",
    "            if nav_path:\n",
    "                print(f\"   Using navigation: {os.path.basename(nav_path)}\")\n",
    "                result = analyzer.analyze_with_nav(obs_path, nav_path)\n",
    "            else:\n",
    "                result = analyzer.analyze_file(obs_path)\n",
    "            \n",
    "            progress.value = 0.8\n",
    "            \n",
    "            # Display results with preset mode\n",
    "            display_rust_results(result, preset, preset_cfg)\n",
    "            analysis_results['data'] = result\n",
    "            export_btn.disabled = False\n",
    "            \n",
    "        except ImportError as e:\n",
    "            print(f\"\\n‚ö†Ô∏è Rust library not available: {e}\")\n",
    "            print(\"   Install with: pip install ./geoveil-cn0\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Analysis error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        progress.value = 1.0\n",
    "        status.value = \"<b>Status:</b> <span style='color:green'>‚úì Analysis complete</span>\"\n",
    "        analyze_btn.disabled = False\n",
    "\n",
    "\n",
    "def display_rust_results(result, preset='full', preset_cfg=None):\n",
    "    \"\"\"Display results with preset-specific output\"\"\"\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import numpy as np\n",
    "    import pandas as pd  # For robust timestamp parsing\n",
    "    \n",
    "    if preset_cfg is None:\n",
    "        preset_cfg = PRESET_CONFIGS.get(preset, PRESET_CONFIGS['full'])\n",
    "    \n",
    "    quick_mode = preset_cfg.get('skip_heavy_plots', False)\n",
    "    \n",
    "    figures = {}\n",
    "    report_lines = []\n",
    "    const_data = []\n",
    "    \n",
    "    # Get anomalies\n",
    "    try:\n",
    "        anomalies = result.get_anomalies()\n",
    "    except:\n",
    "        anomalies = []\n",
    "    \n",
    "    def add_report(text):\n",
    "        report_lines.append(text)\n",
    "        print(text)\n",
    "    \n",
    "    add_report(\"\\n\" + \"=\"*70)\n",
    "    add_report(\"üìä CN0 ANALYSIS RESULTS\")\n",
    "    add_report(\"=\"*70)\n",
    "    \n",
    "    # File info\n",
    "    add_report(f\"\\nüìÅ File: {result.filename}\")\n",
    "    add_report(f\"   RINEX Version: {result.rinex_version}\")\n",
    "    add_report(f\"   Duration: {result.duration_hours:.2f} hours ({result.epoch_count} epochs)\")\n",
    "    if result.station_name:\n",
    "        add_report(f\"   Station: {result.station_name}\")\n",
    "    add_report(f\"   Constellations: {', '.join(result.constellations)}\")\n",
    "    \n",
    "    # Quality Score\n",
    "    qs = result.quality_score\n",
    "    \n",
    "    # === CALCULATE LOCK INTEGRITY ===\n",
    "    total_cycle_slips = 0\n",
    "    total_data_gaps = 0\n",
    "    total_satellites = 0\n",
    "    \n",
    "    for const_name in result.constellations:\n",
    "        cs = result.get_constellation_summary(const_name)\n",
    "        if cs:\n",
    "            total_cycle_slips += int(cs.get('cycle_slips', 0))\n",
    "            total_data_gaps += int(cs.get('data_gaps', 0))\n",
    "            total_satellites += int(cs.get('satellites_observed', cs.get('satellite_count', 0)))\n",
    "    \n",
    "    duration_hours = max(result.duration_hours, 0.01)\n",
    "    slips_per_hour = total_cycle_slips / duration_hours\n",
    "    gaps_per_hour = total_data_gaps / duration_hours\n",
    "    \n",
    "    if total_satellites > 0:\n",
    "        slips_per_sat_hour = slips_per_hour / total_satellites\n",
    "        gaps_per_sat_hour = gaps_per_hour / total_satellites\n",
    "        slip_score = max(0, min(100, 100 - (slips_per_sat_hour * 50)))\n",
    "        gap_score = max(0, min(100, 100 - (gaps_per_sat_hour * 25)))\n",
    "        lock_integrity_score = (slip_score * 0.6 + gap_score * 0.4)\n",
    "    else:\n",
    "        lock_integrity_score = 0\n",
    "        slips_per_sat_hour = 0\n",
    "    \n",
    "    add_report(f\"\\nüèÜ QUALITY SCORE: {qs.overall:.0f}/100 ({qs.rating})\")\n",
    "    add_report(f\"   CN0 Quality:   {qs.cn0_quality:.0f}\")\n",
    "    add_report(f\"   Availability:  {qs.availability:.0f}\")\n",
    "    add_report(f\"   Continuity:    {qs.continuity:.0f}\")\n",
    "    add_report(f\"   Stability:     {qs.stability:.0f}\")\n",
    "    add_report(f\"   Diversity:     {qs.diversity:.0f}\")\n",
    "    add_report(f\"   Lock Integrity: {lock_integrity_score:.0f}\")\n",
    "    \n",
    "    # Signal quality\n",
    "    add_report(f\"\\nüì∂ SIGNAL QUALITY:\")\n",
    "    add_report(f\"   Average CN0: {result.avg_cn0:.1f} dB-Hz\")\n",
    "    add_report(f\"   Std Dev: {result.cn0_std_dev:.1f} dB-Hz\")\n",
    "    add_report(f\"   Range: {result.min_cn0:.1f} - {result.max_cn0:.1f} dB-Hz\")\n",
    "    \n",
    "    # Lock Loss\n",
    "    add_report(f\"\\nüîì LOCK INTEGRITY:\")\n",
    "    add_report(f\"   Cycle Slips: {total_cycle_slips} ({slips_per_hour:.1f}/hour)\")\n",
    "    add_report(f\"   Data Gaps: {total_data_gaps} ({gaps_per_hour:.1f}/hour)\")\n",
    "    add_report(f\"   Score: {lock_integrity_score:.0f}/100\")\n",
    "    \n",
    "    # === PLOT 1: Quality Score Radar (with Lock Integrity) ===\n",
    "    try:\n",
    "        categories = ['CN0 Quality', 'Availability', 'Continuity', 'Stability', 'Diversity', 'Lock Integrity']\n",
    "        values = [qs.cn0_quality, qs.availability, qs.continuity, qs.stability, qs.diversity, lock_integrity_score]\n",
    "        values.append(values[0])  # Close polygon\n",
    "        categories.append(categories[0])\n",
    "        \n",
    "        fig_radar = go.Figure()\n",
    "        fig_radar.add_trace(go.Scatterpolar(\n",
    "            r=values,\n",
    "            theta=categories,\n",
    "            fill='toself',\n",
    "            fillcolor='rgba(99, 110, 250, 0.3)',\n",
    "            line=dict(color='rgb(99, 110, 250)', width=2),\n",
    "            name=f'Score: {qs.overall:.0f}'\n",
    "        ))\n",
    "        fig_radar.update_layout(\n",
    "            polar=dict(radialaxis=dict(visible=True, range=[0, 100])),\n",
    "            title=f\"Quality Score: {qs.overall:.0f}/100 ({qs.rating})\",\n",
    "            showlegend=True,\n",
    "            height=450\n",
    "        )\n",
    "        figures['quality_radar'] = fig_radar\n",
    "        print(\"\\nüìä Quality Score Radar:\")\n",
    "        fig_radar.show()\n",
    "    except Exception as e:\n",
    "        print(f\"   (Radar chart error: {e})\")\n",
    "    \n",
    "    # Constellation summaries\n",
    "    add_report(\"\\nüõ∞Ô∏è CONSTELLATION SUMMARY:\")\n",
    "    sys_names = {'GPS': 'GPS', 'GLONASS': 'GLONASS', 'Galileo': 'Galileo', \n",
    "                 'BeiDou': 'BeiDou', 'QZSS': 'QZSS', 'IRNSS': 'NavIC'}\n",
    "    sys_colors = {'GPS': '#1f77b4', 'GLONASS': '#ff7f0e', 'Galileo': '#2ca02c', \n",
    "                  'BeiDou': '#d62728', 'QZSS': '#9467bd', 'IRNSS': '#8c564b'}\n",
    "    \n",
    "    for const_name in result.constellations:\n",
    "        cs = result.get_constellation_summary(const_name)\n",
    "        if cs:\n",
    "            name = sys_names.get(const_name, const_name)\n",
    "            slips_ph = int(cs['cycle_slips']) / max(result.duration_hours, 0.01)\n",
    "            add_report(f\"\\n   {name} ({cs['constellation']}):\")\n",
    "            add_report(f\"      Satellites: {cs['satellites_observed']}/{cs['satellites_expected']}\")\n",
    "            add_report(f\"      CN0: {cs['cn0_mean']} ¬± {cs['cn0_std']} dB-Hz\")\n",
    "            add_report(f\"      Cycle Slips: {cs['cycle_slips']} ({slips_ph:.2f}/hour)\")\n",
    "            const_data.append({\n",
    "                'name': name, 'code': cs['constellation'],\n",
    "                'sats': int(cs['satellites_observed']), 'expected': int(cs['satellites_expected']),\n",
    "                'cn0_mean': float(cs['cn0_mean']), 'cn0_std': float(cs['cn0_std']),\n",
    "                'slips': int(cs['cycle_slips']), 'gaps': int(cs['data_gaps']),\n",
    "                'availability': float(cs['availability_ratio'])\n",
    "            })\n",
    "    \n",
    "    # === PLOT 2: Constellation Bar Chart ===\n",
    "    if const_data:\n",
    "        try:\n",
    "            fig_const = make_subplots(rows=1, cols=2, \n",
    "                                       subplot_titles=('Mean CN0 by Constellation', 'Satellite Count'))\n",
    "            \n",
    "            names = [d['name'] for d in const_data]\n",
    "            colors = [sys_colors.get(d['name'], '#999') for d in const_data]\n",
    "            \n",
    "            fig_const.add_trace(go.Bar(\n",
    "                x=names, y=[d['cn0_mean'] for d in const_data],\n",
    "                error_y=dict(type='data', array=[d['cn0_std'] for d in const_data]),\n",
    "                marker_color=colors, name='CN0',\n",
    "                text=[f\"{d['cn0_mean']:.1f}\" for d in const_data],\n",
    "                textposition='outside'\n",
    "            ), row=1, col=1)\n",
    "            \n",
    "            fig_const.add_trace(go.Bar(\n",
    "                x=names, y=[d['sats'] for d in const_data],\n",
    "                marker_color=colors, name='Observed',\n",
    "            ), row=1, col=2)\n",
    "            \n",
    "            fig_const.add_hline(y=35, line_dash=\"dash\", line_color=\"orange\", row=1, col=1)\n",
    "            fig_const.add_hline(y=25, line_dash=\"dash\", line_color=\"red\", row=1, col=1)\n",
    "            \n",
    "            fig_const.update_layout(height=400, title=\"Constellation Overview\", showlegend=False)\n",
    "            figures['constellation_overview'] = fig_const\n",
    "            print(\"\\nüìä Constellation Overview:\")\n",
    "            fig_const.show()\n",
    "        except Exception as e:\n",
    "            print(f\"   (Constellation chart error: {e})\")\n",
    "    \n",
    "    # === PLOT 3: CN0 Timeseries ===\n",
    "    try:\n",
    "        ts_data = result.get_timeseries_data()\n",
    "        if ts_data and len(ts_data.get('timestamps', [])) > 0:\n",
    "            fig_ts = make_subplots(rows=2, cols=1, shared_xaxes=True,\n",
    "                                    subplot_titles=('Mean CN0 Over Time', 'Satellite Count'),\n",
    "                                    vertical_spacing=0.1)\n",
    "            \n",
    "            timestamps = ts_data['timestamps']\n",
    "            cn0_values = ts_data['cn0_mean']\n",
    "            sat_counts = ts_data.get('satellite_counts', [])\n",
    "            \n",
    "            fig_ts.add_trace(go.Scatter(\n",
    "                x=timestamps, y=cn0_values,\n",
    "                mode='lines', name='Mean CN0',\n",
    "                line=dict(color='blue', width=1.5),\n",
    "                fill='tozeroy', fillcolor='rgba(0,100,255,0.1)'\n",
    "            ), row=1, col=1)\n",
    "            \n",
    "            fig_ts.add_hline(y=35, line_dash=\"dash\", line_color=\"orange\", row=1, col=1)\n",
    "            fig_ts.add_hline(y=25, line_dash=\"dash\", line_color=\"red\", row=1, col=1)\n",
    "            \n",
    "            if sat_counts and len(sat_counts) == len(timestamps):\n",
    "                fig_ts.add_trace(go.Scatter(\n",
    "                    x=timestamps, y=sat_counts,\n",
    "                    mode='lines', name='Satellites',\n",
    "                    line=dict(color='green', width=1.5),\n",
    "                ), row=2, col=1)\n",
    "            \n",
    "            fig_ts.update_layout(height=500, title='CN0 Timeseries', showlegend=True)\n",
    "            figures['timeseries'] = fig_ts\n",
    "            print(\"\\nüìä CN0 Timeseries:\")\n",
    "            fig_ts.show()\n",
    "    except Exception as e:\n",
    "        print(f\"   (Timeseries chart error: {e})\")\n",
    "    \n",
    "    # === PLOT 4: CN0 Heatmap (skip in quick mode) ===\n",
    "    if quick_mode:\n",
    "        print(\"\\nüìä CN0 Heatmap: Skipped (quick mode)\")\n",
    "    else:\n",
    "        try:\n",
    "            result_json = json.loads(result.to_json())\n",
    "            sat_timeseries = result_json.get('timeseries', {}).get('satellite_timeseries', {})\n",
    "            \n",
    "            if sat_timeseries and len(sat_timeseries) > 0:\n",
    "                all_times = set()\n",
    "                for sat_id, sat_data in sat_timeseries.items():\n",
    "                    if isinstance(sat_data, dict):\n",
    "                        series = sat_data.get('cn0_series', sat_data.get('series', []))\n",
    "                        if isinstance(series, list):\n",
    "                            for point in series:\n",
    "                                if isinstance(point, dict):\n",
    "                                    all_times.add(point.get('timestamp', point.get('time', '')))\n",
    "                \n",
    "                all_times = sorted([t for t in all_times if t])\n",
    "                \n",
    "                if all_times:\n",
    "                    max_time_points = 400\n",
    "                    if len(all_times) > max_time_points:\n",
    "                        step = len(all_times) // max_time_points\n",
    "                        all_times = all_times[::step]\n",
    "                    \n",
    "                    def sat_sort_key(s):\n",
    "                        if len(s) >= 2:\n",
    "                            sys = s[0]\n",
    "                            try:\n",
    "                                prn = int(s[1:])\n",
    "                            except:\n",
    "                                prn = 0\n",
    "                            sys_order = {'G': 0, 'R': 1, 'E': 2, 'C': 3}\n",
    "                            return (sys_order.get(sys, 9), prn)\n",
    "                        return (9, 0)\n",
    "                    \n",
    "                    all_satellites = sorted(sat_timeseries.keys(), key=sat_sort_key, reverse=True)\n",
    "                    \n",
    "                    z_matrix = []\n",
    "                    sat_labels = []\n",
    "                    \n",
    "                    for sat in all_satellites:\n",
    "                        sat_data = sat_timeseries.get(sat, {})\n",
    "                        if isinstance(sat_data, dict):\n",
    "                            cn0_series = sat_data.get('cn0_series', sat_data.get('series', []))\n",
    "                        else:\n",
    "                            continue\n",
    "                        \n",
    "                        cn0_by_time = {}\n",
    "                        if isinstance(cn0_series, list):\n",
    "                            for p in cn0_series:\n",
    "                                if isinstance(p, dict):\n",
    "                                    t = p.get('timestamp', p.get('time', ''))\n",
    "                                    v = p.get('value', p.get('cn0', None))\n",
    "                                    if t and v is not None:\n",
    "                                        cn0_by_time[t] = v\n",
    "                        \n",
    "                        row = [cn0_by_time.get(t, None) for t in all_times]\n",
    "                        valid_count = sum(1 for v in row if v is not None)\n",
    "                        if valid_count > len(all_times) * 0.05:\n",
    "                            z_matrix.append(row)\n",
    "                            sat_labels.append(sat)\n",
    "                    \n",
    "                    if z_matrix:\n",
    "                        time_labels = pd.to_datetime(all_times)\n",
    "                        \n",
    "                        fig_heat = go.Figure(data=go.Heatmap(\n",
    "                            z=z_matrix,\n",
    "                            x=time_labels,\n",
    "                            y=sat_labels,\n",
    "                            colorscale='Viridis',\n",
    "                            zmin=25, zmax=55,\n",
    "                            colorbar=dict(title='C/N‚ÇÄ<br>(dB-Hz)'),\n",
    "                            hoverongaps=False,\n",
    "                        ))\n",
    "                        \n",
    "                        fig_heat.update_layout(\n",
    "                            title=f\"C/N‚ÇÄ Heatmap - Time vs Satellite\",\n",
    "                            xaxis_title=\"Time\",\n",
    "                            yaxis_title=\"Satellite PRN\",\n",
    "                            height=max(400, len(sat_labels) * 18),\n",
    "                            width=1100,\n",
    "                        )\n",
    "                        \n",
    "                        figures['cn0_heatmap'] = fig_heat\n",
    "                        print(f\"\\nüìä C/N‚ÇÄ Heatmap ({len(sat_labels)} satellites):\")\n",
    "                        fig_heat.show()\n",
    "        except Exception as e:\n",
    "            print(f\"   (Heatmap error: {e})\")\n",
    "    \n",
    "    # === PLOT 5: Per-Constellation Timeseries (skip in quick mode) ===\n",
    "    if quick_mode:\n",
    "        print(\"\\nüìä Per-Constellation Timeseries: Skipped (quick mode)\")\n",
    "    else:\n",
    "        try:\n",
    "            result_json = json.loads(result.to_json())\n",
    "            sat_timeseries = result_json.get('timeseries', {}).get('satellite_timeseries', {})\n",
    "            \n",
    "            if sat_timeseries:\n",
    "                by_constellation = {}\n",
    "                sys_code_map = {'G': 'GPS', 'R': 'GLONASS', 'E': 'Galileo', 'C': 'BeiDou'}\n",
    "                \n",
    "                for sat_id, sat_data in sat_timeseries.items():\n",
    "                    const = sat_id[0]\n",
    "                    const_name = sys_code_map.get(const, const)\n",
    "                    if const_name not in by_constellation:\n",
    "                        by_constellation[const_name] = {}\n",
    "                    by_constellation[const_name][sat_id] = sat_data\n",
    "                \n",
    "                sat_colors = ['#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A',\n",
    "                             '#19D3F3', '#FF6692', '#B6E880', '#FF97FF', '#FECB52']\n",
    "                \n",
    "                for const_name, satellites in by_constellation.items():\n",
    "                    if not satellites:\n",
    "                        continue\n",
    "                    \n",
    "                    fig_const_ts = go.Figure()\n",
    "                    \n",
    "                    for i, (sat_id, sat_data) in enumerate(sorted(satellites.items())):\n",
    "                        cn0_series = sat_data.get('cn0_series', sat_data.get('series', []))\n",
    "                        if not cn0_series:\n",
    "                            continue\n",
    "                        \n",
    "                        times = [p.get('timestamp', p.get('time', '')) for p in cn0_series if isinstance(p, dict)]\n",
    "                        values = [p.get('value', p.get('cn0', 0)) for p in cn0_series if isinstance(p, dict)]\n",
    "                        \n",
    "                        if times and values:\n",
    "                            fig_const_ts.add_trace(go.Scatter(\n",
    "                                x=pd.to_datetime(times),\n",
    "                                y=values,\n",
    "                                mode='lines',\n",
    "                                name=sat_id,\n",
    "                                line=dict(width=1.2, color=sat_colors[i % len(sat_colors)]),\n",
    "                            ))\n",
    "                    \n",
    "                    fig_const_ts.add_hline(y=35, line_dash=\"dash\", line_color=\"orange\")\n",
    "                    fig_const_ts.add_hline(y=25, line_dash=\"dash\", line_color=\"red\")\n",
    "                    \n",
    "                    fig_const_ts.update_layout(\n",
    "                        title=f\"üì° {const_name} - C/N‚ÇÄ by Satellite\",\n",
    "                        xaxis_title=\"Time (UTC)\",\n",
    "                        yaxis_title=\"C/N‚ÇÄ (dB-Hz)\",\n",
    "                        height=450,\n",
    "                        yaxis=dict(range=[20, 60]),\n",
    "                        legend=dict(orientation='h', y=1.02, font=dict(size=9)),\n",
    "                    )\n",
    "                    \n",
    "                    figures[f'timeseries_{const_name.lower()}'] = fig_const_ts\n",
    "                    print(f\"\\nüìä {const_name} Timeseries ({len(satellites)} satellites):\")\n",
    "                    fig_const_ts.show()\n",
    "        except Exception as e:\n",
    "            print(f\"   (Per-constellation timeseries error: {e})\")\n",
    "    \n",
    "    # === PLOT 6: Skyplot ===\n",
    "    try:\n",
    "        skyplot_data = result.get_skyplot_data()\n",
    "        if skyplot_data:\n",
    "            traces = skyplot_data if isinstance(skyplot_data, list) else skyplot_data.get('traces', [])\n",
    "            \n",
    "            if traces:\n",
    "                fig_sky = go.Figure()\n",
    "                \n",
    "                for trace in traces:\n",
    "                    if not isinstance(trace, dict):\n",
    "                        continue\n",
    "                    \n",
    "                    sat_id = trace.get('name', trace.get('satellite', ''))\n",
    "                    \n",
    "                    # Parse CSV strings\n",
    "                    def parse_csv(value):\n",
    "                        if isinstance(value, list):\n",
    "                            return [float(v) for v in value if v is not None]\n",
    "                        if isinstance(value, str):\n",
    "                            return [float(v.strip()) for v in value.split(',') if v.strip()]\n",
    "                        return []\n",
    "                    \n",
    "                    elevations = parse_csv(trace.get('elevations', trace.get('elevation', [])))\n",
    "                    azimuths = parse_csv(trace.get('azimuths', trace.get('azimuth', [])))\n",
    "                    cn0_vals = parse_csv(trace.get('cn0_values', trace.get('cn0', [])))\n",
    "                    \n",
    "                    if elevations and azimuths:\n",
    "                        r_vals = [90.0 - el for el in elevations]\n",
    "                        min_len = min(len(r_vals), len(azimuths))\n",
    "                        cn0_list = cn0_vals[:min_len] if cn0_vals else [40.0] * min_len\n",
    "                        \n",
    "                        fig_sky.add_trace(go.Scatterpolar(\n",
    "                            r=r_vals[:min_len],\n",
    "                            theta=azimuths[:min_len],\n",
    "                            mode='markers+lines',\n",
    "                            marker=dict(\n",
    "                                size=6,\n",
    "                                color=cn0_list,\n",
    "                                colorscale='RdYlGn',\n",
    "                                cmin=25, cmax=55,\n",
    "                            ),\n",
    "                            line=dict(width=1.5),\n",
    "                            name=str(sat_id),\n",
    "                        ))\n",
    "                \n",
    "                fig_sky.update_layout(\n",
    "                    polar=dict(\n",
    "                        radialaxis=dict(visible=True, range=[90, 0],\n",
    "                                       tickvals=[0, 30, 60, 90],\n",
    "                                       ticktext=['90¬∞', '60¬∞', '30¬∞', '0¬∞']),\n",
    "                        angularaxis=dict(direction='clockwise', rotation=90,\n",
    "                                        tickvals=[0, 90, 180, 270],\n",
    "                                        ticktext=['N', 'E', 'S', 'W'])\n",
    "                    ),\n",
    "                    title=\"üõ∞Ô∏è Skyplot (Color = CN0)\",\n",
    "                    showlegend=False,\n",
    "                    height=550,\n",
    "                    width=600\n",
    "                )\n",
    "                \n",
    "                figures['skyplot'] = fig_sky\n",
    "                print(f\"\\nüìä Skyplot ({len(traces)} satellites):\")\n",
    "                fig_sky.show()\n",
    "    except Exception as e:\n",
    "        print(f\"   (Skyplot error: {e})\")\n",
    "    \n",
    "    # === PLOT 7: Anomaly Timeline (FIXED with pd.to_datetime) ===\n",
    "    if anomalies:\n",
    "        add_report(f\"\\n‚ö†Ô∏è ANOMALIES DETECTED: {len(anomalies)}\")\n",
    "        \n",
    "        try:\n",
    "            fig_anom = go.Figure()\n",
    "            \n",
    "            # Case-insensitive severity colors\n",
    "            severity_colors = {\n",
    "                'critical': '#ef4444', 'high': '#f97316',\n",
    "                'medium': '#eab308', 'low': '#22c55e'\n",
    "            }\n",
    "            \n",
    "            # Parse anomalies using pd.to_datetime (robust!)\n",
    "            valid_anomalies = []\n",
    "            for a in anomalies[:500]:\n",
    "                try:\n",
    "                    ts_str = a.get('start_time') or a.get('timestamp') or ''\n",
    "                    if ts_str:\n",
    "                        # Use pandas for robust parsing\n",
    "                        ts = pd.to_datetime(ts_str, errors='coerce')\n",
    "                        if pd.notna(ts):\n",
    "                            valid_anomalies.append({\n",
    "                                'time': ts,\n",
    "                                'severity': str(a.get('severity', 'low')).lower(),\n",
    "                                'cn0_drop': float(a.get('cn0_drop', a.get('cn0_drop_db', 0)) or 0),\n",
    "                                'type': a.get('anomaly_type', a.get('type', 'Unknown')),\n",
    "                                'description': a.get('description', ''),\n",
    "                                'confidence': float(a.get('confidence', 0.5) or 0.5),\n",
    "                            })\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if valid_anomalies:\n",
    "                for severity in ['critical', 'high', 'medium', 'low']:\n",
    "                    sev_data = [d for d in valid_anomalies if d['severity'] == severity]\n",
    "                    if sev_data:\n",
    "                        fig_anom.add_trace(go.Scatter(\n",
    "                            x=[d['time'] for d in sev_data],\n",
    "                            y=[d['cn0_drop'] for d in sev_data],\n",
    "                            mode='markers',\n",
    "                            marker=dict(\n",
    "                                size=[8 + d['confidence'] * 10 for d in sev_data],\n",
    "                                color=severity_colors.get(severity, '#888'),\n",
    "                                opacity=0.7,\n",
    "                            ),\n",
    "                            name=f\"{severity.capitalize()} ({len(sev_data)})\",\n",
    "                            text=[f\"{d['type']}<br>{d['description']}\" for d in sev_data],\n",
    "                            hovertemplate=\"Time: %{x}<br>CN0 Drop: %{y:.1f} dB<br>%{text}<extra></extra>\"\n",
    "                        ))\n",
    "                \n",
    "                # Add threshold lines based on preset\n",
    "                if preset == 'jamming':\n",
    "                    fig_anom.add_hline(y=6.0, line_dash=\"dash\", line_color=\"red\",\n",
    "                                      annotation_text=\"Jamming (6 dB)\")\n",
    "                elif preset == 'interference':\n",
    "                    fig_anom.add_hline(y=4.0, line_dash=\"dash\", line_color=\"orange\",\n",
    "                                      annotation_text=\"Interference (4 dB)\")\n",
    "                \n",
    "                fig_anom.update_layout(\n",
    "                    title=f\"‚ö†Ô∏è Anomaly Timeline ({len(valid_anomalies)} events)\",\n",
    "                    xaxis_title=\"Time (UTC)\",\n",
    "                    xaxis=dict(type='date'),\n",
    "                    yaxis_title=\"CN0 Drop (dB)\",\n",
    "                    height=450,\n",
    "                    legend=dict(orientation='h', y=1.1)\n",
    "                )\n",
    "                figures['anomalies'] = fig_anom\n",
    "                print(f\"\\nüìä Anomaly Timeline ({len(valid_anomalies)} events):\")\n",
    "                fig_anom.show()\n",
    "                \n",
    "                # === PRESET-SPECIFIC ANALYSIS ===\n",
    "                if preset == 'jamming':\n",
    "                    jamming_events = [a for a in valid_anomalies if a['cn0_drop'] >= 6.0]\n",
    "                    print(f\"\\nüéØ JAMMING ANALYSIS:\")\n",
    "                    print(f\"   Events with >6 dB drop: {len(jamming_events)}\")\n",
    "                    if jamming_events:\n",
    "                        max_drop = max(a['cn0_drop'] for a in jamming_events)\n",
    "                        print(f\"   Maximum CN0 drop: {max_drop:.1f} dB\")\n",
    "                        if max_drop >= 10:\n",
    "                            print(f\"   ‚ö†Ô∏è SEVERE JAMMING detected (>10 dB drop)\")\n",
    "                \n",
    "                elif preset == 'spoofing':\n",
    "                    print(f\"\\nüõ°Ô∏è SPOOFING ANALYSIS:\")\n",
    "                    if result.cn0_std_dev < 2.0:\n",
    "                        print(f\"   ‚ö†Ô∏è CN0 variance LOW ({result.cn0_std_dev:.2f} dB) - possible spoofing\")\n",
    "                    else:\n",
    "                        print(f\"   ‚úÖ CN0 variance normal ({result.cn0_std_dev:.2f} dB)\")\n",
    "                    if result.avg_cn0 > 50:\n",
    "                        print(f\"   ‚ö†Ô∏è Average CN0 elevated ({result.avg_cn0:.1f} dB-Hz) - possible high-power spoofing\")\n",
    "                \n",
    "                elif preset == 'interference':\n",
    "                    print(f\"\\nüìä INTERFERENCE ANALYSIS:\")\n",
    "                    subtle = [a for a in valid_anomalies if 4.0 <= a['cn0_drop'] < 6.0]\n",
    "                    moderate = [a for a in valid_anomalies if a['cn0_drop'] >= 6.0]\n",
    "                    print(f\"   Subtle interference (4-6 dB): {len(subtle)}\")\n",
    "                    print(f\"   Moderate/severe (‚â•6 dB): {len(moderate)}\")\n",
    "            else:\n",
    "                print(f\"\\n‚ö†Ô∏è {len(anomalies)} anomalies but could not parse timestamps\")\n",
    "        except Exception as e:\n",
    "            print(f\"   (Anomaly chart error: {e})\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        add_report(\"\\n‚úÖ No anomalies detected\")\n",
    "    \n",
    "    print(f\"\\nüõ°Ô∏è THREAT ASSESSMENT:\")\n",
    "    \n",
    "    # === IMPROVED THREAT DETECTION ===\n",
    "    # Don't blindly trust the library's spoofing flag - it has false positives\n",
    "    # When ephemeris doesn't cover all satellites (especially BeiDou), it triggers falsely\n",
    "    \n",
    "    # Jamming: Only if low CN0 + library flag\n",
    "    jamming_detected = result.jamming_detected and result.mean_cn0 < 35.0\n",
    "    \n",
    "    # Spoofing: Check per-constellation std to avoid false positives from incomplete ephemeris\n",
    "    constellation_stds = []\n",
    "    for sys_name in ['GPS', 'GLONASS', 'Galileo', 'BeiDou']:\n",
    "        stats = result.get_constellation_summary(sys_name)\n",
    "        if stats:\n",
    "            try:\n",
    "                std_cn0 = float(stats.get('std_cn0', stats.get('cn0_std', 5.0)))\n",
    "                constellation_stds.append(std_cn0)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    avg_constellation_std = sum(constellation_stds) / len(constellation_stds) if constellation_stds else 5.0\n",
    "    \n",
    "    # Real spoofing indicators:\n",
    "    # 1. Very low CN0 std across constellations (< 2 dB) - signals too uniform\n",
    "    # 2. AND elevated average CN0 (> 50 dB-Hz) - spoofer typically overpowers\n",
    "    # 3. AND overall std also low\n",
    "    spoofing_indicators = []\n",
    "    if avg_constellation_std < 2.0:\n",
    "        spoofing_indicators.append(\"CN0 uniformity suspiciously low\")\n",
    "    if result.mean_cn0 > 50.0:\n",
    "        spoofing_indicators.append(\"CN0 elevated (possible high-power signal)\")\n",
    "    if result.cn0_std_dev < 1.0:\n",
    "        spoofing_indicators.append(\"Overall signal variance very low\")\n",
    "    \n",
    "    # Only flag spoofing if multiple indicators present\n",
    "    spoofing_suspicious = len(spoofing_indicators) >= 2\n",
    "    \n",
    "    # If library says spoofing but our checks don't agree, it's likely false positive\n",
    "    if result.spoofing_detected and not spoofing_suspicious:\n",
    "        print(f\"   Jamming:      {'üö® DETECTED' if jamming_detected else '‚úÖ None'}\")\n",
    "        print(f\"   Spoofing:     ‚ö†Ô∏è Flag raised (likely false positive - incomplete ephemeris)\")\n",
    "        print(f\"   Interference: {'‚ö†Ô∏è Detected' if result.interference_detected else '‚úÖ None'}\")\n",
    "    else:\n",
    "        print(f\"   Jamming:      {'üö® DETECTED' if jamming_detected else '‚úÖ None'}\")\n",
    "        print(f\"   Spoofing:     {'üö® DETECTED' if spoofing_suspicious else '‚úÖ None'}\")\n",
    "        print(f\"   Interference: {'‚ö†Ô∏è Detected' if result.interference_detected else '‚úÖ None'}\")\n",
    "    \n",
    "    if spoofing_indicators and spoofing_suspicious:\n",
    "        print(f\"   ‚îî‚îÄ Indicators: {', '.join(spoofing_indicators)}\")\n",
    "    \n",
    "    # === GENERATE PROPER SUMMARY BASED ON DISPLAYED SCORE ===\n",
    "    # Don't use result.summary - it's based on internal score with different weights\n",
    "    overall_score = qs.overall\n",
    "    \n",
    "    if overall_score >= 90:\n",
    "        quality_text = \"Excellent GNSS signal quality\"\n",
    "    elif overall_score >= 80:\n",
    "        quality_text = \"Good GNSS signal quality\"\n",
    "    elif overall_score >= 70:\n",
    "        quality_text = \"Fair GNSS signal quality\"\n",
    "    elif overall_score >= 60:\n",
    "        quality_text = \"Degraded GNSS signal quality\"\n",
    "    else:\n",
    "        quality_text = \"Poor GNSS signal quality\"\n",
    "    \n",
    "    # Add warnings if needed\n",
    "    warnings = []\n",
    "    if jamming_detected:\n",
    "        warnings.append(\"jamming detected\")\n",
    "    if spoofing_suspicious:\n",
    "        warnings.append(\"spoofing indicators present\")\n",
    "    if result.interference_detected:\n",
    "        warnings.append(\"interference events detected\")\n",
    "    if lock_integrity_score < 50:\n",
    "        warnings.append(\"significant lock loss issues\")\n",
    "    \n",
    "    if warnings:\n",
    "        summary_text = f\"{quality_text} - WARNING: {', '.join(warnings)}\"\n",
    "    else:\n",
    "        summary_text = quality_text\n",
    "    \n",
    "    print(f\"\\nüìù {summary_text}\")\n",
    "    \n",
    "    # === ANALYSIS CONCLUSION ===\n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    print(f\"üìã CONCLUSION:\")\n",
    "    print(f\"=\" * 70)\n",
    "    \n",
    "    conclusions = []\n",
    "    \n",
    "    # Overall assessment\n",
    "    if overall_score >= 90:\n",
    "        conclusions.append(\"‚úÖ Data quality is EXCELLENT - suitable for high-precision applications (PPP/PPK)\")\n",
    "    elif overall_score >= 80:\n",
    "        conclusions.append(\"‚úÖ Data quality is GOOD - suitable for standard GNSS applications\")\n",
    "    elif overall_score >= 70:\n",
    "        conclusions.append(\"‚ö†Ô∏è Data quality is FAIR - usable but may have reduced accuracy\")\n",
    "    elif overall_score >= 60:\n",
    "        conclusions.append(\"‚ö†Ô∏è Data quality is DEGRADED - review anomalies before use\")\n",
    "    else:\n",
    "        conclusions.append(\"‚ùå Data quality is POOR - significant issues detected\")\n",
    "    \n",
    "    # Signal strength assessment\n",
    "    if result.mean_cn0 >= 45:\n",
    "        conclusions.append(f\"‚úÖ Signal strength EXCELLENT ({result.mean_cn0:.1f} dB-Hz average)\")\n",
    "    elif result.mean_cn0 >= 40:\n",
    "        conclusions.append(f\"‚úÖ Signal strength GOOD ({result.mean_cn0:.1f} dB-Hz average)\")\n",
    "    elif result.mean_cn0 >= 35:\n",
    "        conclusions.append(f\"‚ö†Ô∏è Signal strength MODERATE ({result.mean_cn0:.1f} dB-Hz average)\")\n",
    "    else:\n",
    "        conclusions.append(f\"‚ùå Signal strength LOW ({result.mean_cn0:.1f} dB-Hz) - possible interference\")\n",
    "    \n",
    "    # Lock integrity\n",
    "    if lock_integrity_score >= 80:\n",
    "        conclusions.append(\"‚úÖ Signal continuity is excellent (minimal lock losses)\")\n",
    "    elif lock_integrity_score >= 60:\n",
    "        conclusions.append(\"‚úÖ Signal continuity is acceptable\")\n",
    "    else:\n",
    "        conclusions.append(f\"‚ö†Ô∏è Signal continuity issues detected ({total_data_gaps} data gaps)\")\n",
    "    \n",
    "    # Threat summary\n",
    "    if not (jamming_detected or spoofing_suspicious or result.interference_detected):\n",
    "        conclusions.append(\"‚úÖ No significant threats detected\")\n",
    "    else:\n",
    "        if jamming_detected:\n",
    "            conclusions.append(\"üö® JAMMING DETECTED - data may be compromised\")\n",
    "        if spoofing_suspicious:\n",
    "            conclusions.append(\"üö® SPOOFING INDICATORS - verify data integrity\")\n",
    "        if result.interference_detected:\n",
    "            conclusions.append(\"‚ö†Ô∏è Interference events detected - review anomaly timeline\")\n",
    "    \n",
    "    # Post-processing recommendation\n",
    "    if overall_score >= 70 and result.mean_cn0 >= 35 and lock_integrity_score >= 50:\n",
    "        conclusions.append(\"‚úÖ Data suitable for post-processing (PPP/RTK)\")\n",
    "    else:\n",
    "        conclusions.append(\"‚ö†Ô∏è Review issues before post-processing\")\n",
    "    \n",
    "    for c in conclusions:\n",
    "        print(f\"   {c}\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    \n",
    "    # Overall assessment\n",
    "    add_report(\"\\n\" + \"-\"*70)\n",
    "    score = result.quality_score.overall\n",
    "    if score >= 80:\n",
    "        add_report(\"üìà ASSESSMENT: EXCELLENT - High quality data for precise positioning\")\n",
    "    elif score >= 60:\n",
    "        add_report(\"üìà ASSESSMENT: GOOD - Suitable for standard GNSS applications\")\n",
    "    elif score >= 40:\n",
    "        add_report(\"üìà ASSESSMENT: DEGRADED - Some issues detected, review anomalies\")\n",
    "    else:\n",
    "        add_report(\"üìà ASSESSMENT: POOR - Significant interference or equipment issues\")\n",
    "    \n",
    "    # Store for export\n",
    "    analysis_results['figures'] = figures\n",
    "    lock_integrity_data = {\n",
    "        'score': lock_integrity_score,\n",
    "        'total_cycle_slips': total_cycle_slips,\n",
    "        'total_data_gaps': total_data_gaps,\n",
    "        'slips_per_hour': slips_per_hour,\n",
    "    }\n",
    "    analysis_results['lock_integrity'] = lock_integrity_data\n",
    "    analysis_results['report_html'] = generate_html_report(result, const_data, anomalies, lock_integrity_data)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Generated {len(figures)} interactive plots\")\n",
    "\n",
    "\n",
    "def clear_all(btn):\n",
    "    \"\"\"Clear all data and outputs\"\"\"\n",
    "    loaded_data.update({\n",
    "        'obs_content': None, 'obs_filename': None, 'obs_path': None,\n",
    "        'nav_content': None, 'nav_filename': None, 'nav_path': None,\n",
    "    })\n",
    "    analysis_results['data'] = None\n",
    "    analysis_results['figures'] = {}\n",
    "    \n",
    "    with info_out:\n",
    "        clear_output()\n",
    "    with results_out:\n",
    "        clear_output()\n",
    "    \n",
    "    progress.value = 0\n",
    "    progress.layout.visibility = 'hidden'\n",
    "    export_btn.disabled = True\n",
    "    status.value = \"<b>Status:</b> Cleared\"\n",
    "\n",
    "\n",
    "def export_results(btn):\n",
    "    \"\"\"Export results as HTML report\"\"\"\n",
    "    if not analysis_results['data']:\n",
    "        with info_out:\n",
    "            print(\"‚ùå No analysis results to export!\")\n",
    "        return\n",
    "    \n",
    "    with info_out:\n",
    "        clear_output()\n",
    "        print(\"üì¶ Preparing export...\")\n",
    "        \n",
    "        import base64\n",
    "        \n",
    "        result = analysis_results['data']\n",
    "        html = analysis_results.get('report_html', '')\n",
    "        \n",
    "        if html:\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            filename = f\"cn0_report_{timestamp}.html\"\n",
    "            \n",
    "            b64 = base64.b64encode(html.encode()).decode()\n",
    "            \n",
    "            print(f\"‚úÖ Report ready: {filename}\")\n",
    "            \n",
    "            display(HTML(f'''\n",
    "            <div style=\"margin: 20px 0; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; text-align: center;\">\n",
    "                <a download=\"{filename}\" href=\"data:text/html;base64,{b64}\" \n",
    "                   style=\"display:inline-block;padding:15px 30px;background:white;\n",
    "                          color:#667eea;text-decoration:none;border-radius:8px;font-weight:bold;font-size:16px;\">\n",
    "                   üì• Download HTML Report ({len(html)//1024} KB)\n",
    "                </a>\n",
    "            </div>\n",
    "            '''))\n",
    "\n",
    "\n",
    "# Connect handlers\n",
    "load_btn.on_click(load_files)\n",
    "analyze_btn.on_click(run_analysis)\n",
    "clear_btn.on_click(clear_all)\n",
    "export_btn.on_click(export_results)\n",
    "\n",
    "# ============ LAYOUT ============\n",
    "layout = widgets.VBox([\n",
    "    header,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    \n",
    "    # Observation file section\n",
    "    obs_section,\n",
    "    widgets.HBox([obs_upload, widgets.HTML(\"&nbsp; OR &nbsp;\"), obs_path_input]),\n",
    "    \n",
    "    widgets.HTML(\"<br>\"),\n",
    "    \n",
    "    # Navigation file section  \n",
    "    nav_section,\n",
    "    widgets.HBox([nav_upload, widgets.HTML(\"&nbsp; OR &nbsp;\"), nav_path_input]),\n",
    "    auto_download_nav,\n",
    "    \n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    load_btn,\n",
    "    \n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    \n",
    "    # Configuration\n",
    "    config_section,\n",
    "    preset_dropdown,\n",
    "    preset_help,\n",
    "    elevation_slider,\n",
    "    time_bin_slider,\n",
    "    widgets.HBox(list(system_checks.values())),\n",
    "    \n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    \n",
    "    # Action buttons\n",
    "    widgets.HBox([analyze_btn, export_btn, clear_btn]),\n",
    "    progress,\n",
    "    status,\n",
    "    \n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    info_out,\n",
    "    results_out,\n",
    "])\n",
    "\n",
    "display(layout)\n",
    "print(\"‚úÖ CN0 Widget Ready with Presets\")\n",
    "print(\"   Presets: Full | Quick | Interference | Jamming | Spoofing\")\n",
    "print(\"   Features: Lock Integrity, Fixed Anomaly Graph, Research-based Thresholds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separated output - Modified Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17afb3b180ce409688a10ad8ebb8cc13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>üì° GeoVeil CN0 Analysis - GNSS Signal Quality</h3>'), HTML(value=‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Widget loaded - use buttons above to analyze GNSS data\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CN0 Analysis Widget - MODIFIED VERSION with Separate Output Buttons\n",
    "# =============================================================================\n",
    "# Replace your existing widget cell (Cell 21) with this code\n",
    "#\n",
    "# CHANGES:\n",
    "# - Removed single \"Run Analysis\" button\n",
    "# - Added 5 separate buttons for different outputs:\n",
    "#   1. üìä Summary & Score - Text info + Quality radar chart\n",
    "#   2. üó∫Ô∏è Heatmap - CN0 heatmap by azimuth/elevation AND time vs satellite\n",
    "#   3. üìà SNR Graphs - CN0 timeseries plots\n",
    "#   4. üõ∞Ô∏è Skyplot - Satellite skyplot\n",
    "#   5. ‚ö†Ô∏è Anomalies - Anomaly timeline\n",
    "# - Export runs full analysis silently and offers download\n",
    "# =============================================================================\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import os\n",
    "import gzip\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import urllib.request\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import geoveil_cn0 as gcn0\n",
    "\n",
    "# Storage for loaded data\n",
    "loaded_data = {\n",
    "    'obs_content': None,\n",
    "    'obs_filename': None,\n",
    "    'obs_path': None,\n",
    "    'nav_content': None,\n",
    "    'nav_filename': None,\n",
    "    'nav_path': None,\n",
    "}\n",
    "\n",
    "# Store analysis results\n",
    "analysis_results = {'data': None, 'figures': {}, 'report_html': ''}\n",
    "\n",
    "# ============ NAVIGATION DOWNLOADER ============\n",
    "class NavDownloader:\n",
    "    \"\"\"Minimal nav downloader for notebook use\"\"\"\n",
    "    \n",
    "    IGS_SERVERS = [\n",
    "        ('igs.bkg.bund.de', '/root_ftp/IGS/BRDC/{year}/{doy:03d}/{filename}', 'BKG'),\n",
    "        ('igs.ign.fr', '/pub/igs/data/{year}/{doy:03d}/{filename}', 'IGN'),\n",
    "    ]\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_rinex_date(filename):\n",
    "        \"\"\"Extract year, doy from RINEX filename\"\"\"\n",
    "        import re\n",
    "        try:\n",
    "            # RINEX 3/4 format: SSSSMMMMR_U_YYYYDDDHHMM_...\n",
    "            parts = [p for p in filename.split('_') if p]\n",
    "            if len(parts) >= 4 and len(parts[2]) >= 7:\n",
    "                ts = parts[2]\n",
    "                return int(ts[0:4]), int(ts[4:7])\n",
    "            \n",
    "            # RINEX 2 standard format: ssssdddf.yyt (e.g., bucu1520.25o)\n",
    "            # where ssss=station, ddd=doy, f=file seq, yy=year, t=type\n",
    "            match = re.match(r'^[a-zA-Z0-9]{4}(\\d{3})\\d?\\.(\\d{2})[oOnNmMgG]$', filename)\n",
    "            if match:\n",
    "                doy = int(match.group(1))\n",
    "                yr = int(match.group(2))\n",
    "                year = 2000 + yr if yr < 80 else 1900 + yr\n",
    "                return year, doy\n",
    "            \n",
    "            # Extended RINEX 2 format: ssssdddsss.yyo (e.g., 0000152157.25o)\n",
    "            # where ssss=station, ddd=doy, sss=sequence/extra, yy=year\n",
    "            match = re.match(r'^[a-zA-Z0-9]{4}(\\d{3})\\d*\\.(\\d{2})[oOnNmMgG]$', filename)\n",
    "            if match:\n",
    "                doy = int(match.group(1))\n",
    "                yr = int(match.group(2))\n",
    "                year = 2000 + yr if yr < 80 else 1900 + yr\n",
    "                return year, doy\n",
    "            \n",
    "            # Try to find any 3-digit DOY pattern after 4-char station\n",
    "            match = re.match(r'^.{4}(\\d{3}).*\\.(\\d{2})[oOnNgGmM]', filename)\n",
    "            if match:\n",
    "                doy = int(match.group(1))\n",
    "                yr = int(match.group(2))\n",
    "                year = 2000 + yr if yr < 80 else 1900 + yr\n",
    "                if 1 <= doy <= 366:  # Valid DOY range\n",
    "                    return year, doy\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   Date parse error: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_rinex_header(content):\n",
    "        \"\"\"Extract year, doy from RINEX file content header (more reliable)\"\"\"\n",
    "        from datetime import date\n",
    "        try:\n",
    "            # Handle bytes\n",
    "            if isinstance(content, bytes):\n",
    "                content = content.decode('utf-8', errors='ignore')\n",
    "            \n",
    "            for line in content.split('\\n'):\n",
    "                if 'TIME OF FIRST OBS' in line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 6:\n",
    "                        year = int(float(parts[0]))\n",
    "                        month = int(float(parts[1]))\n",
    "                        day = int(float(parts[2]))\n",
    "                        doy = date(year, month, day).timetuple().tm_yday\n",
    "                        return year, doy\n",
    "                if 'END OF HEADER' in line:\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            print(f\"   Header parse error: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    @staticmethod\n",
    "    def download(year, doy, output_dir, log_func=print):\n",
    "        \"\"\"Download BRDC navigation file\"\"\"\n",
    "        filename = f\"BRDC00IGS_R_{year}{doy:03d}0000_01D_MN.rnx.gz\"\n",
    "        out_path = Path(output_dir) / filename.replace('.gz', '')\n",
    "        \n",
    "        if out_path.exists():\n",
    "            log_func(f\"‚úì Nav file exists: {out_path.name}\")\n",
    "            return out_path\n",
    "        \n",
    "        for host, path_tpl, name in NavDownloader.IGS_SERVERS:\n",
    "            try:\n",
    "                url_path = path_tpl.format(year=year, doy=doy, filename=filename)\n",
    "                url = f\"https://{host}{url_path}\"\n",
    "                log_func(f\"  Trying {name}...\")\n",
    "                \n",
    "                req = urllib.request.Request(url)\n",
    "                req.add_header('User-Agent', 'Mozilla/5.0 GNSS-Notebook')\n",
    "                \n",
    "                with urllib.request.urlopen(req, timeout=60) as resp:\n",
    "                    data = resp.read()\n",
    "                \n",
    "                decompressed = gzip.decompress(data)\n",
    "                with open(out_path, 'wb') as f:\n",
    "                    f.write(decompressed)\n",
    "                \n",
    "                log_func(f\"‚úì Downloaded: {out_path.name} ({len(decompressed)/1024:.1f} KB)\")\n",
    "                return out_path\n",
    "                \n",
    "            except Exception as e:\n",
    "                log_func(f\"  ‚úó {name}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return None\n",
    "\n",
    "# ============ FILE INPUT WIDGETS ============\n",
    "\n",
    "header = widgets.HTML(\"<h3>üì° GeoVeil CN0 Analysis - GNSS Signal Quality</h3>\")\n",
    "\n",
    "# === OBSERVATION FILE ===\n",
    "obs_section = widgets.HTML(\"<b>Observation File</b> (required)\")\n",
    "\n",
    "obs_upload = widgets.FileUpload(\n",
    "    accept='.obs,.rnx,.crx,.24o,.23o,.22o,.21o,.20o,.25o,.gz,.Z,*',\n",
    "    multiple=False,\n",
    "    description='Upload OBS',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "obs_path_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='/path/to/observation.rnx',\n",
    "    description='OBS Path:',\n",
    "    style={'description_width': '70px'},\n",
    "    layout=widgets.Layout(width='450px')\n",
    ")\n",
    "\n",
    "# === NAVIGATION FILE ===\n",
    "nav_section = widgets.HTML(\"<b>Navigation/Ephemeris</b> (for elevation & skyplots)\")\n",
    "\n",
    "nav_upload = widgets.FileUpload(\n",
    "    accept='.nav,.rnx,.24n,.24g,.25n,.sp3,.SP3,.gz,.Z,*',\n",
    "    multiple=False,\n",
    "    description='Upload NAV',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "nav_path_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='/path/to/navigation.rnx or .sp3',\n",
    "    description='NAV Path:',\n",
    "    style={'description_width': '70px'},\n",
    "    layout=widgets.Layout(width='450px')\n",
    ")\n",
    "\n",
    "auto_download_nav = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Auto-download BRDC if missing',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='250px')\n",
    ")\n",
    "\n",
    "load_btn = widgets.Button(\n",
    "    description='üì• Load Files',\n",
    "    button_style='warning',\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "\n",
    "# === ANALYSIS CONFIG ===\n",
    "config_section = widgets.HTML(\"<b>Analysis Configuration</b>\")\n",
    "\n",
    "elevation_slider = widgets.FloatSlider(\n",
    "    value=5.0, min=0.0, max=30.0, step=1.0,\n",
    "    description='Elevation Cutoff (¬∞):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "time_bin_slider = widgets.IntSlider(\n",
    "    value=60, min=10, max=300, step=10,\n",
    "    description='Time Bin (sec):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='400px')\n",
    ")\n",
    "\n",
    "system_checks = {\n",
    "    'G': widgets.Checkbox(value=True, description='GPS', layout=widgets.Layout(width='100px')),\n",
    "    'R': widgets.Checkbox(value=True, description='GLONASS', layout=widgets.Layout(width='100px')),\n",
    "    'E': widgets.Checkbox(value=True, description='Galileo', layout=widgets.Layout(width='100px')),\n",
    "    'C': widgets.Checkbox(value=True, description='BeiDou', layout=widgets.Layout(width='100px')),\n",
    "}\n",
    "\n",
    "# === OUTPUT BUTTONS (NEW!) ===\n",
    "buttons_section = widgets.HTML(\"<b>üìä Analysis Outputs</b> <i>(click to generate each view)</i>\")\n",
    "\n",
    "btn_summary = widgets.Button(\n",
    "    description='üìä Summary & Score',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='160px', height='35px'),\n",
    "    tooltip='Show text summary and quality radar chart'\n",
    ")\n",
    "\n",
    "btn_heatmap = widgets.Button(\n",
    "    description='üó∫Ô∏è Heatmaps',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='120px', height='35px'),\n",
    "    tooltip='Show CN0 heatmaps (Az/El + Time vs Satellite)'\n",
    ")\n",
    "\n",
    "btn_snr = widgets.Button(\n",
    "    description='üìà SNR Graphs',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='130px', height='35px'),\n",
    "    tooltip='Show CN0 timeseries plots'\n",
    ")\n",
    "\n",
    "btn_skyplot = widgets.Button(\n",
    "    description='üõ∞Ô∏è Skyplot',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='120px', height='35px'),\n",
    "    tooltip='Show satellite skyplot'\n",
    ")\n",
    "\n",
    "btn_anomaly = widgets.Button(\n",
    "    description='‚ö†Ô∏è Anomalies',\n",
    "    button_style='warning',\n",
    "    layout=widgets.Layout(width='130px', height='35px'),\n",
    "    tooltip='Show anomaly timeline'\n",
    ")\n",
    "\n",
    "# === EXPORT BUTTON ===\n",
    "export_btn = widgets.Button(\n",
    "    description='üì• Export Full Report',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='180px', height='35px'),\n",
    "    tooltip='Run complete analysis and download HTML report'\n",
    ")\n",
    "\n",
    "clear_btn = widgets.Button(\n",
    "    description='üóëÔ∏è Clear',\n",
    "    button_style='danger',\n",
    "    layout=widgets.Layout(width='80px', height='35px')\n",
    ")\n",
    "\n",
    "# Progress & Status\n",
    "progress = widgets.FloatProgress(\n",
    "    value=0, min=0, max=1.0,\n",
    "    description='Progress:',\n",
    "    layout=widgets.Layout(width='400px', visibility='hidden')\n",
    ")\n",
    "\n",
    "status = widgets.HTML(value=\"<b>Status:</b> Ready - load files to begin\")\n",
    "\n",
    "# Output areas\n",
    "info_out = widgets.Output()\n",
    "results_out = widgets.Output()\n",
    "\n",
    "# ============ CORE ANALYSIS FUNCTION ============\n",
    "\n",
    "def run_core_analysis(silent=False):\n",
    "    \"\"\"Run the CN0 analysis - returns result or None\"\"\"\n",
    "    global analysis_results\n",
    "    \n",
    "    if not loaded_data['obs_content']:\n",
    "        if not silent:\n",
    "            with results_out:\n",
    "                clear_output()\n",
    "                print(\"‚ùå No observation file loaded!\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        import geoveil_cn0 as gcn0\n",
    "        import tempfile\n",
    "        \n",
    "        # Get enabled systems\n",
    "        systems = [s for s, cb in system_checks.items() if cb.value]\n",
    "        \n",
    "        # Create config\n",
    "        config = gcn0.AnalysisConfig(\n",
    "            min_elevation=elevation_slider.value,\n",
    "            time_bin_seconds=time_bin_slider.value,\n",
    "            systems=systems,\n",
    "            detect_anomalies=True,\n",
    "        )\n",
    "        \n",
    "        # Create analyzer\n",
    "        analyzer = gcn0.CN0Analyzer(config)\n",
    "        \n",
    "        # Save content to temp files (analyzer expects file paths)\n",
    "        temp_dir = tempfile.gettempdir()\n",
    "        \n",
    "        obs_path = os.path.join(temp_dir, loaded_data['obs_filename'])\n",
    "        with open(obs_path, 'wb') as f:\n",
    "            f.write(loaded_data['obs_content'])\n",
    "        \n",
    "        nav_path = None\n",
    "        if loaded_data['nav_content']:\n",
    "            nav_path = os.path.join(temp_dir, loaded_data['nav_filename'])\n",
    "            with open(nav_path, 'wb') as f:\n",
    "                f.write(loaded_data['nav_content'])\n",
    "        \n",
    "        # Run analysis\n",
    "        if nav_path:\n",
    "            result = analyzer.analyze_with_nav(obs_path, nav_path)\n",
    "        else:\n",
    "            result = analyzer.analyze_file(obs_path)\n",
    "        \n",
    "        analysis_results['data'] = result\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        if not silent:\n",
    "            with results_out:\n",
    "                clear_output()\n",
    "                print(f\"‚ùå Analysis error: {e}\")\n",
    "        return None\n",
    "\n",
    "# ============ OUTPUT HANDLERS ============\n",
    "\n",
    "def show_summary(btn):\n",
    "    \"\"\"Show text summary and quality score radar\"\"\"\n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        print(\"üìä Generating summary...\")\n",
    "    \n",
    "    result = analysis_results.get('data')\n",
    "    if not result:\n",
    "        result = run_core_analysis()\n",
    "    \n",
    "    if not result:\n",
    "        return\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        \n",
    "        # === TEXT SUMMARY ===\n",
    "        qs = result.quality_score\n",
    "        \n",
    "        print(\"=\" * 70)\n",
    "        print(\"üìä GEOVEIL CN0 ANALYSIS RESULTS\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        print(f\"\\nüìÅ File:\")\n",
    "        print(f\"   RINEX Version: {result.rinex_version}\")\n",
    "        print(f\"   Duration: {result.duration_hours:.2f} hours ({result.epoch_count} epochs)\")\n",
    "        print(f\"   Station: {result.station_name or 'Unknown'}\")\n",
    "        print(f\"   Constellations: {', '.join(result.get_systems())}\")\n",
    "        \n",
    "        # === CALCULATE LOCK LOSS METRICS ===\n",
    "        total_cycle_slips = 0\n",
    "        total_data_gaps = 0\n",
    "        total_satellites = 0\n",
    "        \n",
    "        for sys_name in ['GPS', 'GLONASS', 'Galileo', 'BeiDou']:\n",
    "            stats = result.get_constellation_summary(sys_name)\n",
    "            if stats:\n",
    "                total_cycle_slips += int(stats.get('cycle_slips', 0))\n",
    "                total_data_gaps += int(stats.get('data_gaps', 0))\n",
    "                total_satellites += int(stats.get('satellite_count', 0))\n",
    "        \n",
    "        # Calculate rates\n",
    "        duration_hours = max(result.duration_hours, 0.01)\n",
    "        slips_per_hour = total_cycle_slips / duration_hours\n",
    "        gaps_per_hour = total_data_gaps / duration_hours\n",
    "        \n",
    "        # Lock Loss Score (0-100, higher is better = fewer losses)\n",
    "        # Based on cycle slips and data gaps per satellite per hour\n",
    "        if total_satellites > 0:\n",
    "            slips_per_sat_hour = slips_per_hour / total_satellites\n",
    "            gaps_per_sat_hour = gaps_per_hour / total_satellites\n",
    "            \n",
    "            # Score calculation: penalize for slips and gaps\n",
    "            # Target: <0.1 slips/sat/hour = 100, >2 slips/sat/hour = 0\n",
    "            slip_score = max(0, min(100, 100 - (slips_per_sat_hour * 50)))\n",
    "            gap_score = max(0, min(100, 100 - (gaps_per_sat_hour * 25)))\n",
    "            lock_integrity_score = (slip_score * 0.6 + gap_score * 0.4)\n",
    "        else:\n",
    "            lock_integrity_score = 0\n",
    "            slips_per_sat_hour = 0\n",
    "            gaps_per_sat_hour = 0\n",
    "        \n",
    "        print(f\"\\nüèÜ QUALITY SCORE: {qs.overall:.0f}/100 ({qs.rating})\")\n",
    "        print(f\"   CN0 Quality:   {qs.cn0_quality:.0f}\")\n",
    "        print(f\"   Availability:  {qs.availability:.0f}\")\n",
    "        print(f\"   Continuity:    {qs.continuity:.0f}\")\n",
    "        print(f\"   Stability:     {qs.stability:.0f}\")\n",
    "        print(f\"   Diversity:     {qs.diversity:.0f}\")\n",
    "        print(f\"   Lock Integrity: {lock_integrity_score:.0f}\")\n",
    "        print(f\"   Post-processing suitable: {'‚úÖ Yes' if qs.overall >= 70 else '‚ùå No'}\")\n",
    "        \n",
    "        print(f\"\\nüì∂ SIGNAL QUALITY:\")\n",
    "        print(f\"   Average CN0: {result.mean_cn0:.1f} dB-Hz\")\n",
    "        print(f\"   Std Dev: {result.cn0_std_dev:.1f} dB-Hz\")\n",
    "        print(f\"   Range: {result.min_cn0:.1f} - {result.max_cn0:.1f} dB-Hz\")\n",
    "        \n",
    "        # === LOCK LOSS SECTION ===\n",
    "        print(f\"\\nüîì LOCK LOSS / SIGNAL CONTINUITY:\")\n",
    "        print(f\"   Total Cycle Slips: {total_cycle_slips} ({slips_per_hour:.1f}/hour)\")\n",
    "        print(f\"   Total Data Gaps:   {total_data_gaps} ({gaps_per_hour:.1f}/hour)\")\n",
    "        print(f\"   Per-Satellite Rate: {slips_per_sat_hour:.2f} slips/sat/hour\")\n",
    "        \n",
    "        # Lock loss assessment\n",
    "        if lock_integrity_score >= 90:\n",
    "            lock_status = \"‚úÖ Excellent - Minimal signal interruptions\"\n",
    "        elif lock_integrity_score >= 70:\n",
    "            lock_status = \"‚úÖ Good - Acceptable continuity\"\n",
    "        elif lock_integrity_score >= 50:\n",
    "            lock_status = \"‚ö†Ô∏è Moderate - Some signal interruptions\"\n",
    "        elif lock_integrity_score >= 30:\n",
    "            lock_status = \"‚ö†Ô∏è Poor - Frequent lock losses\"\n",
    "        else:\n",
    "            lock_status = \"üö® Critical - Severe continuity issues\"\n",
    "        print(f\"   Lock Integrity Score: {lock_integrity_score:.0f}/100 - {lock_status}\")\n",
    "        \n",
    "        print(f\"\\nüõ°Ô∏è THREAT ASSESSMENT:\")\n",
    "        \n",
    "        # === IMPROVED THREAT DETECTION ===\n",
    "        # Don't blindly trust the library's spoofing flag - it has false positives\n",
    "        # When ephemeris doesn't cover all satellites (especially BeiDou), it triggers falsely\n",
    "        \n",
    "        # Jamming: Only if low CN0 + library flag\n",
    "        jamming_detected = result.jamming_detected and result.mean_cn0 < 35.0\n",
    "        \n",
    "        # Spoofing: Check per-constellation std to avoid false positives from incomplete ephemeris\n",
    "        constellation_stds = []\n",
    "        for sys_name in ['GPS', 'GLONASS', 'Galileo', 'BeiDou']:\n",
    "            stats = result.get_constellation_summary(sys_name)\n",
    "            if stats:\n",
    "                try:\n",
    "                    std_cn0 = float(stats.get('std_cn0', stats.get('cn0_std', 5.0)))\n",
    "                    constellation_stds.append(std_cn0)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        avg_constellation_std = sum(constellation_stds) / len(constellation_stds) if constellation_stds else 5.0\n",
    "        \n",
    "        # Real spoofing indicators:\n",
    "        # 1. Very low CN0 std across constellations (< 2 dB) - signals too uniform\n",
    "        # 2. AND elevated average CN0 (> 50 dB-Hz) - spoofer typically overpowers\n",
    "        # 3. AND overall std also low\n",
    "        spoofing_indicators = []\n",
    "        if avg_constellation_std < 2.0:\n",
    "            spoofing_indicators.append(\"CN0 uniformity suspiciously low\")\n",
    "        if result.mean_cn0 > 50.0:\n",
    "            spoofing_indicators.append(\"CN0 elevated (possible high-power signal)\")\n",
    "        if result.cn0_std_dev < 1.0:\n",
    "            spoofing_indicators.append(\"Overall signal variance very low\")\n",
    "        \n",
    "        # Only flag spoofing if multiple indicators present\n",
    "        spoofing_suspicious = len(spoofing_indicators) >= 2\n",
    "        \n",
    "        # If library says spoofing but our checks don't agree, it's likely false positive\n",
    "        if result.spoofing_detected and not spoofing_suspicious:\n",
    "            print(f\"   Jamming:      {'üö® DETECTED' if jamming_detected else '‚úÖ None'}\")\n",
    "            print(f\"   Spoofing:     ‚ö†Ô∏è Flag raised (likely false positive - incomplete ephemeris)\")\n",
    "            print(f\"   Interference: {'‚ö†Ô∏è Detected' if result.interference_detected else '‚úÖ None'}\")\n",
    "        else:\n",
    "            print(f\"   Jamming:      {'üö® DETECTED' if jamming_detected else '‚úÖ None'}\")\n",
    "            print(f\"   Spoofing:     {'üö® DETECTED' if spoofing_suspicious else '‚úÖ None'}\")\n",
    "            print(f\"   Interference: {'‚ö†Ô∏è Detected' if result.interference_detected else '‚úÖ None'}\")\n",
    "        \n",
    "        if spoofing_indicators and spoofing_suspicious:\n",
    "            print(f\"   ‚îî‚îÄ Indicators: {', '.join(spoofing_indicators)}\")\n",
    "        \n",
    "        # === GENERATE PROPER SUMMARY BASED ON DISPLAYED SCORE ===\n",
    "        # Don't use result.summary - it's based on internal score with different weights\n",
    "        overall_score = qs.overall\n",
    "        \n",
    "        if overall_score >= 90:\n",
    "            quality_text = \"Excellent GNSS signal quality\"\n",
    "        elif overall_score >= 80:\n",
    "            quality_text = \"Good GNSS signal quality\"\n",
    "        elif overall_score >= 70:\n",
    "            quality_text = \"Fair GNSS signal quality\"\n",
    "        elif overall_score >= 60:\n",
    "            quality_text = \"Degraded GNSS signal quality\"\n",
    "        else:\n",
    "            quality_text = \"Poor GNSS signal quality\"\n",
    "        \n",
    "        # Add warnings if needed\n",
    "        warnings = []\n",
    "        if jamming_detected:\n",
    "            warnings.append(\"jamming detected\")\n",
    "        if spoofing_suspicious:\n",
    "            warnings.append(\"spoofing indicators present\")\n",
    "        if result.interference_detected:\n",
    "            warnings.append(\"interference events detected\")\n",
    "        if lock_integrity_score < 50:\n",
    "            warnings.append(\"significant lock loss issues\")\n",
    "        \n",
    "        if warnings:\n",
    "            summary_text = f\"{quality_text} - WARNING: {', '.join(warnings)}\"\n",
    "        else:\n",
    "            summary_text = quality_text\n",
    "        \n",
    "        print(f\"\\nüìù {summary_text}\")\n",
    "        \n",
    "        # === ANALYSIS CONCLUSION ===\n",
    "        print(f\"\\n\" + \"=\" * 70)\n",
    "        print(f\"üìã CONCLUSION:\")\n",
    "        print(f\"=\" * 70)\n",
    "        \n",
    "        conclusions = []\n",
    "        \n",
    "        # Overall assessment\n",
    "        if overall_score >= 90:\n",
    "            conclusions.append(\"‚úÖ Data quality is EXCELLENT - suitable for high-precision applications (PPP/PPK)\")\n",
    "        elif overall_score >= 80:\n",
    "            conclusions.append(\"‚úÖ Data quality is GOOD - suitable for standard GNSS applications\")\n",
    "        elif overall_score >= 70:\n",
    "            conclusions.append(\"‚ö†Ô∏è Data quality is FAIR - usable but may have reduced accuracy\")\n",
    "        elif overall_score >= 60:\n",
    "            conclusions.append(\"‚ö†Ô∏è Data quality is DEGRADED - review anomalies before use\")\n",
    "        else:\n",
    "            conclusions.append(\"‚ùå Data quality is POOR - significant issues detected\")\n",
    "        \n",
    "        # Signal strength assessment\n",
    "        if result.mean_cn0 >= 45:\n",
    "            conclusions.append(f\"‚úÖ Signal strength EXCELLENT ({result.mean_cn0:.1f} dB-Hz average)\")\n",
    "        elif result.mean_cn0 >= 40:\n",
    "            conclusions.append(f\"‚úÖ Signal strength GOOD ({result.mean_cn0:.1f} dB-Hz average)\")\n",
    "        elif result.mean_cn0 >= 35:\n",
    "            conclusions.append(f\"‚ö†Ô∏è Signal strength MODERATE ({result.mean_cn0:.1f} dB-Hz average)\")\n",
    "        else:\n",
    "            conclusions.append(f\"‚ùå Signal strength LOW ({result.mean_cn0:.1f} dB-Hz) - possible interference\")\n",
    "        \n",
    "        # Lock integrity\n",
    "        if lock_integrity_score >= 80:\n",
    "            conclusions.append(\"‚úÖ Signal continuity is excellent (minimal lock losses)\")\n",
    "        elif lock_integrity_score >= 60:\n",
    "            conclusions.append(\"‚úÖ Signal continuity is acceptable\")\n",
    "        else:\n",
    "            conclusions.append(f\"‚ö†Ô∏è Signal continuity issues detected ({total_data_gaps} data gaps)\")\n",
    "        \n",
    "        # Threat summary\n",
    "        if not (jamming_detected or spoofing_suspicious or result.interference_detected):\n",
    "            conclusions.append(\"‚úÖ No significant threats detected\")\n",
    "        else:\n",
    "            if jamming_detected:\n",
    "                conclusions.append(\"üö® JAMMING DETECTED - data may be compromised\")\n",
    "            if spoofing_suspicious:\n",
    "                conclusions.append(\"üö® SPOOFING INDICATORS - verify data integrity\")\n",
    "            if result.interference_detected:\n",
    "                conclusions.append(\"‚ö†Ô∏è Interference events detected - review anomaly timeline\")\n",
    "        \n",
    "        # Post-processing recommendation\n",
    "        if overall_score >= 70 and result.mean_cn0 >= 35 and lock_integrity_score >= 50:\n",
    "            conclusions.append(\"‚úÖ Data suitable for post-processing (PPP/RTK)\")\n",
    "        else:\n",
    "            conclusions.append(\"‚ö†Ô∏è Review issues before post-processing\")\n",
    "        \n",
    "        for c in conclusions:\n",
    "            print(f\"   {c}\")\n",
    "        \n",
    "        print(f\"\\n\" + \"=\" * 70)\n",
    "        \n",
    "        # === CONSTELLATION SUMMARY ===\n",
    "        print(f\"\\nüõ∞Ô∏è CONSTELLATION SUMMARY:\")\n",
    "        for sys_name in ['GPS', 'GLONASS', 'Galileo', 'BeiDou']:\n",
    "            stats = result.get_constellation_summary(sys_name)\n",
    "            if stats:\n",
    "                sat_count = stats.get('satellite_count', '0')\n",
    "                expected = stats.get('satellites_expected', sat_count)\n",
    "                mean_cn0 = stats.get('mean_cn0', '0')\n",
    "                std_cn0 = stats.get('std_cn0', '0')\n",
    "                cycle_slips = stats.get('cycle_slips', '0')\n",
    "                data_gaps = stats.get('data_gaps', '0')\n",
    "                \n",
    "                pct = int(sat_count) / max(int(expected), 1) * 100\n",
    "                slips_rate = int(cycle_slips) / duration_hours\n",
    "                print(f\"\\n   {sys_name}:\")\n",
    "                print(f\"      Satellites: {sat_count}/{expected} ({pct:.0f}%)\")\n",
    "                print(f\"      CN0: {float(mean_cn0):.1f} ¬± {float(std_cn0):.2f} dB-Hz\")\n",
    "                print(f\"      Cycle Slips: {cycle_slips} ({slips_rate:.1f}/hour)\")\n",
    "                print(f\"      Data Gaps: {data_gaps}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        \n",
    "        # === QUALITY RADAR CHART (now includes Lock Integrity) ===\n",
    "        print(\"\\nüìà Quality Score Radar:\")\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Add Lock Integrity to the radar chart\n",
    "        categories = ['Availability', 'CN0 Quality', 'Stability', 'Diversity', 'Continuity', 'Lock Integrity']\n",
    "        values = [qs.availability, qs.cn0_quality, qs.stability, qs.diversity, qs.continuity, lock_integrity_score]\n",
    "        values.append(values[0])  # Close the polygon\n",
    "        \n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "            r=values,\n",
    "            theta=categories + [categories[0]],\n",
    "            fill='toself',\n",
    "            fillcolor='rgba(99, 110, 250, 0.3)',\n",
    "            line=dict(color='rgb(99, 110, 250)', width=2),\n",
    "            name='Quality'\n",
    "        ))\n",
    "        \n",
    "        # Rating color\n",
    "        color = '#22c55e' if qs.overall >= 80 else '#eab308' if qs.overall >= 60 else '#ef4444'\n",
    "        \n",
    "        fig.update_layout(\n",
    "            polar=dict(radialaxis=dict(visible=True, range=[0, 100])),\n",
    "            showlegend=False,\n",
    "            title=f\"Quality Score: {qs.overall:.0f}/100 ({qs.rating})\",\n",
    "            height=550,\n",
    "            width=650\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "\n",
    "\n",
    "def show_heatmap(btn):\n",
    "    \"\"\"Show BOTH CN0 heatmaps: Az/El and Time vs Satellite\"\"\"\n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        print(\"üó∫Ô∏è Generating heatmaps...\")\n",
    "    \n",
    "    result = analysis_results.get('data')\n",
    "    if not result:\n",
    "        result = run_core_analysis()\n",
    "    \n",
    "    if not result:\n",
    "        return\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        \n",
    "        # =====================================================================\n",
    "        # HEATMAP 1: Time vs Satellite PRN (C/N‚ÇÄ Heatmap)\n",
    "        # =====================================================================\n",
    "        print(\"üî• C/N‚ÇÄ Heatmap - Time vs Satellite\")\n",
    "        \n",
    "        timestamps = result.get_timestamps()\n",
    "        \n",
    "        # Get satellite timeseries from JSON (most reliable method from original widget)\n",
    "        try:\n",
    "            result_json = json.loads(result.to_json())\n",
    "            sat_timeseries = result_json.get('timeseries', {}).get('satellite_timeseries', {})\n",
    "            \n",
    "            if sat_timeseries and len(sat_timeseries) > 0:\n",
    "                print(f\"   Found {len(sat_timeseries)} satellites in timeseries\")\n",
    "                \n",
    "                # Get all timestamps from the data\n",
    "                all_times = set()\n",
    "                for sat_id, sat_data in sat_timeseries.items():\n",
    "                    if isinstance(sat_data, dict):\n",
    "                        series = sat_data.get('cn0_series', sat_data.get('series', []))\n",
    "                        if isinstance(series, list):\n",
    "                            for point in series:\n",
    "                                if isinstance(point, dict):\n",
    "                                    all_times.add(point.get('timestamp', point.get('time', '')))\n",
    "                \n",
    "                all_times = sorted([t for t in all_times if t])\n",
    "                \n",
    "                if all_times:\n",
    "                    # Subsample if too many points\n",
    "                    max_time_points = 500\n",
    "                    if len(all_times) > max_time_points:\n",
    "                        step = len(all_times) // max_time_points\n",
    "                        all_times = all_times[::step]\n",
    "                    \n",
    "                    # Sort satellites by constellation then PRN\n",
    "                    def sat_sort_key(s):\n",
    "                        if len(s) >= 2:\n",
    "                            sys = s[0]\n",
    "                            try:\n",
    "                                prn = int(s[1:])\n",
    "                            except:\n",
    "                                prn = 0\n",
    "                            sys_order = {'G': 0, 'R': 1, 'E': 2, 'C': 3, 'J': 4, 'I': 5, 'S': 6}\n",
    "                            return (sys_order.get(sys, 9), prn)\n",
    "                        return (9, 0)\n",
    "                    \n",
    "                    all_satellites = sorted(sat_timeseries.keys(), key=sat_sort_key, reverse=True)\n",
    "                    \n",
    "                    # Build z matrix (satellites x time)\n",
    "                    z_matrix = []\n",
    "                    sat_labels = []\n",
    "                    \n",
    "                    for sat in all_satellites:\n",
    "                        sat_data = sat_timeseries.get(sat, {})\n",
    "                        \n",
    "                        if isinstance(sat_data, dict):\n",
    "                            cn0_series = sat_data.get('cn0_series', sat_data.get('series', []))\n",
    "                        else:\n",
    "                            continue\n",
    "                        \n",
    "                        # Create lookup dict\n",
    "                        cn0_by_time = {}\n",
    "                        if isinstance(cn0_series, list):\n",
    "                            for p in cn0_series:\n",
    "                                if isinstance(p, dict):\n",
    "                                    t = p.get('timestamp', p.get('time', ''))\n",
    "                                    v = p.get('value', p.get('cn0', None))\n",
    "                                    if t and v is not None:\n",
    "                                        cn0_by_time[t] = v\n",
    "                        \n",
    "                        # Fill row\n",
    "                        row = []\n",
    "                        for t in all_times:\n",
    "                            val = cn0_by_time.get(t, None)\n",
    "                            row.append(val if val is not None else None)\n",
    "                        \n",
    "                        # Only add if we have some data\n",
    "                        valid_count = sum(1 for v in row if v is not None)\n",
    "                        if valid_count > len(all_times) * 0.05:  # At least 5% data\n",
    "                            z_matrix.append(row)\n",
    "                            sat_labels.append(sat)\n",
    "                    \n",
    "                    if z_matrix:\n",
    "                        # Parse timestamps for display\n",
    "                        time_labels = pd.to_datetime(all_times)\n",
    "                        \n",
    "                        fig1 = go.Figure(go.Heatmap(\n",
    "                            z=z_matrix,\n",
    "                            x=time_labels,\n",
    "                            y=sat_labels,\n",
    "                            colorscale='Viridis',\n",
    "                            colorbar=dict(title='C/N‚ÇÄ<br>(dB-Hz)'),\n",
    "                            hoverongaps=False,\n",
    "                            hovertemplate='Satellite: %{y}<br>Time: %{x}<br>CN0: %{z:.1f} dB-Hz<extra></extra>',\n",
    "                            zmin=25,\n",
    "                            zmax=55\n",
    "                        ))\n",
    "                        \n",
    "                        fig1.update_layout(\n",
    "                            title='üî• C/N‚ÇÄ Heatmap - Time vs Satellite',\n",
    "                            xaxis_title='Time (UTC)',\n",
    "                            yaxis_title='Satellite PRN',\n",
    "                            width=1100,\n",
    "                            height=max(400, len(sat_labels) * 20 + 150),\n",
    "                            xaxis=dict(type='date'),\n",
    "                            yaxis=dict(tickmode='array', tickvals=sat_labels, ticktext=sat_labels)\n",
    "                        )\n",
    "                        \n",
    "                        fig1.show()\n",
    "                    else:\n",
    "                        print(\"‚ö†Ô∏è No valid satellite data for heatmap\")\n",
    "                else:\n",
    "                    print(\"‚ö†Ô∏è No timestamps found in satellite timeseries\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è No satellite_timeseries data available\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not create Time vs Satellite heatmap: {e}\")\n",
    "        \n",
    "        # =====================================================================\n",
    "        # HEATMAP 2: CN0 by Azimuth/Elevation\n",
    "        # =====================================================================\n",
    "        print(\"\\nüó∫Ô∏è CN0 Heatmap by Azimuth/Elevation\")\n",
    "        \n",
    "        # Get skyplot data for azimuth/elevation heatmap\n",
    "        skyplot_data = result.get_skyplot_data()\n",
    "        \n",
    "        if not skyplot_data:\n",
    "            print(\"‚ö†Ô∏è No azimuth/elevation data available (need navigation file)\")\n",
    "            return\n",
    "        \n",
    "        # Build heatmap from satellite traces\n",
    "        # Create bins for azimuth (0-360) and elevation (0-90)\n",
    "        az_bins = list(range(0, 361, 15))  # 0, 15, 30, ..., 360\n",
    "        el_bins = list(range(0, 91, 5))    # 0, 5, 10, ..., 90\n",
    "        \n",
    "        # Initialize grid\n",
    "        cn0_sum = [[0.0 for _ in range(len(az_bins)-1)] for _ in range(len(el_bins)-1)]\n",
    "        cn0_count = [[0 for _ in range(len(az_bins)-1)] for _ in range(len(el_bins)-1)]\n",
    "        \n",
    "        # Aggregate data from all satellites\n",
    "        for sat_trace in skyplot_data:\n",
    "            azimuths = [float(x) for x in sat_trace.get('azimuths', '').split(',') if x]\n",
    "            elevations = [float(x) for x in sat_trace.get('elevations', '').split(',') if x]\n",
    "            cn0_values = [float(x) for x in sat_trace.get('cn0_values', '').split(',') if x]\n",
    "            \n",
    "            for az, el, cn0 in zip(azimuths, elevations, cn0_values):\n",
    "                az_idx = min(int(az / 15), len(az_bins) - 2)\n",
    "                el_idx = min(int(el / 5), len(el_bins) - 2)\n",
    "                cn0_sum[el_idx][az_idx] += cn0\n",
    "                cn0_count[el_idx][az_idx] += 1\n",
    "        \n",
    "        # Compute mean CN0 for each bin\n",
    "        cn0_grid = []\n",
    "        for el_idx in range(len(el_bins) - 1):\n",
    "            row = []\n",
    "            for az_idx in range(len(az_bins) - 1):\n",
    "                if cn0_count[el_idx][az_idx] > 0:\n",
    "                    row.append(cn0_sum[el_idx][az_idx] / cn0_count[el_idx][az_idx])\n",
    "                else:\n",
    "                    row.append(None)  # No data\n",
    "            cn0_grid.append(row)\n",
    "        \n",
    "        if all(all(v is None for v in row) for row in cn0_grid):\n",
    "            print(\"‚ö†Ô∏è No heatmap data available (no valid observations)\")\n",
    "            return\n",
    "        \n",
    "        fig2 = go.Figure(go.Heatmap(\n",
    "            z=cn0_grid,\n",
    "            x=[f\"{az_bins[i]}-{az_bins[i+1]}\" for i in range(len(az_bins)-1)],\n",
    "            y=[f\"{el_bins[i]}-{el_bins[i+1]}\" for i in range(len(el_bins)-1)],\n",
    "            colorscale='Viridis',\n",
    "            colorbar=dict(title='CN0 (dB-Hz)'),\n",
    "            hoverongaps=False,\n",
    "            zmin=30,\n",
    "            zmax=55\n",
    "        ))\n",
    "        \n",
    "        fig2.update_layout(\n",
    "            title='CN0 Heatmap by Azimuth/Elevation',\n",
    "            xaxis_title='Azimuth (¬∞)',\n",
    "            yaxis_title='Elevation (¬∞)',\n",
    "            width=850,\n",
    "            height=500\n",
    "        )\n",
    "        \n",
    "        fig2.show()\n",
    "\n",
    "\n",
    "def show_snr_graphs(btn):\n",
    "    \"\"\"Show CN0 timeseries - Overall average + Per-constellation satellite graphs\"\"\"\n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        print(\"üìà Generating SNR timeseries...\")\n",
    "    \n",
    "    result = analysis_results.get('data')\n",
    "    if not result:\n",
    "        result = run_core_analysis()\n",
    "    \n",
    "    if not result:\n",
    "        return\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        \n",
    "        # Get timestamps\n",
    "        timestamps = result.get_timestamps()\n",
    "        \n",
    "        if not timestamps:\n",
    "            print(\"‚ö†Ô∏è No timeseries data available\")\n",
    "            return\n",
    "        \n",
    "        # Parse timestamps\n",
    "        ts = pd.to_datetime(timestamps)\n",
    "        \n",
    "        # Get mean CN0 and satellite counts\n",
    "        mean_cn0 = result.get_mean_cn0_series()\n",
    "        sat_counts = result.get_satellite_count_series()\n",
    "        \n",
    "        if len(mean_cn0) == 0:\n",
    "            print(\"‚ö†Ô∏è No CN0 timeseries data\")\n",
    "            return\n",
    "        \n",
    "        # =====================================================================\n",
    "        # GRAPH 1: Overall Mean CN0 Timeseries with Satellite Count\n",
    "        # =====================================================================\n",
    "        print(\"üìä Overall CN0 Timeseries:\")\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=1,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.08,\n",
    "            row_heights=[0.7, 0.3],\n",
    "            subplot_titles=('CN0 Timeseries', 'Satellite Count')\n",
    "        )\n",
    "        \n",
    "        # Overall mean\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=ts, y=mean_cn0,\n",
    "            name='Overall Mean',\n",
    "            line=dict(color='black', width=2.5)\n",
    "        ), row=1, col=1)\n",
    "        \n",
    "        # Satellite count\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=ts, y=sat_counts,\n",
    "            marker_color='#6b7280',\n",
    "            showlegend=False\n",
    "        ), row=2, col=1)\n",
    "        \n",
    "        # Warning threshold (Degraded at 35)\n",
    "        fig.add_hline(y=35, line_dash='dash', line_color='orange', \n",
    "                      annotation_text='Degraded (35)', annotation_position='right', row=1, col=1)\n",
    "        \n",
    "        fig.update_layout(\n",
    "            height=500,\n",
    "            width=1100,\n",
    "            title='CN0 Timeseries',\n",
    "            legend=dict(orientation='h', y=1.12)\n",
    "        )\n",
    "        fig.update_yaxes(title_text='CN0 (dB-Hz)', row=1, col=1)\n",
    "        fig.update_yaxes(title_text='Satellites', row=2, col=1)\n",
    "        fig.update_xaxes(title_text='Time (UTC)', row=2, col=1)\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        # =====================================================================\n",
    "        # GRAPH 2+: Per-Constellation Satellite CN0 Timeseries\n",
    "        # =====================================================================\n",
    "        \n",
    "        # Distinct colors for satellites within each constellation\n",
    "        sat_colors = [\n",
    "            '#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A',\n",
    "            '#19D3F3', '#FF6692', '#B6E880', '#FF97FF', '#FECB52',\n",
    "            '#1F77B4', '#FF7F0E', '#2CA02C', '#D62728', '#9467BD',\n",
    "            '#8C564B', '#E377C2', '#7F7F7F', '#BCBD22', '#17BECF'\n",
    "        ]\n",
    "        \n",
    "        sys_to_const = {'G': 'GPS', 'R': 'GLONASS', 'E': 'Galileo', 'C': 'BeiDou'}\n",
    "        \n",
    "        # Get satellite timeseries from JSON\n",
    "        try:\n",
    "            result_json = json.loads(result.to_json())\n",
    "            sat_timeseries = result_json.get('timeseries', {}).get('satellite_timeseries', {})\n",
    "            \n",
    "            if not sat_timeseries or len(sat_timeseries) == 0:\n",
    "                print(\"\\n‚ö†Ô∏è No per-satellite data available for constellation graphs\")\n",
    "                return\n",
    "            \n",
    "            # Organize by constellation\n",
    "            const_satellites = {\n",
    "                'GPS': [],\n",
    "                'GLONASS': [],\n",
    "                'Galileo': [],\n",
    "                'BeiDou': []\n",
    "            }\n",
    "            \n",
    "            for sat_id, sat_data in sat_timeseries.items():\n",
    "                if len(sat_id) < 2:\n",
    "                    continue\n",
    "                \n",
    "                system = sat_id[0]\n",
    "                const_name = sys_to_const.get(system)\n",
    "                if not const_name:\n",
    "                    continue\n",
    "                \n",
    "                if isinstance(sat_data, dict):\n",
    "                    cn0_series = sat_data.get('cn0_series', sat_data.get('series', []))\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                # Extract timestamps and values\n",
    "                sat_timestamps = []\n",
    "                sat_cn0_values = []\n",
    "                \n",
    "                if isinstance(cn0_series, list):\n",
    "                    for p in cn0_series:\n",
    "                        if isinstance(p, dict):\n",
    "                            t = p.get('timestamp', p.get('time', ''))\n",
    "                            v = p.get('value', p.get('cn0', None))\n",
    "                            if t and v is not None:\n",
    "                                sat_timestamps.append(t)\n",
    "                                sat_cn0_values.append(v)\n",
    "                \n",
    "                if len(sat_cn0_values) > 0:\n",
    "                    const_satellites[const_name].append({\n",
    "                        'sat_id': sat_id,\n",
    "                        'timestamps': pd.to_datetime(sat_timestamps),\n",
    "                        'cn0_values': sat_cn0_values\n",
    "                    })\n",
    "            \n",
    "            # Check if we have any data\n",
    "            total_sats = sum(len(sats) for sats in const_satellites.values())\n",
    "            if total_sats == 0:\n",
    "                print(\"\\n‚ö†Ô∏è No per-satellite data available for constellation graphs\")\n",
    "                return\n",
    "            \n",
    "            # Create a graph for each constellation that has data\n",
    "            for const_name, satellites in const_satellites.items():\n",
    "                if not satellites:\n",
    "                    continue\n",
    "                \n",
    "                # Sort satellites by PRN number\n",
    "                satellites.sort(key=lambda s: int(s['sat_id'][1:]) if s['sat_id'][1:].isdigit() else 0)\n",
    "                \n",
    "                print(f\"\\nüì° {const_name} C/N‚ÇÄ Timeseries ({len(satellites)} satellites):\")\n",
    "                \n",
    "                fig_const = go.Figure()\n",
    "                \n",
    "                # Add each satellite trace\n",
    "                for i, sat_data in enumerate(satellites):\n",
    "                    color = sat_colors[i % len(sat_colors)]\n",
    "                    fig_const.add_trace(go.Scatter(\n",
    "                        x=sat_data['timestamps'],\n",
    "                        y=sat_data['cn0_values'],\n",
    "                        name=sat_data['sat_id'],\n",
    "                        mode='lines',\n",
    "                        line=dict(width=1.5, color=color),\n",
    "                        hovertemplate=f\"{sat_data['sat_id']}<br>Time: %{{x}}<br>CN0: %{{y:.1f}} dB-Hz<extra></extra>\"\n",
    "                    ))\n",
    "                \n",
    "                # Add threshold lines\n",
    "                fig_const.add_hline(y=35, line_dash='dash', line_color='orange', \n",
    "                                   annotation_text='Degraded (35)', annotation_position='right')\n",
    "                fig_const.add_hline(y=25, line_dash='dash', line_color='red',\n",
    "                                   annotation_text='Poor (25)', annotation_position='right')\n",
    "                \n",
    "                fig_const.update_layout(\n",
    "                    title=f'üì° {const_name} - C/N‚ÇÄ by Satellite',\n",
    "                    xaxis_title='Time (UTC)',\n",
    "                    yaxis_title='C/N‚ÇÄ (dB-Hz)',\n",
    "                    height=450,\n",
    "                    width=1100,\n",
    "                    yaxis=dict(range=[20, 60]),\n",
    "                    legend=dict(\n",
    "                        orientation='h',\n",
    "                        yanchor='bottom',\n",
    "                        y=1.02,\n",
    "                        xanchor='right',\n",
    "                        x=1,\n",
    "                        font=dict(size=10)\n",
    "                    ),\n",
    "                    hovermode='x unified'\n",
    "                )\n",
    "                \n",
    "                fig_const.show()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ö†Ô∏è Could not create per-constellation graphs: {e}\")\n",
    "\n",
    "\n",
    "def show_skyplot(btn):\n",
    "    \"\"\"Show satellite skyplot\"\"\"\n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        print(\"üõ∞Ô∏è Generating skyplot...\")\n",
    "    \n",
    "    result = analysis_results.get('data')\n",
    "    if not result:\n",
    "        result = run_core_analysis()\n",
    "    \n",
    "    if not result:\n",
    "        return\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        \n",
    "        # Get skyplot data (list of satellite traces)\n",
    "        skyplot_data = result.get_skyplot_data()\n",
    "        coverage = result.skyplot_coverage\n",
    "        \n",
    "        if not skyplot_data:\n",
    "            print(\"‚ö†Ô∏è No skyplot data (need receiver position)\")\n",
    "            return\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Group by constellation\n",
    "        const_colors = {'GPS': '#3b82f6', 'GLONASS': '#ef4444', 'Galileo': '#22c55e', 'BeiDou': '#f59e0b'}\n",
    "        const_data = {}\n",
    "        \n",
    "        for sat_trace in skyplot_data:\n",
    "            system = sat_trace.get('system', 'Other')\n",
    "            const_name = {'G': 'GPS', 'R': 'GLONASS', 'E': 'Galileo', 'C': 'BeiDou'}.get(system, system)\n",
    "            \n",
    "            if const_name not in const_data:\n",
    "                const_data[const_name] = {'r': [], 'theta': [], 'cn0': [], 'text': []}\n",
    "            \n",
    "            azimuths = [float(x) for x in sat_trace.get('azimuths', '').split(',') if x]\n",
    "            elevations = [float(x) for x in sat_trace.get('elevations', '').split(',') if x]\n",
    "            cn0_values = [float(x) for x in sat_trace.get('cn0_values', '').split(',') if x]\n",
    "            sat_id = sat_trace.get('satellite', '')\n",
    "            \n",
    "            for az, el, cn0 in zip(azimuths, elevations, cn0_values):\n",
    "                # Convert elevation to radius (90¬∞ at center, 0¬∞ at edge)\n",
    "                r = 90 - el\n",
    "                const_data[const_name]['r'].append(r)\n",
    "                const_data[const_name]['theta'].append(az)\n",
    "                const_data[const_name]['cn0'].append(cn0)\n",
    "                const_data[const_name]['text'].append(f\"{sat_id}: {cn0:.1f} dB-Hz\")\n",
    "        \n",
    "        # Plot each constellation\n",
    "        for i, (const_name, data) in enumerate(const_data.items()):\n",
    "            if data['r']:\n",
    "                fig.add_trace(go.Scatterpolar(\n",
    "                    r=data['r'],\n",
    "                    theta=data['theta'],\n",
    "                    mode='markers',\n",
    "                    name=const_name,\n",
    "                    marker=dict(\n",
    "                        size=8,\n",
    "                        color=data['cn0'],\n",
    "                        colorscale='Viridis',\n",
    "                        cmin=25, cmax=55,\n",
    "                        colorbar=dict(title='CN0 (dB-Hz)') if i == 0 else None,\n",
    "                        showscale=(i == 0)\n",
    "                    ),\n",
    "                    text=data['text'],\n",
    "                    hoverinfo='text'\n",
    "                ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f'CN0 Skyplot (Coverage: {coverage:.1f}%)',\n",
    "            width=650,\n",
    "            height=650,\n",
    "            polar=dict(\n",
    "                radialaxis=dict(\n",
    "                    range=[0, 90],\n",
    "                    tickvals=[0, 30, 60, 90],\n",
    "                    ticktext=['90¬∞', '60¬∞', '30¬∞', '0¬∞']\n",
    "                ),\n",
    "                angularaxis=dict(\n",
    "                    tickvals=[0, 45, 90, 135, 180, 225, 270, 315],\n",
    "                    ticktext=['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW'],\n",
    "                    direction='clockwise',\n",
    "                    rotation=90\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "\n",
    "\n",
    "def show_anomalies(btn):\n",
    "    \"\"\"Show anomaly timeline\"\"\"\n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        print(\"‚ö†Ô∏è Generating anomaly timeline...\")\n",
    "    \n",
    "    result = analysis_results.get('data')\n",
    "    if not result:\n",
    "        result = run_core_analysis()\n",
    "    \n",
    "    if not result:\n",
    "        return\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        \n",
    "        anomalies = result.get_anomalies()\n",
    "        \n",
    "        if not anomalies:\n",
    "            print(\"‚úÖ No anomalies detected!\")\n",
    "            fig = go.Figure()\n",
    "            fig.add_annotation(\n",
    "                text='‚úÖ No anomalies detected',\n",
    "                xref='paper', yref='paper',\n",
    "                x=0.5, y=0.5,\n",
    "                showarrow=False,\n",
    "                font=dict(size=24, color='green')\n",
    "            )\n",
    "            fig.update_layout(title='Anomaly Timeline', height=400)\n",
    "            fig.show()\n",
    "            return\n",
    "        \n",
    "        print(f\"‚ö†Ô∏è Found {len(anomalies)} anomalies\")\n",
    "        \n",
    "        # Parse anomalies\n",
    "        parsed = []\n",
    "        for a in anomalies:\n",
    "            try:\n",
    "                ts_str = a.get('start_time') or a.get('timestamp') or ''\n",
    "                if ts_str:\n",
    "                    parsed.append({\n",
    "                        'time': pd.to_datetime(ts_str),\n",
    "                        'severity': a.get('severity', 'low'),\n",
    "                        'cn0_drop': float(a.get('cn0_drop', 0) or 0),\n",
    "                        'type': a.get('anomaly_type', 'Unknown'),\n",
    "                        'description': a.get('description', '')\n",
    "                    })\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if not parsed:\n",
    "            print(\"‚ö†Ô∏è Could not parse anomaly timestamps\")\n",
    "            return\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        severity_colors = {\n",
    "            'critical': '#ef4444', 'Critical': '#ef4444',\n",
    "            'high': '#f97316', 'High': '#f97316',\n",
    "            'medium': '#eab308', 'Medium': '#eab308',\n",
    "            'low': '#22c55e', 'Low': '#22c55e'\n",
    "        }\n",
    "        \n",
    "        for severity in ['critical', 'high', 'medium', 'low']:\n",
    "            sev_data = [d for d in parsed if d['severity'].lower() == severity]\n",
    "            if sev_data:\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=[d['time'] for d in sev_data],\n",
    "                    y=[d['cn0_drop'] for d in sev_data],\n",
    "                    mode='markers',\n",
    "                    marker=dict(size=10, color=severity_colors.get(severity, '#888')),\n",
    "                    name=f\"{severity.capitalize()} ({len(sev_data)})\",\n",
    "                    text=[f\"{d['type']}<br>{d['description']}\" for d in sev_data],\n",
    "                    hovertemplate=\"Time: %{x}<br>CN0 Drop: %{y:.1f} dB<br>%{text}<extra></extra>\"\n",
    "                ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f'Anomaly Timeline ({len(parsed)} events)',\n",
    "            xaxis_title='Time (UTC)',\n",
    "            xaxis=dict(type='date'),\n",
    "            yaxis_title='CN0 Drop (dB)',\n",
    "            height=450,\n",
    "            legend=dict(orientation='h', y=1.1)\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "\n",
    "\n",
    "def export_report(btn):\n",
    "    \"\"\"Run full analysis silently and offer download\"\"\"\n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        print(\"üì• Generating full report (please wait)...\")\n",
    "        progress.layout.visibility = 'visible'\n",
    "        progress.value = 0.1\n",
    "    \n",
    "    # Run analysis silently\n",
    "    result = run_core_analysis(silent=True)\n",
    "    \n",
    "    if not result:\n",
    "        with results_out:\n",
    "            clear_output()\n",
    "            print(\"‚ùå Could not generate report - check files are loaded\")\n",
    "        progress.layout.visibility = 'hidden'\n",
    "        return\n",
    "    \n",
    "    progress.value = 0.5\n",
    "    \n",
    "    try:\n",
    "        # Generate HTML report\n",
    "        qs = result.quality_score\n",
    "        anomalies = result.get_anomalies()\n",
    "        \n",
    "        # Generate all figures\n",
    "        figures_html = \"\"\n",
    "        \n",
    "        # 1. Quality Radar\n",
    "        fig_radar = go.Figure()\n",
    "        categories = ['Availability', 'CN0 Quality', 'Stability', 'Diversity', 'Continuity']\n",
    "        values = [qs.availability, qs.cn0_quality, qs.stability, qs.diversity, qs.continuity, qs.availability]\n",
    "        fig_radar.add_trace(go.Scatterpolar(r=values, theta=categories + [categories[0]], fill='toself'))\n",
    "        fig_radar.update_layout(polar=dict(radialaxis=dict(range=[0, 100])), title=f\"Quality: {qs.overall:.0f}/100\", height=400)\n",
    "        figures_html += \"<h3>Quality Score</h3>\" + fig_radar.to_html(include_plotlyjs='cdn', full_html=False)\n",
    "        \n",
    "        progress.value = 0.6\n",
    "        \n",
    "        # 2. Timeseries\n",
    "        timestamps = result.get_timestamps()\n",
    "        if timestamps:\n",
    "            ts = pd.to_datetime(timestamps)\n",
    "            mean_cn0 = result.get_mean_cn0_series()\n",
    "            sat_counts = result.get_satellite_count_series()\n",
    "            \n",
    "            fig_ts = make_subplots(rows=2, cols=1, shared_xaxes=True, row_heights=[0.7, 0.3])\n",
    "            fig_ts.add_trace(go.Scatter(x=ts, y=mean_cn0, name='Mean CN0'), row=1, col=1)\n",
    "            fig_ts.add_trace(go.Bar(x=ts, y=sat_counts, showlegend=False), row=2, col=1)\n",
    "            fig_ts.update_layout(height=500, title='CN0 Timeseries')\n",
    "            figures_html += \"<h3>CN0 Timeseries</h3>\" + fig_ts.to_html(include_plotlyjs=False, full_html=False)\n",
    "        \n",
    "        progress.value = 0.7\n",
    "        \n",
    "        # 3. Skyplot\n",
    "        skyplot_data = result.get_skyplot_data()\n",
    "        coverage = result.skyplot_coverage\n",
    "        if skyplot_data:\n",
    "            fig_sky = go.Figure()\n",
    "            const_data = {}\n",
    "            \n",
    "            for sat_trace in skyplot_data:\n",
    "                system = sat_trace.get('system', 'Other')\n",
    "                const_name = {'G': 'GPS', 'R': 'GLONASS', 'E': 'Galileo', 'C': 'BeiDou'}.get(system, system)\n",
    "                \n",
    "                if const_name not in const_data:\n",
    "                    const_data[const_name] = {'r': [], 'theta': [], 'cn0': []}\n",
    "                \n",
    "                azimuths = [float(x) for x in sat_trace.get('azimuths', '').split(',') if x]\n",
    "                elevations = [float(x) for x in sat_trace.get('elevations', '').split(',') if x]\n",
    "                cn0_values = [float(x) for x in sat_trace.get('cn0_values', '').split(',') if x]\n",
    "                \n",
    "                for az, el, cn0 in zip(azimuths, elevations, cn0_values):\n",
    "                    const_data[const_name]['r'].append(90 - el)\n",
    "                    const_data[const_name]['theta'].append(az)\n",
    "                    const_data[const_name]['cn0'].append(cn0)\n",
    "            \n",
    "            for const_name, data in const_data.items():\n",
    "                if data['r']:\n",
    "                    fig_sky.add_trace(go.Scatterpolar(\n",
    "                        r=data['r'], theta=data['theta'], mode='markers', name=const_name,\n",
    "                        marker=dict(size=6, color=data['cn0'], colorscale='Viridis', cmin=25, cmax=55)\n",
    "                    ))\n",
    "            \n",
    "            fig_sky.update_layout(title=f'Skyplot ({coverage:.1f}% coverage)', height=500, \n",
    "                                  polar=dict(radialaxis=dict(range=[0, 90])))\n",
    "            figures_html += \"<h3>Skyplot</h3>\" + fig_sky.to_html(include_plotlyjs=False, full_html=False)\n",
    "        \n",
    "        progress.value = 0.75\n",
    "        \n",
    "        # 4. Time vs Satellite Heatmap\n",
    "        if skyplot_data and timestamps:\n",
    "            sat_data = {}\n",
    "            for sat_trace in skyplot_data:\n",
    "                sat_id = sat_trace.get('satellite', '')\n",
    "                if not sat_id:\n",
    "                    continue\n",
    "                cn0_str = sat_trace.get('cn0_values', '')\n",
    "                ts_str = sat_trace.get('timestamps', '')\n",
    "                if cn0_str and ts_str:\n",
    "                    cn0_vals = [float(x) for x in cn0_str.split(',') if x]\n",
    "                    sat_ts = [x.strip() for x in ts_str.split(',') if x.strip()]\n",
    "                    if len(cn0_vals) == len(sat_ts):\n",
    "                        sat_data[sat_id] = dict(zip(sat_ts, cn0_vals))\n",
    "            \n",
    "            if sat_data:\n",
    "                def sat_sort_key(s):\n",
    "                    if len(s) >= 2:\n",
    "                        sys = s[0]\n",
    "                        try:\n",
    "                            prn = int(s[1:])\n",
    "                        except:\n",
    "                            prn = 0\n",
    "                        sys_order = {'G': 0, 'R': 1, 'E': 2, 'C': 3}\n",
    "                        return (sys_order.get(sys, 9), prn)\n",
    "                    return (9, 0)\n",
    "                \n",
    "                sorted_sats = sorted(sat_data.keys(), key=sat_sort_key, reverse=True)\n",
    "                ts_list = pd.to_datetime(timestamps)\n",
    "                z_matrix = []\n",
    "                y_labels = []\n",
    "                \n",
    "                for sat_id in sorted_sats:\n",
    "                    row = []\n",
    "                    ts_cn0_map = sat_data[sat_id]\n",
    "                    for t in timestamps:\n",
    "                        cn0 = ts_cn0_map.get(t, None)\n",
    "                        row.append(cn0)\n",
    "                    z_matrix.append(row)\n",
    "                    y_labels.append(sat_id)\n",
    "                \n",
    "                fig_time_sat = go.Figure(go.Heatmap(\n",
    "                    z=z_matrix, x=ts_list, y=y_labels,\n",
    "                    colorscale='Viridis', hoverongaps=False, zmin=25, zmax=55\n",
    "                ))\n",
    "                fig_time_sat.update_layout(title='C/N‚ÇÄ Heatmap - Time vs Satellite', \n",
    "                                           height=max(400, len(sorted_sats) * 18 + 100))\n",
    "                figures_html += \"<h3>Time vs Satellite Heatmap</h3>\" + fig_time_sat.to_html(include_plotlyjs=False, full_html=False)\n",
    "        \n",
    "        progress.value = 0.8\n",
    "        \n",
    "        # 5. Az/El Heatmap\n",
    "        if skyplot_data:\n",
    "            az_bins = list(range(0, 361, 15))\n",
    "            el_bins = list(range(0, 91, 5))\n",
    "            cn0_sum = [[0.0 for _ in range(len(az_bins)-1)] for _ in range(len(el_bins)-1)]\n",
    "            cn0_count = [[0 for _ in range(len(az_bins)-1)] for _ in range(len(el_bins)-1)]\n",
    "            \n",
    "            for sat_trace in skyplot_data:\n",
    "                azimuths = [float(x) for x in sat_trace.get('azimuths', '').split(',') if x]\n",
    "                elevations = [float(x) for x in sat_trace.get('elevations', '').split(',') if x]\n",
    "                cn0_values = [float(x) for x in sat_trace.get('cn0_values', '').split(',') if x]\n",
    "                \n",
    "                for az, el, cn0 in zip(azimuths, elevations, cn0_values):\n",
    "                    az_idx = min(int(az / 15), len(az_bins) - 2)\n",
    "                    el_idx = min(int(el / 5), len(el_bins) - 2)\n",
    "                    cn0_sum[el_idx][az_idx] += cn0\n",
    "                    cn0_count[el_idx][az_idx] += 1\n",
    "            \n",
    "            cn0_grid = []\n",
    "            for el_idx in range(len(el_bins) - 1):\n",
    "                row = []\n",
    "                for az_idx in range(len(az_bins) - 1):\n",
    "                    if cn0_count[el_idx][az_idx] > 0:\n",
    "                        row.append(cn0_sum[el_idx][az_idx] / cn0_count[el_idx][az_idx])\n",
    "                    else:\n",
    "                        row.append(None)\n",
    "                cn0_grid.append(row)\n",
    "            \n",
    "            if not all(all(v is None for v in row) for row in cn0_grid):\n",
    "                fig_hm = go.Figure(go.Heatmap(z=cn0_grid, colorscale='Viridis', hoverongaps=False))\n",
    "                fig_hm.update_layout(title='CN0 Heatmap by Az/El', height=400, xaxis_title='Azimuth', yaxis_title='Elevation')\n",
    "                figures_html += \"<h3>CN0 Heatmap (Az/El)</h3>\" + fig_hm.to_html(include_plotlyjs=False, full_html=False)\n",
    "        \n",
    "        progress.value = 0.9\n",
    "        \n",
    "        # Build full HTML\n",
    "        html = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>GeoVeil CN0 Report - {result.filename}</title>\n",
    "    <style>\n",
    "        body {{ font-family: Arial, sans-serif; margin: 40px; background: #f5f5f5; }}\n",
    "        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; }}\n",
    "        h1 {{ color: #1a365d; border-bottom: 3px solid #3182ce; padding-bottom: 10px; }}\n",
    "        h2 {{ color: #2c5282; }}\n",
    "        .score {{ font-size: 48px; font-weight: bold; color: {'#22c55e' if qs.overall >= 80 else '#eab308' if qs.overall >= 60 else '#ef4444'}; }}\n",
    "        .metric {{ display: inline-block; margin: 10px; padding: 15px; background: #f0f0f0; border-radius: 8px; }}\n",
    "        .metric-value {{ font-size: 24px; font-weight: bold; }}\n",
    "        .ok {{ color: #22c55e; }}\n",
    "        .warn {{ color: #eab308; }}\n",
    "        .danger {{ color: #ef4444; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "<div class=\"container\">\n",
    "    <h1>üì° GeoVeil CN0 Analysis Report</h1>\n",
    "    \n",
    "    <h2>üìÅ File Information</h2>\n",
    "    <p><b>File:</b> {result.filename}<br>\n",
    "    <b>Duration:</b> {result.duration_hours:.2f} hours ({result.epoch_count} epochs)<br>\n",
    "    <b>Constellations:</b> {', '.join(result.get_systems())}</p>\n",
    "    \n",
    "    <h2>üèÜ Quality Score</h2>\n",
    "    <p class=\"score\">{qs.overall:.0f}/100 ({qs.rating})</p>\n",
    "    <div class=\"metric\"><div class=\"metric-value\">{qs.cn0_quality:.0f}</div>CN0 Quality</div>\n",
    "    <div class=\"metric\"><div class=\"metric-value\">{qs.availability:.0f}</div>Availability</div>\n",
    "    <div class=\"metric\"><div class=\"metric-value\">{qs.continuity:.0f}</div>Continuity</div>\n",
    "    <div class=\"metric\"><div class=\"metric-value\">{qs.stability:.0f}</div>Stability</div>\n",
    "    \n",
    "    <h2>üì∂ Signal Quality</h2>\n",
    "    <p><b>Mean CN0:</b> {result.mean_cn0:.1f} dB-Hz<br>\n",
    "    <b>Std Dev:</b> {result.cn0_std_dev:.1f} dB-Hz<br>\n",
    "    <b>Range:</b> {result.min_cn0:.1f} - {result.max_cn0:.1f} dB-Hz</p>\n",
    "    \n",
    "    <h2>üõ°Ô∏è Threat Assessment</h2>\n",
    "    <p><span class=\"{'danger' if result.jamming_detected else 'ok'}\">Jamming: {'üö® DETECTED' if result.jamming_detected else '‚úÖ None'}</span><br>\n",
    "    <span class=\"{'danger' if result.spoofing_detected else 'ok'}\">Spoofing: {'üö® DETECTED' if result.spoofing_detected else '‚úÖ None'}</span><br>\n",
    "    <span class=\"{'warn' if result.interference_detected else 'ok'}\">Interference: {'‚ö†Ô∏è Detected' if result.interference_detected else '‚úÖ None'}</span></p>\n",
    "    \n",
    "    <p><b>Summary:</b> {result.summary}</p>\n",
    "    \n",
    "    <h2>üìä Analysis Charts</h2>\n",
    "    {figures_html}\n",
    "    \n",
    "    <h2>‚ö†Ô∏è Anomalies ({len(anomalies)} detected)</h2>\n",
    "    {'<p>No significant anomalies detected.</p>' if not anomalies else f'<p>{len(anomalies)} anomaly events recorded. See anomaly chart above.</p>'}\n",
    "    \n",
    "    <hr>\n",
    "    <p><small>Generated by GeoVeil CN0 v{gcn0.VERSION} on {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}</small></p>\n",
    "</div>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "        \n",
    "        progress.value = 1.0\n",
    "        \n",
    "        # Save to temp file and offer download\n",
    "        import tempfile\n",
    "        import base64\n",
    "        \n",
    "        filename = f\"cn0_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html\"\n",
    "        \n",
    "        # Create download link\n",
    "        b64 = base64.b64encode(html.encode()).decode()\n",
    "        \n",
    "        with results_out:\n",
    "            clear_output()\n",
    "            print(f\"‚úÖ Report generated: {filename}\")\n",
    "            print(f\"   Quality Score: {qs.overall:.0f}/100 ({qs.rating})\")\n",
    "            print(f\"   Anomalies: {len(anomalies)}\")\n",
    "            print()\n",
    "            \n",
    "            # Display download link\n",
    "            download_link = f'<a download=\"{filename}\" href=\"data:text/html;base64,{b64}\" style=\"font-size:18px; padding:10px 20px; background:#22c55e; color:white; text-decoration:none; border-radius:5px;\">üì• Download Report ({len(html)//1024} KB)</a>'\n",
    "            display(HTML(download_link))\n",
    "        \n",
    "        progress.layout.visibility = 'hidden'\n",
    "        \n",
    "    except Exception as e:\n",
    "        with results_out:\n",
    "            clear_output()\n",
    "            print(f\"‚ùå Export error: {e}\")\n",
    "        progress.layout.visibility = 'hidden'\n",
    "\n",
    "\n",
    "def clear_all(btn):\n",
    "    \"\"\"Clear all outputs\"\"\"\n",
    "    with info_out:\n",
    "        clear_output()\n",
    "    with results_out:\n",
    "        clear_output()\n",
    "    analysis_results['data'] = None\n",
    "    analysis_results['figures'] = {}\n",
    "    status.value = \"<b>Status:</b> Cleared\"\n",
    "\n",
    "\n",
    "def load_files(btn):\n",
    "    \"\"\"Load files from paths OR upload widgets\"\"\"\n",
    "    with info_out:\n",
    "        clear_output()\n",
    "        print(\"üì• Loading files...\")\n",
    "        \n",
    "        obs_loaded = False\n",
    "        nav_loaded = False\n",
    "        \n",
    "        # ===== OBSERVATION FILE =====\n",
    "        if obs_path_input.value.strip():\n",
    "            path = obs_path_input.value.strip()\n",
    "            print(f\"\\nüìÇ Loading OBS from path: {path}\")\n",
    "            \n",
    "            if os.path.exists(path):\n",
    "                try:\n",
    "                    with open(path, 'rb') as f:\n",
    "                        content = f.read()\n",
    "                    \n",
    "                    # Handle gzip\n",
    "                    if path.endswith('.gz'):\n",
    "                        content = gzip.decompress(content)\n",
    "                    \n",
    "                    loaded_data['obs_content'] = content\n",
    "                    loaded_data['obs_filename'] = os.path.basename(path)\n",
    "                    loaded_data['obs_path'] = path\n",
    "                    obs_loaded = True\n",
    "                    print(f\"   ‚úÖ Loaded: {loaded_data['obs_filename']} ({len(content)/1024:.1f} KB)\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Error: {e}\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå File not found: {path}\")\n",
    "        \n",
    "        elif obs_upload.value:\n",
    "            file_info = list(obs_upload.value.values())[0]\n",
    "            content = file_info['content']\n",
    "            filename = file_info['metadata']['name']\n",
    "            \n",
    "            print(f\"\\nüì§ Loading uploaded OBS: {filename}\")\n",
    "            \n",
    "            if filename.endswith('.gz'):\n",
    "                content = gzip.decompress(content)\n",
    "                filename = filename[:-3]\n",
    "            \n",
    "            loaded_data['obs_content'] = content\n",
    "            loaded_data['obs_filename'] = filename\n",
    "            obs_loaded = True\n",
    "            print(f\"   ‚úÖ Loaded: {filename} ({len(content)/1024:.1f} KB)\")\n",
    "        \n",
    "        # ===== NAVIGATION FILE =====\n",
    "        if nav_path_input.value.strip():\n",
    "            path = nav_path_input.value.strip()\n",
    "            print(f\"\\nüìÇ Loading NAV from path: {path}\")\n",
    "            \n",
    "            if os.path.exists(path):\n",
    "                try:\n",
    "                    with open(path, 'rb') as f:\n",
    "                        content = f.read()\n",
    "                    \n",
    "                    if path.endswith('.gz'):\n",
    "                        content = gzip.decompress(content)\n",
    "                    \n",
    "                    loaded_data['nav_content'] = content\n",
    "                    loaded_data['nav_filename'] = os.path.basename(path)\n",
    "                    loaded_data['nav_path'] = path\n",
    "                    nav_loaded = True\n",
    "                    print(f\"   ‚úÖ Loaded: {loaded_data['nav_filename']} ({len(content)/1024:.1f} KB)\")\n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Error: {e}\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå File not found: {path}\")\n",
    "        \n",
    "        elif nav_upload.value:\n",
    "            file_info = list(nav_upload.value.values())[0]\n",
    "            content = file_info['content']\n",
    "            filename = file_info['metadata']['name']\n",
    "            \n",
    "            print(f\"\\nüì§ Loading uploaded NAV: {filename}\")\n",
    "            \n",
    "            if filename.endswith('.gz'):\n",
    "                content = gzip.decompress(content)\n",
    "                filename = filename[:-3]\n",
    "            \n",
    "            loaded_data['nav_content'] = content\n",
    "            loaded_data['nav_filename'] = filename\n",
    "            nav_loaded = True\n",
    "            print(f\"   ‚úÖ Loaded: {filename} ({len(content)/1024:.1f} KB)\")\n",
    "        \n",
    "        # ===== AUTO-DOWNLOAD NAV =====\n",
    "        if not nav_loaded and obs_loaded and auto_download_nav.value:\n",
    "            print(\"\\nüåê Attempting to auto-download navigation...\")\n",
    "            \n",
    "            # Try to get date from file header first (most reliable)\n",
    "            year, doy = NavDownloader.parse_rinex_header(loaded_data['obs_content'])\n",
    "            \n",
    "            # Fall back to filename parsing if header didn't work\n",
    "            if not year or not doy:\n",
    "                year, doy = NavDownloader.parse_rinex_date(loaded_data['obs_filename'])\n",
    "            \n",
    "            if year and doy:\n",
    "                print(f\"   Detected date: {year} DOY {doy}\")\n",
    "                \n",
    "                nav_path = NavDownloader.download(year, doy, tempfile.gettempdir(), log_func=print)\n",
    "                \n",
    "                if nav_path and nav_path.exists():\n",
    "                    with open(nav_path, 'rb') as f:\n",
    "                        loaded_data['nav_content'] = f.read()\n",
    "                    loaded_data['nav_filename'] = nav_path.name\n",
    "                    loaded_data['nav_path'] = str(nav_path)\n",
    "                    nav_loaded = True\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è Could not determine date from filename or header\")\n",
    "        \n",
    "        # ===== SUMMARY =====\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        if obs_loaded:\n",
    "            print(f\"‚úÖ OBS: {loaded_data['obs_filename']}\")\n",
    "        else:\n",
    "            print(\"‚ùå OBS: Not loaded\")\n",
    "        \n",
    "        if nav_loaded:\n",
    "            print(f\"‚úÖ NAV: {loaded_data['nav_filename']}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è NAV: Not loaded (skyplots will be limited)\")\n",
    "        \n",
    "        if obs_loaded:\n",
    "            status.value = f\"<b>Status:</b> ‚úÖ Files loaded - click output buttons to analyze\"\n",
    "            analysis_results['data'] = None  # Clear old results\n",
    "        else:\n",
    "            status.value = \"<b>Status:</b> ‚ùå No observation file loaded\"\n",
    "\n",
    "\n",
    "# ============ CONNECT HANDLERS ============\n",
    "load_btn.on_click(load_files)\n",
    "btn_summary.on_click(show_summary)\n",
    "btn_heatmap.on_click(show_heatmap)\n",
    "btn_snr.on_click(show_snr_graphs)\n",
    "btn_skyplot.on_click(show_skyplot)\n",
    "btn_anomaly.on_click(show_anomalies)\n",
    "export_btn.on_click(export_report)\n",
    "clear_btn.on_click(clear_all)\n",
    "\n",
    "# ============ LAYOUT ============\n",
    "file_box = widgets.VBox([\n",
    "    header,\n",
    "    obs_section,\n",
    "    widgets.HBox([obs_upload, obs_path_input]),\n",
    "    nav_section,\n",
    "    widgets.HBox([nav_upload, nav_path_input]),\n",
    "    widgets.HBox([auto_download_nav, load_btn]),\n",
    "])\n",
    "\n",
    "config_box = widgets.VBox([\n",
    "    config_section,\n",
    "    elevation_slider,\n",
    "    time_bin_slider,\n",
    "    widgets.HBox([system_checks['G'], system_checks['R'], system_checks['E'], system_checks['C']]),\n",
    "])\n",
    "\n",
    "# NEW: Output buttons in a row\n",
    "output_buttons = widgets.HBox([\n",
    "    btn_summary, btn_heatmap, btn_snr, btn_skyplot, btn_anomaly\n",
    "], layout=widgets.Layout(margin='10px 0'))\n",
    "\n",
    "action_box = widgets.VBox([\n",
    "    buttons_section,\n",
    "    output_buttons,\n",
    "    widgets.HBox([export_btn, clear_btn]),\n",
    "    progress,\n",
    "    status\n",
    "])\n",
    "\n",
    "main_widget = widgets.VBox([\n",
    "    file_box,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    config_box,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    action_box,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    info_out,\n",
    "    results_out\n",
    "])\n",
    "\n",
    "# Display the widget\n",
    "display(main_widget)\n",
    "print(\"‚úÖ Widget loaded - use buttons above to analyze GNSS data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check what data structure we have\n",
    "result = analysis_results.get('data')\n",
    "if result:\n",
    "    print(\"=== Available methods ===\")\n",
    "    methods = [m for m in dir(result) if not m.startswith('_')]\n",
    "    for m in methods:\n",
    "        print(f\"  {m}\")\n",
    "    \n",
    "    print(\"\\n=== Skyplot data sample ===\")\n",
    "    skyplot = result.get_skyplot_data()\n",
    "    if skyplot and len(skyplot) > 0:\n",
    "        print(f\"Number of satellite traces: {len(skyplot)}\")\n",
    "        print(f\"First trace keys: {skyplot[0].keys() if isinstance(skyplot[0], dict) else type(skyplot[0])}\")\n",
    "        print(f\"First trace: {skyplot[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Verify RINEX parsing and satellite counts\n",
    "# Run this cell after loading files to compare direct parsing vs analysis\n",
    "\n",
    "def debug_rinex_parsing():\n",
    "    \"\"\"Compare direct RINEX satellite count with analysis results\"\"\"\n",
    "    import geoveil_cn0 as gcn0\n",
    "    \n",
    "    if not loaded_data.get('obs_content'):\n",
    "        print(\"‚ùå No observation file loaded!\")\n",
    "        return\n",
    "    \n",
    "    # Parse RINEX directly\n",
    "    # Try new name first, fall back to old\n",
    "    try:\n",
    "        obs = gcn0.parse_rinex(loaded_data['obs_content'], loaded_data['obs_filename'])\n",
    "    except AttributeError:\n",
    "        obs = gcn0.read_rinex_obs_bytes(loaded_data['obs_content'], loaded_data['obs_filename'])\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üîç RINEX PARSING DEBUG INFO\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get debug info\n",
    "    debug = obs.debug_info()\n",
    "    \n",
    "    print(f\"\\nüìÑ File: {loaded_data['obs_filename']}\")\n",
    "    print(f\"   Version: {debug.get('version', 'N/A')}\")\n",
    "    print(f\"   Epochs: {debug.get('num_epochs', 'N/A')}\")\n",
    "    print(f\"   Total Satellites: {debug.get('num_satellites', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\nüì° SATELLITES BY CONSTELLATION:\")\n",
    "    sats_by_sys = obs.satellites_by_system()\n",
    "    for sys in sorted(sats_by_sys.keys()):\n",
    "        sats = sats_by_sys[sys]\n",
    "        sys_name = {'G': 'GPS', 'R': 'GLONASS', 'E': 'Galileo', 'C': 'BeiDou', 'J': 'QZSS', 'I': 'NavIC'}.get(sys, sys)\n",
    "        print(f\"   {sys_name:10} ({sys}): {len(sats):2} satellites - {', '.join(sorted(sats))}\")\n",
    "    \n",
    "    print(f\"\\nüìä OBSERVATION TYPES BY SYSTEM:\")\n",
    "    obs_types = obs.obs_types_by_system()\n",
    "    for sys in sorted(obs_types.keys()):\n",
    "        types = obs_types[sys]\n",
    "        snr_types = [t for t in types if t.startswith('S')]\n",
    "        sys_name = {'G': 'GPS', 'R': 'GLONASS', 'E': 'Galileo', 'C': 'BeiDou', 'J': 'QZSS', 'I': 'NavIC'}.get(sys, sys)\n",
    "        print(f\"   {sys_name:10} ({sys}): {len(types):2} types, {len(snr_types)} SNR\")\n",
    "        print(f\"      All: {', '.join(types[:15])}{'...' if len(types) > 15 else ''}\")\n",
    "        if snr_types:\n",
    "            print(f\"      SNR: {', '.join(snr_types)}\")\n",
    "        else:\n",
    "            print(f\"      ‚ö†Ô∏è  NO SNR TYPES FOUND!\")\n",
    "    \n",
    "    print(f\"\\nüî¨ SNR AVAILABILITY:\")\n",
    "    snr_avail = obs.snr_availability()\n",
    "    for sys in sorted(snr_avail.keys()):\n",
    "        has_snr = snr_avail[sys]\n",
    "        sys_name = {'G': 'GPS', 'R': 'GLONASS', 'E': 'Galileo', 'C': 'BeiDou', 'J': 'QZSS', 'I': 'NavIC'}.get(sys, sys)\n",
    "        status = \"‚úÖ Yes\" if has_snr else \"‚ùå No\"\n",
    "        print(f\"   {sys_name:10} ({sys}): {status}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    return obs\n",
    "\n",
    "# Run debug\n",
    "if loaded_data.get('obs_content'):\n",
    "    _debug_obs = debug_rinex_parsing()\n",
    "else:\n",
    "    print(\"Load files first, then run this cell\")\n",
    "\n",
    "def debug_visibility():\n",
    "    \"\"\"Debug visibility prediction\"\"\"\n",
    "    if not loaded_data.get('nav_content'):\n",
    "        print(\"‚ö†Ô∏è No navigation data loaded - visibility prediction unavailable\")\n",
    "        return\n",
    "    \n",
    "    result = analysis_results.get('data') if 'analysis_results' in dir() else None\n",
    "    if not result or not result.has_visibility_prediction:\n",
    "        print(\"‚ö†Ô∏è No visibility prediction available\")\n",
    "        return\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üîç VISIBILITY PREDICTION DEBUG\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    vis_debug = result.visibility_debug()\n",
    "    \n",
    "    # Overall stats\n",
    "    if '_overall' in vis_debug:\n",
    "        overall = vis_debug['_overall']\n",
    "        print(f\"\\nüì° Source: {overall.get('source', 'unknown')}\")\n",
    "        print(f\"   Mean predicted: {overall.get('mean_predicted', 'N/A')} satellites/epoch\")\n",
    "        print(f\"   Mean observed: {overall.get('mean_observed', 'N/A')} satellites/epoch\")\n",
    "        print(f\"   Mean missing: {overall.get('mean_missing', 'N/A')}\")\n",
    "        print(f\"   Mean unexpected: {overall.get('mean_unexpected', 'N/A')}\")\n",
    "        print(f\"   Confirmation rate: {overall.get('confirmation_rate', 'N/A')}\")\n",
    "    \n",
    "    print(\"\\nüõ∞Ô∏è PER-SYSTEM BREAKDOWN:\")\n",
    "    for sys_name in ['GPS', 'GLONASS', 'Galileo', 'BeiDou']:\n",
    "        if sys_name in vis_debug:\n",
    "            info = vis_debug[sys_name]\n",
    "            predicted = info.get('predicted', '0')\n",
    "            observed = info.get('observed', '0')\n",
    "            conf_rate = info.get('confirmation_rate', 'N/A')\n",
    "            unexpected = info.get('unexpected_count', '0')\n",
    "            unexpected_sats = info.get('unexpected_sats', '')\n",
    "            \n",
    "            print(f\"\\n   {sys_name}:\")\n",
    "            print(f\"      Predicted (from nav): {predicted}\")\n",
    "            print(f\"      Observed (in RINEX): {observed}\")\n",
    "            print(f\"      Confirmation rate: {conf_rate}\")\n",
    "            if int(unexpected) > 0:\n",
    "                print(f\"      ‚ö†Ô∏è Unexpected satellites: {unexpected} ({unexpected_sats})\")\n",
    "                print(f\"         (These are in RINEX but not in nav file)\")\n",
    "\n",
    "# Run if navigation data available\n",
    "if loaded_data.get('nav_content') and 'analysis_results' in dir() and analysis_results.get('data'):\n",
    "    debug_visibility()\n",
    "\n",
    "def debug_satellite_comparison():\n",
    "    \"\"\"Compare satellites in RINEX vs Analysis result\"\"\"\n",
    "    if not loaded_data.get('obs_content'):\n",
    "        print(\"Load files first\")\n",
    "        return\n",
    "    \n",
    "    result = analysis_results.get('data') if 'analysis_results' in dir() else None\n",
    "    if not result:\n",
    "        print(\"Run analysis first\")\n",
    "        return\n",
    "    \n",
    "    import geoveil_cn0 as gcn0\n",
    "    import json as js\n",
    "    \n",
    "    # Parse RINEX\n",
    "    try:\n",
    "        obs = gcn0.parse_rinex(loaded_data['obs_content'], loaded_data['obs_filename'])\n",
    "    except AttributeError:\n",
    "        obs = gcn0.read_rinex_obs_bytes(loaded_data['obs_content'], loaded_data['obs_filename'])\n",
    "    \n",
    "    rinex_sats = obs.satellites_by_system()\n",
    "    \n",
    "    # Get analysis result satellites from JSON\n",
    "    result_json = js.loads(result.to_json())\n",
    "    timeseries_sats = result_json.get('timeseries', {}).get('satellite_timeseries', {}).keys()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üîç SATELLITE COMPARISON: RINEX vs Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    sys_names = {'G': 'GPS', 'R': 'GLONASS', 'E': 'Galileo', 'C': 'BeiDou', 'J': 'QZSS', 'I': 'NavIC'}\n",
    "    \n",
    "    for sys_code in sorted(rinex_sats.keys()):\n",
    "        sys_name = sys_names.get(sys_code, sys_code)\n",
    "        rinex_set = set(rinex_sats[sys_code])\n",
    "        ts_set = set(s for s in timeseries_sats if s.startswith(sys_code))\n",
    "        \n",
    "        in_rinex_only = rinex_set - ts_set\n",
    "        in_ts_only = ts_set - rinex_set\n",
    "        in_both = rinex_set & ts_set\n",
    "        \n",
    "        print(f\"\\n{sys_name} ({sys_code}):\")\n",
    "        print(f\"   RINEX: {len(rinex_set)} satellites - {', '.join(sorted(rinex_set))}\")\n",
    "        print(f\"   Timeseries: {len(ts_set)} satellites - {', '.join(sorted(ts_set))}\")\n",
    "        \n",
    "        if in_rinex_only:\n",
    "            print(f\"   ‚ö†Ô∏è  Missing from timeseries: {', '.join(sorted(in_rinex_only))}\")\n",
    "            print(f\"      (These satellites have no valid SNR data or are filtered out)\")\n",
    "        if in_ts_only:\n",
    "            print(f\"   ‚ùì Extra in timeseries: {', '.join(sorted(in_ts_only))}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Run if both data available\n",
    "if loaded_data.get('obs_content') and 'analysis_results' in dir() and analysis_results.get('data'):\n",
    "    debug_satellite_comparison()\n",
    "\n",
    "def debug_snr_content():\n",
    "    \"\"\"Analyze SNR data availability in RINEX file\"\"\"\n",
    "    if not loaded_data.get('obs_content'):\n",
    "        print(\"Load files first\")\n",
    "        return\n",
    "    \n",
    "    import geoveil_cn0 as gcn0\n",
    "    \n",
    "    try:\n",
    "        obs = gcn0.parse_rinex(loaded_data['obs_content'], loaded_data['obs_filename'])\n",
    "    except AttributeError:\n",
    "        obs = gcn0.read_rinex_obs_bytes(loaded_data['obs_content'], loaded_data['obs_filename'])\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üî¨ SNR DATA ANALYSIS PER SATELLITE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get SNR statistics per satellite\n",
    "    snr_stats = obs.snr_stats_by_satellite()\n",
    "    \n",
    "    sys_names = {'G': 'GPS', 'R': 'GLONASS', 'E': 'Galileo', 'C': 'BeiDou', 'J': 'QZSS', 'I': 'NavIC'}\n",
    "    \n",
    "    # Group by system\n",
    "    by_system = {}\n",
    "    for sat_id, stats in snr_stats.items():\n",
    "        sys_code = sat_id[0]\n",
    "        if sys_code not in by_system:\n",
    "            by_system[sys_code] = []\n",
    "        by_system[sys_code].append((sat_id, stats))\n",
    "    \n",
    "    for sys_code in sorted(by_system.keys()):\n",
    "        sys_name = sys_names.get(sys_code, sys_code)\n",
    "        print(f\"\\n{sys_name} ({sys_code}):\")\n",
    "        \n",
    "        for sat_id, stats in sorted(by_system[sys_code]):\n",
    "            obs_count = stats.get('obs_count', 0)\n",
    "            valid_count = stats.get('valid_count', 0)\n",
    "            mean_snr = stats.get('mean_snr', 0)\n",
    "            \n",
    "            status = \"‚úÖ\" if valid_count > 0 else \"‚ùå\"\n",
    "            print(f\"   {sat_id}: {status} {valid_count}/{obs_count} valid SNR obs, mean={mean_snr:.1f} dB-Hz\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Satellites with ‚ùå have no valid SNR data and won't appear in timeseries\")\n",
    "\n",
    "# Uncomment to run:\n",
    "# debug_snr_content()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Extract and build library\n",
    "[ ! -d geoveil-cn0 ] && [ -f geoveil-cn0.tar.gz ] && tar -xzf geoveil-cn0.tar.gz\n",
    "\n",
    "# Source cargo environment (required after fresh install)\n",
    ". \"$HOME/.cargo/env\"\n",
    "\n",
    "cd geoveil-cn0\n",
    "echo \"üî® Building with Python bindings...\"\n",
    "maturin develop --features python --release 2>&1 | tail -15\n",
    "echo \"‚úÖ Build complete!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Programmatic API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick: result = gcn0.analyze_rinex('file.rnx')\n",
    "# Config: config = gcn0.AnalysisConfig(min_elevation=10, anomaly_sensitivity=0.8)\n",
    "#         result = gcn0.CN0Analyzer(config).analyze_file('file.rnx')\n",
    "# Presets: gcn0.AnalysisConfig.high_precision() / .quick() / .interference_monitoring()\n",
    "# Results: result.score, result.rating, result.jamming_detected, result.get_anomalies()\n",
    "#          result.get_timeseries_data(), result.get_skyplot_data(), result.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Reference\n",
    "\n",
    "| Class | Description |\n",
    "|-------|-------------|\n",
    "| `CN0Analyzer` | Rust analyzer |\n",
    "| `AnalysisConfig` | Config + presets |\n",
    "| `AnalysisResult` | Results container |\n",
    "\n",
    "**90% Rust** - parsing, analysis, anomaly detection. **10% Python** - UI & plots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
