{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì° GeoVeil CN0 Analysis Widget - v6.1\n",
    "\n",
    "**Performance Edition** - Optimized with parallel processing & detailed timing\n",
    "\n",
    "## üöÄ Performance Optimizations\n",
    "- ‚ö° **Parallel file I/O** - Load OBS/NAV files concurrently\n",
    "- ‚ö° **Rust-powered analysis** - Native speed for CN0 processing  \n",
    "- ‚ö° **Multi-threaded data extraction** - Uses all CPU cores\n",
    "- ‚ö° **Automatic downsampling** - Handle large datasets efficiently\n",
    "- ‚è±Ô∏è **Timing output** - See exactly where time is spent\n",
    "\n",
    "## üìÅ Auto-Export Files\n",
    "| Button | Files Saved |\n",
    "|--------|-------------|\n",
    "| **üìä Summary** | `quality_radar.png`, `cn0_boxplot.png`, `satellite_count.png`, `analysis_log.txt`, `constellation_stats.csv`, `full_results.json` |\n",
    "| **üìà SNR Graphs** | `cn0_timeseries.png`, `cn0_gps.png`, `cn0_glonass.png`, `cn0_galileo.png`, `cn0_beidou.png` |\n",
    "| **üó∫Ô∏è Heatmaps** | `heatmap_time_satellite.png`, `heatmap_azel.png` |\n",
    "| **üõ∞Ô∏è Skyplot** | `skyplot.png` *(only satellites with CN0 data shown)* |\n",
    "| **üì• Report** | `report.html` with embedded PNGs |\n",
    "\n",
    "## üî¥ Threat Detection Explanations\n",
    "When threats are detected, detailed explanations are provided:\n",
    "- **Jamming** - Broadband interference causing CN0 drops across satellites\n",
    "- **Spoofing** - Suspicious patterns suggesting fake GNSS signals  \n",
    "- **Interference** - Localized signal degradation from multipath/electronics\n",
    "\n",
    "## üìã Usage\n",
    "1. Run all cells in order\n",
    "2. Load RINEX observation file (path or upload)\n",
    "3. Enable \"Auto-download BRDC\" for navigation data *(recommended)*\n",
    "4. Click **Analyze** to run\n",
    "5. View results with buttons *(each auto-saves to export folder)*\n",
    "6. Click **Download Report** for HTML summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build Rust Library (Linux/Mac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LINUX/MAC BUILD ===\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import glob\n",
    "\n",
    "print(\"üêß Linux/Mac Build for geoveil_cn0\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    print(\"‚ö†Ô∏è This cell is for Linux/Mac. Use the Windows build cell instead.\")\n",
    "else:\n",
    "    NOTEBOOK_DIR = os.getcwd()\n",
    "    \n",
    "    # Setup PATH for cargo/maturin\n",
    "    cargo_bin = os.path.expanduser(\"~/.cargo/bin\")\n",
    "    local_bin = os.path.expanduser(\"~/.local/bin\")\n",
    "    os.environ[\"PATH\"] = f\"{cargo_bin}:{local_bin}:\" + os.environ.get(\"PATH\", \"\")\n",
    "    \n",
    "    # Find or extract library\n",
    "    LIB_PATH = None\n",
    "    for candidate in [\n",
    "        os.path.join(NOTEBOOK_DIR, 'geoveil-cn0'),\n",
    "        os.path.join(NOTEBOOK_DIR, 'geoveil_cn0'),\n",
    "    ]:\n",
    "        if os.path.exists(os.path.join(candidate, 'Cargo.toml')):\n",
    "            LIB_PATH = candidate\n",
    "            break\n",
    "    \n",
    "    if not LIB_PATH:\n",
    "        tar_file = os.path.join(NOTEBOOK_DIR, 'geoveil-cn0.tar.gz')\n",
    "        if os.path.exists(tar_file):\n",
    "            print(\"üì¶ Extracting geoveil-cn0.tar.gz...\")\n",
    "            import tarfile\n",
    "            with tarfile.open(tar_file, 'r:gz') as tar:\n",
    "                tar.extractall(NOTEBOOK_DIR)\n",
    "            LIB_PATH = os.path.join(NOTEBOOK_DIR, 'geoveil-cn0')\n",
    "    \n",
    "    if not LIB_PATH:\n",
    "        raise FileNotFoundError(\"geoveil-cn0 directory not found\")\n",
    "    \n",
    "    print(f\"üìÅ Library: {LIB_PATH}\")\n",
    "    print(f\"üêç Python: {sys.version.split()[0]}\")\n",
    "    \n",
    "    # Check Rust\n",
    "    print(\"\\nüîß Checking Rust...\")\n",
    "    result = subprocess.run(['rustc', '--version'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"‚úÖ {result.stdout.strip()}\")\n",
    "    else:\n",
    "        print(\"‚ùå Rust not found. Install: curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\")\n",
    "        raise RuntimeError(\"Rust not installed\")\n",
    "    \n",
    "    # Check maturin\n",
    "    print(\"\\nüì¶ Checking maturin...\")\n",
    "    result = subprocess.run([sys.executable, '-m', 'maturin', '--version'], capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"   Installing maturin...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'maturin>=1.4'])\n",
    "    result = subprocess.run([sys.executable, '-m', 'maturin', '--version'], capture_output=True, text=True)\n",
    "    print(f\"‚úÖ {result.stdout.strip()}\")\n",
    "    \n",
    "    # Build\n",
    "    print(\"\\nüî® Building (this may take 2-5 minutes)...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    wheel_dir = os.path.join(LIB_PATH, 'target', 'wheels')\n",
    "    \n",
    "    # Set environment for Python 3.13+ compatibility\n",
    "    env = os.environ.copy()\n",
    "    env['PYO3_USE_ABI3_FORWARD_COMPATIBILITY'] = '1'\n",
    "    \n",
    "    result = subprocess.run(\n",
    "        [sys.executable, '-m', 'maturin', 'build', '--release', '-o', wheel_dir],\n",
    "        cwd=LIB_PATH,\n",
    "        env=env,\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(f\"Build output: {result.stdout}\")\n",
    "        print(f\"Build errors: {result.stderr}\")\n",
    "        raise RuntimeError(\"Build failed\")\n",
    "    \n",
    "    # Find and install wheel\n",
    "    wheels = glob.glob(os.path.join(wheel_dir, '*.whl'))\n",
    "    if not wheels:\n",
    "        raise RuntimeError(\"No wheel found after build\")\n",
    "    \n",
    "    wheel = sorted(wheels)[-1]\n",
    "    print(f\"\\nüì¶ Installing: {os.path.basename(wheel)}\")\n",
    "    \n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--force-reinstall', '-q', wheel])\n",
    "    \n",
    "    # Test import\n",
    "    import geoveil_cn0 as gcn0\n",
    "    print(f\"\\n‚úÖ geoveil_cn0 v{gcn0.VERSION} installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Windows Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === WINDOWS BUILD ===\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import glob\n",
    "\n",
    "print(\"ü™ü Windows Build for geoveil_cn0\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if platform.system() != 'Windows':\n",
    "    print(\"‚ö†Ô∏è This cell is for Windows. Use the Linux/Mac build cell instead.\")\n",
    "else:\n",
    "    NOTEBOOK_DIR = os.getcwd()\n",
    "    \n",
    "    # Find library\n",
    "    LIB_PATH = None\n",
    "    for candidate in [\n",
    "        os.path.join(NOTEBOOK_DIR, 'geoveil-cn0'),\n",
    "        os.path.join(NOTEBOOK_DIR, 'geoveil_cn0'),\n",
    "    ]:\n",
    "        if os.path.exists(os.path.join(candidate, 'Cargo.toml')):\n",
    "            LIB_PATH = candidate\n",
    "            break\n",
    "    \n",
    "    if not LIB_PATH:\n",
    "        raise FileNotFoundError(\"geoveil-cn0 directory not found\")\n",
    "    \n",
    "    print(f\"üìÅ Library: {LIB_PATH}\")\n",
    "    \n",
    "    # Check Rust\n",
    "    result = subprocess.run(['cargo', '--version'], capture_output=True, text=True, shell=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"‚úÖ {result.stdout.strip()}\")\n",
    "    else:\n",
    "        print(\"‚ùå Rust not found. Install from: https://rustup.rs\")\n",
    "        raise RuntimeError(\"Rust not installed\")\n",
    "    \n",
    "    # Install maturin\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'maturin>=1.4'])\n",
    "    \n",
    "    # Build with maturin develop\n",
    "    print(\"\\nüî® Building...\")\n",
    "    build_cmd = f'cd /d \"{LIB_PATH}\" && \"{sys.executable}\" -m maturin develop --release'\n",
    "    ret = os.system(build_cmd)\n",
    "    \n",
    "    if ret != 0:\n",
    "        raise RuntimeError(f\"Build failed with code {ret}\")\n",
    "    \n",
    "    import geoveil_cn0 as gcn0\n",
    "    print(f\"\\n‚úÖ geoveil_cn0 v{gcn0.VERSION} installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ geoveil_cn0 v0.3.6\n"
     ]
    }
   ],
   "source": [
    "import geoveil_cn0 as gcn0\n",
    "print(f\"‚úÖ geoveil_cn0 v{gcn0.VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports ready\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly pandas numpy ipywidgets kaleido -q\n",
    "\n",
    "import os\n",
    "import json\n",
    "import tempfile\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output, FileLink\n",
    "import geoveil_cn0 as gcn0\n",
    "\n",
    "print(\"‚úÖ Imports ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Presets configured\n"
     ]
    }
   ],
   "source": [
    "# Analysis presets\n",
    "PRESETS = {\n",
    "    'Full Analysis': {\n",
    "        'min_elevation': 5.0,\n",
    "        'time_bin': 60,\n",
    "        'detect_anomalies': True,\n",
    "        'anomaly_sensitivity': 0.3,\n",
    "        'interference_threshold_db': 8.0,\n",
    "        'systems': ['G', 'R', 'E', 'C'],\n",
    "        'description': 'Complete analysis with all features'\n",
    "    },\n",
    "    'Quick Overview': {\n",
    "        'min_elevation': 10.0,\n",
    "        'time_bin': 120,\n",
    "        'detect_anomalies': True,\n",
    "        'anomaly_sensitivity': 0.5,\n",
    "        'interference_threshold_db': 10.0,\n",
    "        'systems': ['G', 'E'],\n",
    "        'description': 'Fast overview - GPS/Galileo only'\n",
    "    },\n",
    "    'Interference Detection': {\n",
    "        'min_elevation': 5.0,\n",
    "        'time_bin': 30,\n",
    "        'detect_anomalies': True,\n",
    "        'anomaly_sensitivity': 0.2,\n",
    "        'interference_threshold_db': 6.0,\n",
    "        'systems': ['G', 'R', 'E', 'C'],\n",
    "        'description': 'High sensitivity for interference'\n",
    "    },\n",
    "    'Jamming Analysis': {\n",
    "        'min_elevation': 5.0,\n",
    "        'time_bin': 15,\n",
    "        'detect_anomalies': True,\n",
    "        'anomaly_sensitivity': 0.15,\n",
    "        'interference_threshold_db': 4.0,\n",
    "        'systems': ['G', 'R', 'E', 'C'],\n",
    "        'description': 'Maximum sensitivity for jamming detection'\n",
    "    },\n",
    "    'Spoofing Detection': {\n",
    "        'min_elevation': 10.0,\n",
    "        'time_bin': 60,\n",
    "        'detect_anomalies': True,\n",
    "        'anomaly_sensitivity': 0.25,\n",
    "        'interference_threshold_db': 6.0,\n",
    "        'systems': ['G', 'E'],\n",
    "        'description': 'Tuned for spoofing pattern detection'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Presets configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Widget Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Storage initialized\n"
     ]
    }
   ],
   "source": [
    "# Global storage\n",
    "file_data = {'obs': None, 'obs_name': None, 'nav': None, 'nav_name': None}\n",
    "analysis_results = {'data': None, 'timestamp': None}\n",
    "\n",
    "# System colors\n",
    "SYSTEM_COLORS = {\n",
    "    'GPS': '#1f77b4', 'GLONASS': '#ff7f0e',\n",
    "    'Galileo': '#2ca02c', 'BeiDou': '#d62728',\n",
    "    'QZSS': '#9467bd', 'IRNSS': '#8c564b'\n",
    "}\n",
    "SYS_CODE_MAP = {'G': 'GPS', 'R': 'GLONASS', 'E': 'Galileo', 'C': 'BeiDou', 'J': 'QZSS', 'I': 'IRNSS'}\n",
    "\n",
    "# Satellite trace colors\n",
    "SAT_COLORS = ['#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A',\n",
    "              '#19D3F3', '#FF6692', '#B6E880', '#FF97FF', '#FECB52']\n",
    "\n",
    "print(\"‚úÖ Storage initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ NavDownloader ready (auto-download multi-GNSS BRDC ephemeris)\n"
     ]
    }
   ],
   "source": [
    "# ============ NAVIGATION AUTO-DOWNLOADER ============\n",
    "# Downloads BRDC (broadcast) navigation files for multi-GNSS elevation/skyplot support\n",
    "import urllib.request\n",
    "import ssl\n",
    "from pathlib import Path\n",
    "\n",
    "class NavDownloader:\n",
    "    \"\"\"Multi-GNSS Navigation/Ephemeris Downloader\n",
    "    \n",
    "    Downloads from multiple sources and picks the most complete file.\n",
    "    Includes: GPS (G), GLONASS (R), Galileo (E), BeiDou (C), QZSS (J)\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def gps_week_from_date(year, doy):\n",
    "        \"\"\"Calculate GPS week and day-of-week from year and DOY\"\"\"\n",
    "        from datetime import date, timedelta\n",
    "        gps_epoch = date(1980, 1, 6)\n",
    "        target = date(year, 1, 1) + timedelta(days=doy - 1)\n",
    "        delta = (target - gps_epoch).days\n",
    "        return delta // 7, delta % 7\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_rinex_header_content(content):\n",
    "        \"\"\"Extract year, doy from RINEX file content (bytes or str)\"\"\"\n",
    "        from datetime import date\n",
    "        try:\n",
    "            if isinstance(content, bytes):\n",
    "                text = content[:10000].decode('utf-8', errors='ignore')\n",
    "            else:\n",
    "                text = content[:10000]\n",
    "            \n",
    "            for line in text.split('\\n'):\n",
    "                if 'TIME OF FIRST OBS' in line:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 6:\n",
    "                        year = int(float(parts[0]))\n",
    "                        month = int(float(parts[1]))\n",
    "                        day = int(float(parts[2]))\n",
    "                        doy = date(year, month, day).timetuple().tm_yday\n",
    "                        return year, doy\n",
    "                if 'END OF HEADER' in line:\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            print(f\"   Header parse error: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_rinex_date(filename):\n",
    "        \"\"\"Extract year, doy from RINEX filename\"\"\"\n",
    "        import re\n",
    "        try:\n",
    "            # RINEX 3/4 format: SSSSMMMMR_U_YYYYDDDHHMM_...\n",
    "            # Example: BRAI00ROU_R_20250200600_01H_30S_MO.rnx -> 2025, 020\n",
    "            parts = [p for p in filename.split('_') if p]\n",
    "            if len(parts) >= 3 and len(parts[2]) >= 7:\n",
    "                ts = parts[2]\n",
    "                year = int(ts[0:4])\n",
    "                doy = int(ts[4:7])\n",
    "                if 1980 <= year <= 2100 and 1 <= doy <= 366:\n",
    "                    return year, doy\n",
    "            \n",
    "            # RINEX 2 standard format: ssssdddf.yyt (e.g., bucu1520.25o)\n",
    "            match = re.match(r'^[a-zA-Z0-9]{4}(\\d{3})\\d?\\.([\\d]{2})[oOnNmMgG]$', filename)\n",
    "            if match:\n",
    "                doy = int(match.group(1))\n",
    "                yr = int(match.group(2))\n",
    "                year = 2000 + yr if yr < 80 else 1900 + yr\n",
    "                return year, doy\n",
    "            \n",
    "            # Extended RINEX 2 format with longer sequence\n",
    "            match = re.match(r'^\\d{4}(\\d{3})\\d{3}\\.(\\d{2})[oOnNmMgG]$', filename)\n",
    "            if match:\n",
    "                doy = int(match.group(1))\n",
    "                yr = int(match.group(2))\n",
    "                year = 2000 + yr if yr < 80 else 1900 + yr\n",
    "                return year, doy\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   Filename parse error: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    @staticmethod\n",
    "    def count_nav_satellites(content):\n",
    "        \"\"\"Count satellites per constellation in navigation file content\"\"\"\n",
    "        if isinstance(content, bytes):\n",
    "            content = content.decode('utf-8', errors='ignore')\n",
    "        \n",
    "        sats = {'G': set(), 'R': set(), 'E': set(), 'C': set(), 'J': set(), 'I': set()}\n",
    "        \n",
    "        for line in content.split('\\n'):\n",
    "            if len(line) >= 3:\n",
    "                first_char = line[0]\n",
    "                if first_char in sats:\n",
    "                    try:\n",
    "                        prn = line[1:3].strip()\n",
    "                        if prn.isdigit():\n",
    "                            sats[first_char].add(int(prn))\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        return {k: len(v) for k, v in sats.items()}\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_sat_summary(counts):\n",
    "        \"\"\"Format satellite count summary\"\"\"\n",
    "        names = {'G': 'GPS', 'R': 'GLO', 'E': 'GAL', 'C': 'BDS', 'J': 'QZS', 'I': 'NAV'}\n",
    "        parts = []\n",
    "        for sys, count in counts.items():\n",
    "            if count > 0:\n",
    "                parts.append(f\"{names.get(sys, sys)}:{count}\")\n",
    "        return \", \".join(parts)\n",
    "    \n",
    "    @staticmethod\n",
    "    def download(year, doy, output_dir, log_func=print):\n",
    "        \"\"\"Download ephemeris - tries multiple sources and picks best\"\"\"\n",
    "        result = NavDownloader.download_brdc_best(year, doy, output_dir, log_func)\n",
    "        if result:\n",
    "            return result\n",
    "        \n",
    "        log_func(\"   BRDC not available, trying SP3...\")\n",
    "        return NavDownloader.download_sp3(year, doy, output_dir, log_func)\n",
    "    \n",
    "    @staticmethod\n",
    "    def download_brdc_best(year, doy, output_dir, log_func=print):\n",
    "        \"\"\"Download BRDC - tries multiple sources and picks the most complete\"\"\"\n",
    "        ctx = ssl.create_default_context()\n",
    "        ctx.check_hostname = False\n",
    "        ctx.verify_mode = ssl.CERT_NONE\n",
    "        \n",
    "        brdc_sources = [\n",
    "            {\"name\": \"BKG IGS\", \"url\": f\"https://igs.bkg.bund.de/root_ftp/IGS/BRDC/{year}/{doy:03d}/BRDC00IGS_R_{year}{doy:03d}0000_01D_MN.rnx.gz\",\n",
    "             \"filename\": f\"BRDC00IGS_R_{year}{doy:03d}0000_01D_MN.rnx\"},\n",
    "            {\"name\": \"DLR MGEX\", \"url\": f\"https://igs.bkg.bund.de/root_ftp/MGEX/BRDC/{year}/{doy:03d}/BRDM00DLR_S_{year}{doy:03d}0000_01D_MN.rnx.gz\",\n",
    "             \"filename\": f\"BRDM00DLR_S_{year}{doy:03d}0000_01D_MN.rnx\"},\n",
    "            {\"name\": \"IGN France\", \"url\": f\"https://igs.ign.fr/pub/igs/data/{year}/{doy:03d}/BRDC00IGS_R_{year}{doy:03d}0000_01D_MN.rnx.gz\",\n",
    "             \"filename\": f\"BRDC00IGS_R_{year}{doy:03d}0000_01D_MN_ign.rnx\"},\n",
    "        ]\n",
    "        \n",
    "        out_path = Path(output_dir)\n",
    "        candidates = []\n",
    "        \n",
    "        log_func(\"   Checking BRDC sources...\")\n",
    "        \n",
    "        for source in brdc_sources:\n",
    "            log_func(f\"   ‚è≥ {source['name']}...\")\n",
    "            \n",
    "            try:\n",
    "                req = urllib.request.Request(source[\"url\"])\n",
    "                req.add_header('User-Agent', 'Mozilla/5.0 GNSS-Analysis')\n",
    "                \n",
    "                with urllib.request.urlopen(req, timeout=45, context=ctx) as resp:\n",
    "                    data = resp.read()\n",
    "                \n",
    "                if len(data) < 1000:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    decompressed = gzip.decompress(data)\n",
    "                except:\n",
    "                    decompressed = data\n",
    "                \n",
    "                counts = NavDownloader.count_nav_satellites(decompressed)\n",
    "                total = sum(counts.values())\n",
    "                \n",
    "                if total == 0:\n",
    "                    continue\n",
    "                \n",
    "                summary = NavDownloader.format_sat_summary(counts)\n",
    "                log_func(f\"      ‚úì {total} sats: {summary}\")\n",
    "                \n",
    "                candidates.append({\n",
    "                    'source': source,\n",
    "                    'content': decompressed,\n",
    "                    'counts': counts,\n",
    "                    'total': total,\n",
    "                    'summary': summary\n",
    "                })\n",
    "                \n",
    "            except urllib.error.HTTPError as e:\n",
    "                log_func(f\"      ‚úó HTTP {e.code}\")\n",
    "            except Exception as e:\n",
    "                log_func(f\"      ‚úó {str(e)[:30]}\")\n",
    "        \n",
    "        if not candidates:\n",
    "            log_func(\"   ‚ùå No BRDC sources available\")\n",
    "            return None\n",
    "        \n",
    "        def score(c):\n",
    "            num_systems = sum(1 for v in c['counts'].values() if v > 0)\n",
    "            return (num_systems, c['total'])\n",
    "        \n",
    "        best = max(candidates, key=score)\n",
    "        \n",
    "        out_file = out_path / best['source']['filename']\n",
    "        with open(out_file, 'wb') as f:\n",
    "            f.write(best['content'])\n",
    "        \n",
    "        log_func(f\"   ‚úÖ Selected: {best['source']['name']}\")\n",
    "        log_func(f\"   üìä Ephemeris: {best['summary']}\")\n",
    "        \n",
    "        return out_file\n",
    "    \n",
    "    @staticmethod\n",
    "    def download_sp3(year, doy, output_dir, log_func=print):\n",
    "        \"\"\"Download Multi-GNSS SP3 precise ephemeris (fallback)\"\"\"\n",
    "        ctx = ssl.create_default_context()\n",
    "        ctx.check_hostname = False\n",
    "        ctx.verify_mode = ssl.CERT_NONE\n",
    "        \n",
    "        week, dow = NavDownloader.gps_week_from_date(year, doy)\n",
    "        \n",
    "        sp3_sources = [\n",
    "            {\"name\": \"ESA Final\", \"url\": f\"http://navigation-office.esa.int/products/gnss-products/{week}/ESA0MGNFIN_{year}{doy:03d}0000_01D_05M_ORB.SP3.gz\"},\n",
    "            {\"name\": \"GFZ Final\", \"url\": f\"https://igs.bkg.bund.de/root_ftp/IGS/products/mgex/{week}/GFZ0MGXFIN_{year}{doy:03d}0000_01D_05M_ORB.SP3.gz\"},\n",
    "        ]\n",
    "        \n",
    "        out_path = Path(output_dir)\n",
    "        log_func(f\"   üîç Looking for SP3 (Week {week})...\")\n",
    "        \n",
    "        for source in sp3_sources:\n",
    "            try:\n",
    "                req = urllib.request.Request(source[\"url\"])\n",
    "                req.add_header('User-Agent', 'Mozilla/5.0 GNSS-Analysis')\n",
    "                \n",
    "                with urllib.request.urlopen(req, timeout=60, context=ctx) as resp:\n",
    "                    data = resp.read()\n",
    "                \n",
    "                if len(data) < 10000:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    decompressed = gzip.decompress(data)\n",
    "                except:\n",
    "                    decompressed = data\n",
    "                \n",
    "                out_file = out_path / f\"{source['name'].replace(' ', '_')}_{year}{doy:03d}.sp3\"\n",
    "                with open(out_file, 'wb') as f:\n",
    "                    f.write(decompressed)\n",
    "                \n",
    "                log_func(f\"   ‚úÖ {source['name']}\")\n",
    "                return out_file\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        log_func(\"   ‚ùå SP3 not available\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ NavDownloader ready (auto-download multi-GNSS BRDC ephemeris)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Widgets created (v6 - auto-export)\n"
     ]
    }
   ],
   "source": [
    "# === FILE INPUT WIDGETS ===\n",
    "obs_upload = widgets.FileUpload(accept='.obs,.rnx,.crx,.24o,.23o,.gz', multiple=False, description='OBS File')\n",
    "nav_upload = widgets.FileUpload(accept='.nav,.rnx,.24n,.sp3,.gz', multiple=False, description='NAV File')\n",
    "\n",
    "obs_path = widgets.Text(placeholder='Or enter path: /path/to/file.rnx', description='OBS Path:', layout=widgets.Layout(width='500px'))\n",
    "nav_path = widgets.Text(placeholder='Optional: /path/to/file.nav', description='NAV Path:', layout=widgets.Layout(width='500px'))\n",
    "\n",
    "auto_download_nav = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Auto-download BRDC if missing',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='250px')\n",
    ")\n",
    "\n",
    "load_btn = widgets.Button(description='üì• Load Files', button_style='info')\n",
    "\n",
    "# === PRESET ===\n",
    "preset_dropdown = widgets.Dropdown(\n",
    "    options=list(PRESETS.keys()),\n",
    "    value='Full Analysis',\n",
    "    description='Preset:',\n",
    "    layout=widgets.Layout(width='250px')\n",
    ")\n",
    "\n",
    "# === OUTPUT BUTTONS (v6) ===\n",
    "btn_summary = widgets.Button(description='üìä Summary', button_style='primary', tooltip='Quality summary + saves PNGs')\n",
    "btn_heatmap = widgets.Button(description='üó∫Ô∏è Heatmaps', button_style='warning', tooltip='CN0 heatmaps + saves PNGs')\n",
    "btn_snr = widgets.Button(description='üìà SNR Graphs', button_style='success', tooltip='CN0 timeseries + saves PNGs')\n",
    "btn_skyplot = widgets.Button(description='üõ∞Ô∏è Skyplot', button_style='info', tooltip='Satellite skyplot + saves PNG')\n",
    "btn_anomaly = widgets.Button(description='‚ö†Ô∏è Anomalies', button_style='danger', tooltip='Anomaly timeline + saves CSV')\n",
    "btn_report = widgets.Button(description='üì• Download Report', button_style='', tooltip='Generate HTML report from saved files')\n",
    "\n",
    "# === OUTPUT AREAS ===\n",
    "status_out = widgets.Output()\n",
    "results_out = widgets.Output()\n",
    "\n",
    "# === EXPORT STATE (shared across all handlers) ===\n",
    "export_state = {'dir': None, 'files': []}\n",
    "\n",
    "# SNR quality thresholds (ICAO/ITU standards)\n",
    "SNR_THRESHOLDS = {'excellent': 45, 'good': 35, 'marginal': 25, 'poor': 15}\n",
    "\n",
    "# Expected satellites per constellation (typical visibility)\n",
    "EXPECTED_SATS = {'GPS': 12, 'GLONASS': 8, 'Galileo': 10, 'BeiDou': 14, 'QZSS': 4, 'IRNSS': 7}\n",
    "\n",
    "def get_export_dir():\n",
    "    \"\"\"Get or create export directory\"\"\"\n",
    "    if export_state['dir'] is None:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        export_state['dir'] = f'cn0_export_{timestamp}'\n",
    "        os.makedirs(export_state['dir'], exist_ok=True)\n",
    "    return export_state['dir']\n",
    "\n",
    "print(\"‚úÖ Widgets created (v6 - auto-export)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ File loader ready (optimized with parallel I/O)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import tempfile\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "def load_files(btn):\n",
    "    \"\"\"Load files with parallel processing for speed\"\"\"\n",
    "    with status_out:\n",
    "        clear_output()\n",
    "        print(\"üì• Loading files...\")\n",
    "        print(\"   ‚ö° Using parallel I/O for speed\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        obs_loaded = False\n",
    "        nav_loaded = False\n",
    "        \n",
    "        def load_file_parallel(path, is_gz=False):\n",
    "            \"\"\"Load a file in parallel thread\"\"\"\n",
    "            with open(path, 'rb') as f:\n",
    "                content = f.read()\n",
    "            if is_gz or path.lower().endswith('.gz'):\n",
    "                content = gzip.decompress(content)\n",
    "            return content\n",
    "        \n",
    "        # === OBSERVATION FILE ===\n",
    "        obs_start = time.time()\n",
    "        \n",
    "        if obs_path.value.strip():\n",
    "            path = obs_path.value.strip()\n",
    "            if os.path.exists(path):\n",
    "                content = load_file_parallel(path)\n",
    "                name = os.path.basename(path)\n",
    "                file_data['obs'] = content\n",
    "                file_data['obs_name'] = name\n",
    "                obs_loaded = True\n",
    "                obs_time = time.time() - obs_start\n",
    "                print(f\"‚úÖ OBS: {name} ({len(content)/1024/1024:.1f} MB) [{obs_time:.2f}s]\")\n",
    "            else:\n",
    "                print(f\"‚ùå File not found: {path}\")\n",
    "        \n",
    "        elif obs_upload.value:\n",
    "            try:\n",
    "                file_info = obs_upload.value[0] if isinstance(obs_upload.value, tuple) else list(obs_upload.value.values())[0]\n",
    "                name = getattr(file_info, 'name', None) or file_info.get('name', 'obs.rnx')\n",
    "                content = getattr(file_info, 'content', None) or file_info.get('content', b'')\n",
    "                if content:\n",
    "                    if name.lower().endswith('.gz'):\n",
    "                        content = gzip.decompress(content)\n",
    "                    file_data['obs'] = content\n",
    "                    file_data['obs_name'] = name\n",
    "                    obs_loaded = True\n",
    "                    obs_time = time.time() - obs_start\n",
    "                    print(f\"‚úÖ OBS: {name} ({len(content)/1024/1024:.1f} MB) [{obs_time:.2f}s]\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Upload error: {e}\")\n",
    "        \n",
    "        if not obs_loaded:\n",
    "            print(\"‚ö†Ô∏è No observation file loaded\")\n",
    "            return\n",
    "        \n",
    "        # === NAVIGATION FILE (parallel with date parsing) ===\n",
    "        nav_start = time.time()\n",
    "        \n",
    "        # Start date parsing in background while loading NAV\n",
    "        year, doy = None, None\n",
    "        \n",
    "        def parse_date_async():\n",
    "            \"\"\"Parse date from OBS file\"\"\"\n",
    "            if file_data.get('obs'):\n",
    "                y, d = NavDownloader.parse_rinex_header_content(file_data['obs'])\n",
    "                if y and d:\n",
    "                    return y, d\n",
    "            if file_data.get('obs_name'):\n",
    "                return NavDownloader.parse_rinex_date(file_data['obs_name'])\n",
    "            return None, None\n",
    "        \n",
    "        # Load NAV file if provided\n",
    "        if nav_path.value.strip():\n",
    "            path = nav_path.value.strip()\n",
    "            if os.path.exists(path):\n",
    "                content = load_file_parallel(path)\n",
    "                name = os.path.basename(path)\n",
    "                file_data['nav'] = content\n",
    "                file_data['nav_name'] = name\n",
    "                nav_loaded = True\n",
    "                nav_time = time.time() - nav_start\n",
    "                print(f\"‚úÖ NAV: {name} [{nav_time:.2f}s]\")\n",
    "        elif nav_upload.value:\n",
    "            try:\n",
    "                file_info = nav_upload.value[0] if isinstance(nav_upload.value, tuple) else list(nav_upload.value.values())[0]\n",
    "                name = getattr(file_info, 'name', None) or file_info.get('name', 'nav.rnx')\n",
    "                content = getattr(file_info, 'content', None) or file_info.get('content', b'')\n",
    "                if content:\n",
    "                    if name.lower().endswith('.gz'):\n",
    "                        content = gzip.decompress(content)\n",
    "                    file_data['nav'] = content\n",
    "                    file_data['nav_name'] = name\n",
    "                    nav_loaded = True\n",
    "                    print(f\"‚úÖ NAV: {name}\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # === AUTO-DOWNLOAD NAV (with parallel download attempts) ===\n",
    "        if not nav_loaded and auto_download_nav.value and obs_loaded:\n",
    "            print(\"\\nüåê Auto-downloading navigation file...\")\n",
    "            \n",
    "            year, doy = parse_date_async()\n",
    "            \n",
    "            if year and doy:\n",
    "                print(f\"   Date: Year {year}, DOY {doy}\")\n",
    "                temp_dir = tempfile.gettempdir()\n",
    "                nav_path_result = NavDownloader.download(year, doy, temp_dir, log_func=print)\n",
    "                \n",
    "                if nav_path_result and nav_path_result.exists():\n",
    "                    with open(nav_path_result, 'rb') as f:\n",
    "                        file_data['nav'] = f.read()\n",
    "                    file_data['nav_name'] = nav_path_result.name\n",
    "                    nav_loaded = True\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è Could not parse date from OBS file or filename\")\n",
    "        \n",
    "        # Summary\n",
    "        total_time = time.time() - start_time\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"üìä LOADED FILES (total: {total_time:.2f}s):\")\n",
    "        print(f\"   OBS: {file_data['obs_name'] or 'None'}\")\n",
    "        print(f\"   NAV: {file_data['nav_name'] or 'None (elevations estimated)'}\")\n",
    "        \n",
    "        if nav_loaded:\n",
    "            print(\"\\n‚úÖ Ready for analysis with ephemeris (skyplot enabled)\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è No NAV file - skyplot/elevation heatmap unavailable\")\n",
    "\n",
    "load_btn.on_click(load_files)\n",
    "print(\"‚úÖ File loader ready (optimized with parallel I/O)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Core analysis function ready (with timing)\n"
     ]
    }
   ],
   "source": [
    "# === CORE ANALYSIS FUNCTION (optimized with timing) ===\n",
    "def run_core_analysis():\n",
    "    \"\"\"Run the Rust analysis and cache result - with timing\"\"\"\n",
    "    import time\n",
    "    \n",
    "    if not file_data['obs']:\n",
    "        with results_out:\n",
    "            print(\"‚ùå No observation file loaded. Click 'Load Files' first.\")\n",
    "        return None\n",
    "    \n",
    "    # Get preset settings\n",
    "    preset = PRESETS[preset_dropdown.value]\n",
    "    \n",
    "    with results_out:\n",
    "        print(f\"üî¨ Running analysis with preset: {preset_dropdown.value}\")\n",
    "        print(f\"   Settings: elev={preset['min_elevation']}¬∞, bin={preset['time_bin']}s, sens={preset['anomaly_sensitivity']}\")\n",
    "        print(\"   ‚ö° Rust-powered analysis engine\")\n",
    "        start_time = time.time()\n",
    "    \n",
    "    # Create config\n",
    "    config = gcn0.AnalysisConfig(\n",
    "        min_elevation=preset['min_elevation'],\n",
    "        time_bin=preset['time_bin'],\n",
    "        detect_anomalies=preset['detect_anomalies'],\n",
    "        anomaly_sensitivity=preset['anomaly_sensitivity'],\n",
    "        interference_threshold_db=preset['interference_threshold_db'],\n",
    "        systems=preset['systems']\n",
    "    )\n",
    "    \n",
    "    analyzer = gcn0.CN0Analyzer(config)\n",
    "    \n",
    "    # Run analysis\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        # Write files\n",
    "        write_start = time.time()\n",
    "        obs_file = os.path.join(tmpdir, file_data['obs_name'] or 'obs.rnx')\n",
    "        with open(obs_file, 'wb') as f:\n",
    "            f.write(file_data['obs'])\n",
    "        \n",
    "        nav_file = None\n",
    "        if file_data['nav']:\n",
    "            nav_file = os.path.join(tmpdir, file_data['nav_name'] or 'nav.rnx')\n",
    "            with open(nav_file, 'wb') as f:\n",
    "                f.write(file_data['nav'])\n",
    "        \n",
    "        write_time = time.time() - write_start\n",
    "        \n",
    "        # Run Rust analysis\n",
    "        analyze_start = time.time()\n",
    "        if nav_file:\n",
    "            result = analyzer.analyze_with_nav(obs_file, nav_file)\n",
    "        else:\n",
    "            result = analyzer.analyze_file(obs_file)\n",
    "        analyze_time = time.time() - analyze_start\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    with results_out:\n",
    "        print(f\"   ‚è±Ô∏è File I/O: {write_time:.2f}s\")\n",
    "        print(f\"   ‚è±Ô∏è Rust analysis: {analyze_time:.2f}s\")\n",
    "        print(f\"   ‚è±Ô∏è Total: {total_time:.2f}s\")\n",
    "    \n",
    "    analysis_results['data'] = result\n",
    "    analysis_results['timestamp'] = datetime.now()\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"‚úÖ Core analysis function ready (with timing)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary handler ready (displays + auto-saves PNGs)\n"
     ]
    }
   ],
   "source": [
    "# === SHOW SUMMARY (v6 - with PNG export) ===\n",
    "def show_summary(btn):\n",
    "    \"\"\"Show quality summary and save PNGs to export folder\"\"\"\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        print(\"üìä Running analysis...\")\n",
    "    \n",
    "    result = analysis_results.get('data')\n",
    "    if not result:\n",
    "        result = run_core_analysis()\n",
    "    if not result:\n",
    "        return\n",
    "    \n",
    "    export_dir = get_export_dir()\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        qs = result.quality_score\n",
    "        \n",
    "        # Print text summary\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"üèÜ QUALITY SCORE: {qs.overall:.0f}/100 ({qs.rating})\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"   CN0 Quality:   {qs.cn0_quality:.0f}\")\n",
    "        print(f\"   Availability:  {qs.availability:.0f}\")\n",
    "        print(f\"   Continuity:    {qs.continuity:.0f}\")\n",
    "        print(f\"   Stability:     {qs.stability:.0f}\")\n",
    "        print(f\"   Diversity:     {qs.diversity:.0f}\")\n",
    "        print()\n",
    "        print(f\"üì∂ Signal Quality:\")\n",
    "        print(f\"   Average CN0: {result.avg_cn0:.1f} dB-Hz\")\n",
    "        print(f\"   Std Dev: {result.cn0_std_dev:.1f} dB-Hz\")\n",
    "        print(f\"   Range: {result.min_cn0:.1f} - {result.max_cn0:.1f} dB-Hz\")\n",
    "        print()\n",
    "        print(f\"üö® Threat Detection:\")\n",
    "        print(f\"   Jamming:      {'üî¥ DETECTED' if result.jamming_detected else 'üü¢ Clear'}\")\n",
    "        print(f\"   Spoofing:     {'üî¥ DETECTED' if result.spoofing_detected else 'üü¢ Clear'}\")\n",
    "        print(f\"   Interference: {'üü° DETECTED' if result.interference_detected else 'üü¢ Clear'}\")\n",
    "        print(f\"   Anomalies:    {result.anomaly_count}\")\n",
    "        \n",
    "        # === THREAT EXPLANATIONS ===\n",
    "        if result.jamming_detected or result.spoofing_detected or result.interference_detected:\n",
    "            print()\n",
    "            print('üîç THREAT ANALYSIS:')\n",
    "            \n",
    "            if result.jamming_detected:\n",
    "                print('   üî¥ JAMMING: Broadband signal detected causing CN0 drops across')\n",
    "                print('      multiple satellites simultaneously. This indicates intentional')\n",
    "                print('      or unintentional RF interference overwhelming GNSS signals.')\n",
    "                print('      ‚Üí Impact: Degraded positioning accuracy, potential loss of fix')\n",
    "                print('      ‚Üí Action: Check for nearby RF sources, consider relocating receiver')\n",
    "                print()\n",
    "            \n",
    "            if result.spoofing_detected:\n",
    "                print('   üî¥ SPOOFING: Suspicious signal patterns detected suggesting')\n",
    "                print('      fake GNSS signals. Indicators may include: unusual CN0 correlation')\n",
    "                print('      across satellites, impossible geometry, or timing anomalies.')\n",
    "                print('      ‚Üí Impact: Position/time solution may be manipulated')\n",
    "                print('      ‚Üí Action: Cross-check with independent sources, use multi-GNSS')\n",
    "                print()\n",
    "            \n",
    "            if result.interference_detected:\n",
    "                print('   üü° INTERFERENCE: Localized signal degradation detected.')\n",
    "                print('      May be caused by: multipath, nearby electronics, partial obstruction.')\n",
    "                print('      Less severe than jamming but affects signal quality.')\n",
    "                print('      ‚Üí Impact: Reduced accuracy in affected satellites')\n",
    "                print('      ‚Üí Action: Check antenna placement, reduce multipath sources')\n",
    "                print()\n",
    "            \n",
    "            if result.anomaly_count > 0:\n",
    "                print(f'   üìä {result.anomaly_count} anomalies detected in signal data.')\n",
    "                print('      Anomalies are sudden CN0 changes exceeding normal variation.')\n",
    "                print('      High counts may indicate unstable RF environment.')\n",
    "        \n",
    "        \n",
    "        # Get constellation data\n",
    "        const_data = []\n",
    "        for sys_name in result.constellations:\n",
    "            stats = result.get_constellation_summary(sys_name)\n",
    "            if stats:\n",
    "                const_data.append({\n",
    "                    'name': sys_name,\n",
    "                    'sats_obs': int(stats['satellites_observed']),\n",
    "                    'sats_exp': int(stats.get('satellites_expected', EXPECTED_SATS.get(sys_name, 10))),\n",
    "                    'cn0_mean': float(stats['cn0_mean']),\n",
    "                    'cn0_std': float(stats['cn0_std'])\n",
    "                })\n",
    "        \n",
    "        print(\"\\nüõ∞Ô∏è CONSTELLATION SUMMARY:\")\n",
    "        for c in const_data:\n",
    "            print(f\"   {c['name']}: {c['sats_obs']}/{c['sats_exp']} sats, CN0={c['cn0_mean']:.1f}¬±{c['cn0_std']:.1f} dB-Hz\")\n",
    "        \n",
    "        # ========== PLOTLY DISPLAY ==========\n",
    "        # Radar chart\n",
    "        categories = ['CN0 Quality', 'Availability', 'Continuity', 'Stability', 'Diversity', 'CN0 Quality']\n",
    "        values = [qs.cn0_quality, qs.availability, qs.continuity, qs.stability, qs.diversity, qs.cn0_quality]\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "            r=values, theta=categories, fill='toself',\n",
    "            fillcolor='rgba(99, 110, 250, 0.3)',\n",
    "            line=dict(color='rgb(99, 110, 250)', width=2),\n",
    "            name=f'Score: {qs.overall:.0f}'\n",
    "        ))\n",
    "        fig.add_trace(go.Scatterpolar(\n",
    "            r=[70]*6, theta=categories, fill='none',\n",
    "            line=dict(color='green', dash='dash'), name='Good (70)'\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            polar=dict(radialaxis=dict(visible=True, range=[0, 100])),\n",
    "            title=f'Quality Score: {qs.overall:.0f}/100 ({qs.rating})',\n",
    "            showlegend=True, height=450\n",
    "        )\n",
    "        fig.show()\n",
    "        \n",
    "        # Constellation bar charts with thresholds\n",
    "        if const_data:\n",
    "            fig2 = make_subplots(rows=1, cols=2, subplot_titles=('Mean CN0 (dB-Hz)', 'Satellite Count'))\n",
    "            names = [c['name'] for c in const_data]\n",
    "            colors = [SYSTEM_COLORS.get(c['name'], '#999') for c in const_data]\n",
    "            \n",
    "            # CN0 bars with error bars\n",
    "            fig2.add_trace(go.Bar(\n",
    "                x=names, y=[c['cn0_mean'] for c in const_data],\n",
    "                error_y=dict(type='data', array=[c['cn0_std'] for c in const_data]),\n",
    "                marker_color=colors, name='CN0', showlegend=False\n",
    "            ), row=1, col=1)\n",
    "            \n",
    "            # Satellite observed bars\n",
    "            fig2.add_trace(go.Bar(\n",
    "                x=names, y=[c['sats_obs'] for c in const_data],\n",
    "                marker_color=colors, name='Observed'\n",
    "            ), row=1, col=2)\n",
    "            \n",
    "            # Satellite expected bars (lighter)\n",
    "            fig2.add_trace(go.Bar(\n",
    "                x=names, y=[c['sats_exp'] for c in const_data],\n",
    "                marker_color=['rgba(150,150,150,0.4)']*len(names),\n",
    "                name='Expected', marker_line=dict(color='black', width=1)\n",
    "            ), row=1, col=2)\n",
    "            \n",
    "            # Threshold lines on CN0 chart\n",
    "            fig2.add_hline(y=45, line_dash='dash', line_color='green', annotation_text='Excellent (45)', row=1, col=1)\n",
    "            fig2.add_hline(y=35, line_dash='dash', line_color='orange', annotation_text='Good (35)', row=1, col=1)\n",
    "            fig2.add_hline(y=25, line_dash='dash', line_color='red', annotation_text='Marginal (25)', row=1, col=1)\n",
    "            \n",
    "            fig2.update_layout(height=450, title='Constellation Overview', barmode='group')\n",
    "            fig2.show()\n",
    "        \n",
    "        # ========== SAVE PNGs ==========\n",
    "        print(f\"\\nüìÅ Saving to: {export_dir}/\")\n",
    "        \n",
    "        # 1. Quality Radar PNG\n",
    "        try:\n",
    "            fig_radar, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "            angles = [n / 5.0 * 2 * np.pi for n in range(5)]\n",
    "            angles += angles[:1]\n",
    "            vals = [qs.cn0_quality, qs.availability, qs.continuity, qs.stability, qs.diversity]\n",
    "            vals += vals[:1]\n",
    "            \n",
    "            ax.plot(angles, vals, 'o-', linewidth=2, color='#636EFA')\n",
    "            ax.fill(angles, vals, alpha=0.25, color='#636EFA')\n",
    "            ax.plot(angles, [70]*6, '--', color='green', alpha=0.7, label='Good (70)')\n",
    "            ax.set_xticks(angles[:-1])\n",
    "            ax.set_xticklabels(['CN0', 'Availability', 'Continuity', 'Stability', 'Diversity'])\n",
    "            ax.set_ylim(0, 100)\n",
    "            ax.set_title(f'Quality Score: {qs.overall:.0f}/100 ({qs.rating})', fontsize=14, fontweight='bold')\n",
    "            ax.legend(loc='upper right')\n",
    "            \n",
    "            radar_path = os.path.join(export_dir, 'quality_radar.png')\n",
    "            plt.savefig(radar_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "            plt.close()\n",
    "            export_state['files'].append({'name': 'quality_radar.png', 'title': 'Quality Radar'})\n",
    "            print(f\"   ‚úÖ quality_radar.png\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Radar error: {e}\")\n",
    "        \n",
    "        # 2. CN0 Boxplot with thresholds\n",
    "        try:\n",
    "            # Get CN0 data from JSON\n",
    "            result_json = json.loads(result.to_json())\n",
    "            sat_ts = result_json.get('timeseries', {}).get('satellite_timeseries', {})\n",
    "            if not sat_ts:\n",
    "                sat_ts = result_json.get('satellite_timeseries', {})\n",
    "            \n",
    "            cn0_by_const = {}\n",
    "            for sat_id, sat_data in sat_ts.items():\n",
    "                if not isinstance(sat_data, dict):\n",
    "                    continue\n",
    "                sys_code = sat_id[0] if sat_id else 'X'\n",
    "                sys_name = SYS_CODE_MAP.get(sys_code, sys_code)\n",
    "                if sys_name not in cn0_by_const:\n",
    "                    cn0_by_const[sys_name] = []\n",
    "                \n",
    "                # Try different data structures\n",
    "                cn0_series = sat_data.get('cn0_series', sat_data.get('series', []))\n",
    "                if isinstance(cn0_series, list):\n",
    "                    for p in cn0_series:\n",
    "                        if isinstance(p, dict):\n",
    "                            v = p.get('value', p.get('cn0'))\n",
    "                            if v is not None and v > 0:\n",
    "                                cn0_by_const[sys_name].append(float(v))\n",
    "                        elif isinstance(p, (int, float)) and p > 0:\n",
    "                            cn0_by_const[sys_name].append(float(p))\n",
    "                \n",
    "                # Also try direct cn0 array\n",
    "                cn0_arr = sat_data.get('cn0', [])\n",
    "                if isinstance(cn0_arr, list):\n",
    "                    for v in cn0_arr:\n",
    "                        if v is not None and v > 0:\n",
    "                            cn0_by_const[sys_name].append(float(v))\n",
    "            \n",
    "            if cn0_by_const and any(len(v) > 0 for v in cn0_by_const.values()):\n",
    "                fig_box, ax = plt.subplots(figsize=(12, 6))\n",
    "                names = [n for n in cn0_by_const.keys() if len(cn0_by_const[n]) > 0]\n",
    "                data_lists = [cn0_by_const[n] for n in names]\n",
    "                colors = [SYSTEM_COLORS.get(n, '#999') for n in names]\n",
    "                \n",
    "                bp = ax.boxplot(data_lists, tick_labels=names, patch_artist=True)\n",
    "                for patch, color in zip(bp['boxes'], colors):\n",
    "                    patch.set_facecolor(color)\n",
    "                    patch.set_alpha(0.7)\n",
    "                \n",
    "                # SNR threshold lines with labels\n",
    "                ax.axhline(y=45, color='green', linestyle='--', linewidth=2, label='Excellent (45 dB-Hz)')\n",
    "                ax.axhline(y=35, color='orange', linestyle='--', linewidth=2, label='Good (35 dB-Hz)')\n",
    "                ax.axhline(y=25, color='red', linestyle='--', linewidth=2, label='Marginal (25 dB-Hz)')\n",
    "                \n",
    "                ax.set_ylabel('CN0 (dB-Hz)', fontsize=12)\n",
    "                ax.set_xlabel('Constellation', fontsize=12)\n",
    "                ax.set_title('CN0 Distribution with SNR Quality Thresholds', fontsize=14, fontweight='bold')\n",
    "                ax.legend(loc='lower right')\n",
    "                ax.grid(axis='y', alpha=0.3)\n",
    "                ax.set_ylim(10, 60)\n",
    "                \n",
    "                boxplot_path = os.path.join(export_dir, 'cn0_boxplot.png')\n",
    "                plt.savefig(boxplot_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "                plt.close()\n",
    "                export_state['files'].append({'name': 'cn0_boxplot.png', 'title': 'CN0 Boxplot'})\n",
    "                print(f\"   ‚úÖ cn0_boxplot.png\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è No CN0 data for boxplot\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Boxplot error: {e}\")\n",
    "        \n",
    "        # 3. Satellite Count (Observed vs Expected)\n",
    "        try:\n",
    "            if const_data:\n",
    "                fig_sats, ax = plt.subplots(figsize=(10, 6))\n",
    "                names = [c['name'] for c in const_data]\n",
    "                observed = [c['sats_obs'] for c in const_data]\n",
    "                expected = [c['sats_exp'] for c in const_data]\n",
    "                colors = [SYSTEM_COLORS.get(n, '#999') for n in names]\n",
    "                \n",
    "                x = np.arange(len(names))\n",
    "                width = 0.35\n",
    "                \n",
    "                bars1 = ax.bar(x - width/2, observed, width, label='Observed', color=colors, alpha=0.8)\n",
    "                bars2 = ax.bar(x + width/2, expected, width, label='Expected', color='lightgray', edgecolor='black', linestyle='--')\n",
    "                \n",
    "                # Add value labels\n",
    "                for bar, val in zip(bars1, observed):\n",
    "                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, str(val), ha='center', fontweight='bold', fontsize=11)\n",
    "                for bar, val in zip(bars2, expected):\n",
    "                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, str(val), ha='center', fontsize=10, color='gray')\n",
    "                \n",
    "                ax.set_ylabel('Satellite Count', fontsize=12)\n",
    "                ax.set_xlabel('Constellation', fontsize=12)\n",
    "                ax.set_title('Observed vs Expected Satellite Count', fontsize=14, fontweight='bold')\n",
    "                ax.set_xticks(x)\n",
    "                ax.set_xticklabels(names)\n",
    "                ax.legend()\n",
    "                ax.grid(axis='y', alpha=0.3)\n",
    "                \n",
    "                sats_path = os.path.join(export_dir, 'satellite_count.png')\n",
    "                plt.savefig(sats_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "                plt.close()\n",
    "                export_state['files'].append({'name': 'satellite_count.png', 'title': 'Satellite Count'})\n",
    "                print(f\"   ‚úÖ satellite_count.png\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Satellite count error: {e}\")\n",
    "        \n",
    "        # 4. Save analysis log\n",
    "        try:\n",
    "            log_path = os.path.join(export_dir, 'analysis_log.txt')\n",
    "            anomalies = result.get_anomalies() or []\n",
    "            \n",
    "            with open(log_path, 'w') as f:\n",
    "                f.write(f\"GeoVeil CN0 Analysis Report v6\\n\")\n",
    "                f.write(f\"Generated: {datetime.now().isoformat()}\\n\")\n",
    "                f.write(f\"File: {file_data.get('obs_name', 'unknown')}\\n\")\n",
    "                f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "                f.write(f\"QUALITY SCORE: {qs.overall:.0f}/100 ({qs.rating})\\n\")\n",
    "                f.write(f\"  CN0 Quality:   {qs.cn0_quality:.0f}\\n\")\n",
    "                f.write(f\"  Availability:  {qs.availability:.0f}\\n\")\n",
    "                f.write(f\"  Continuity:    {qs.continuity:.0f}\\n\")\n",
    "                f.write(f\"  Stability:     {qs.stability:.0f}\\n\")\n",
    "                f.write(f\"  Diversity:     {qs.diversity:.0f}\\n\\n\")\n",
    "                f.write(f\"SIGNAL QUALITY:\\n\")\n",
    "                f.write(f\"  Average CN0: {result.avg_cn0:.1f} dB-Hz\\n\")\n",
    "                f.write(f\"  Std Dev: {result.cn0_std_dev:.1f} dB-Hz\\n\")\n",
    "                f.write(f\"  Range: {result.min_cn0:.1f} - {result.max_cn0:.1f} dB-Hz\\n\\n\")\n",
    "                f.write(f\"SNR THRESHOLDS (ICAO/ITU):\\n\")\n",
    "                f.write(f\"  Excellent: ‚â•45 | Good: ‚â•35 | Marginal: ‚â•25 | Poor: <25 dB-Hz\\n\\n\")\n",
    "                f.write(f\"CONSTELLATIONS:\\n\")\n",
    "                for c in const_data:\n",
    "                    f.write(f\"  {c['name']}: {c['sats_obs']}/{c['sats_exp']} sats, CN0={c['cn0_mean']:.1f}¬±{c['cn0_std']:.1f}\\n\")\n",
    "                f.write(f\"\\nTHREAT DETECTION:\\n\")\n",
    "                f.write(f\"  Jamming: {'DETECTED' if result.jamming_detected else 'Clear'}\\n\")\n",
    "                f.write(f\"  Spoofing: {'DETECTED' if result.spoofing_detected else 'Clear'}\\n\")\n",
    "                f.write(f\"  Interference: {'DETECTED' if result.interference_detected else 'Clear'}\\n\")\n",
    "                f.write(f\"  Anomalies: {len(anomalies)}\\n\")\n",
    "            \n",
    "            export_state['files'].append({'name': 'analysis_log.txt', 'title': 'Analysis Log'})\n",
    "            print(f\"   ‚úÖ analysis_log.txt\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Log error: {e}\")\n",
    "        \n",
    "        # 5. Save constellation CSV\n",
    "        try:\n",
    "            if const_data:\n",
    "                csv_path = os.path.join(export_dir, 'constellation_stats.csv')\n",
    "                pd.DataFrame(const_data).to_csv(csv_path, index=False)\n",
    "                export_state['files'].append({'name': 'constellation_stats.csv', 'title': 'Constellation Stats'})\n",
    "                print(f\"   ‚úÖ constellation_stats.csv\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è CSV error: {e}\")\n",
    "        \n",
    "        # 6. Save full JSON\n",
    "        try:\n",
    "            json_path = os.path.join(export_dir, 'full_results.json')\n",
    "            with open(json_path, 'w') as f:\n",
    "                f.write(result.to_json())\n",
    "            export_state['files'].append({'name': 'full_results.json', 'title': 'Full Results'})\n",
    "            print(f\"   ‚úÖ full_results.json\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è JSON error: {e}\")\n",
    "        \n",
    "        print(f\"\\nüìÅ Export folder: {export_dir}/\")\n",
    "\n",
    "btn_summary.on_click(show_summary)\n",
    "print(\"‚úÖ Summary handler ready (displays + auto-saves PNGs)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Heatmap function ready (v6 - with PNG export)\n"
     ]
    }
   ],
   "source": [
    "# === SHOW HEATMAPS (v6 - with PNG export) ===\n",
    "def show_heatmaps(btn):\n",
    "    \"\"\"Show CN0 heatmaps - Time vs Satellite and Az/El - with PNG export\"\"\"\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        print(\"üó∫Ô∏è Generating heatmaps...\")\n",
    "    \n",
    "    result = analysis_results.get('data')\n",
    "    if not result:\n",
    "        result = run_core_analysis()\n",
    "    \n",
    "    if not result:\n",
    "        return\n",
    "    \n",
    "    export_dir = get_export_dir()\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        \n",
    "        # ===== HEATMAP 1: Time vs Satellite =====\n",
    "        print(\"üî• CN0 Heatmap - Time vs Satellite\")\n",
    "        \n",
    "        try:\n",
    "            result_json = json.loads(result.to_json())\n",
    "            sat_timeseries = result_json.get('timeseries', {}).get('satellite_timeseries', {})\n",
    "            \n",
    "            if sat_timeseries and len(sat_timeseries) > 0:\n",
    "                all_times = set()\n",
    "                \n",
    "                for sat_id, sat_data in sat_timeseries.items():\n",
    "                    if isinstance(sat_data, dict):\n",
    "                        series = sat_data.get('cn0_series', sat_data.get('series', []))\n",
    "                        if isinstance(series, list):\n",
    "                            for point in series:\n",
    "                                if isinstance(point, dict):\n",
    "                                    all_times.add(point.get('timestamp', point.get('time', '')))\n",
    "                \n",
    "                all_times = sorted([t for t in all_times if t])\n",
    "                \n",
    "                if all_times:\n",
    "                    max_time_points = 400\n",
    "                    if len(all_times) > max_time_points:\n",
    "                        step = len(all_times) // max_time_points\n",
    "                        all_times = all_times[::step]\n",
    "                    \n",
    "                    def sat_sort_key(s):\n",
    "                        if len(s) >= 2:\n",
    "                            sys = s[0]\n",
    "                            try:\n",
    "                                prn = int(s[1:])\n",
    "                            except:\n",
    "                                prn = 0\n",
    "                            sys_order = {'G': 0, 'R': 1, 'E': 2, 'C': 3, 'J': 4}\n",
    "                            return (sys_order.get(sys, 9), prn)\n",
    "                        return (9, 0)\n",
    "                    \n",
    "                    all_satellites = sorted(sat_timeseries.keys(), key=sat_sort_key, reverse=True)\n",
    "                    \n",
    "                    z_matrix = []\n",
    "                    sat_labels = []\n",
    "                    \n",
    "                    for sat in all_satellites:\n",
    "                        sat_data = sat_timeseries.get(sat, {})\n",
    "                        if isinstance(sat_data, dict):\n",
    "                            cn0_series = sat_data.get('cn0_series', sat_data.get('series', []))\n",
    "                        else:\n",
    "                            continue\n",
    "                        \n",
    "                        cn0_by_time = {}\n",
    "                        if isinstance(cn0_series, list):\n",
    "                            for p in cn0_series:\n",
    "                                if isinstance(p, dict):\n",
    "                                    t = p.get('timestamp', p.get('time', ''))\n",
    "                                    v = p.get('value', p.get('cn0', None))\n",
    "                                    if t and v is not None:\n",
    "                                        cn0_by_time[t] = v\n",
    "                        \n",
    "                        row = [cn0_by_time.get(t, None) for t in all_times]\n",
    "                        valid_count = sum(1 for v in row if v is not None)\n",
    "                        if valid_count > len(all_times) * 0.05:\n",
    "                            z_matrix.append(row)\n",
    "                            sat_labels.append(sat)\n",
    "                    \n",
    "                    if z_matrix:\n",
    "                        time_labels = pd.to_datetime(all_times)\n",
    "                        \n",
    "                        # Plotly display\n",
    "                        fig1 = go.Figure(data=go.Heatmap(\n",
    "                            z=z_matrix,\n",
    "                            x=time_labels,\n",
    "                            y=sat_labels,\n",
    "                            colorscale='Viridis',\n",
    "                            zmin=25, zmax=55,\n",
    "                            colorbar=dict(title='C/N‚ÇÄ<br>(dB-Hz)'),\n",
    "                            hoverongaps=False,\n",
    "                        ))\n",
    "                        \n",
    "                        fig1.update_layout(\n",
    "                            title=f'C/N‚ÇÄ Heatmap - Time vs Satellite ({len(sat_labels)} satellites)',\n",
    "                            xaxis_title='Time (UTC)',\n",
    "                            yaxis_title='Satellite PRN',\n",
    "                            height=max(400, len(sat_labels) * 18),\n",
    "                            width=1100,\n",
    "                        )\n",
    "                        fig1.show()\n",
    "                        \n",
    "                        # ===== SAVE PNG =====\n",
    "                        print(f\"\\nüìÅ Saving to: {export_dir}/\")\n",
    "                        try:\n",
    "                            fig_h1, ax = plt.subplots(figsize=(14, max(6, len(sat_labels) * 0.25)))\n",
    "                            \n",
    "                            # Convert None to NaN for matplotlib\n",
    "                            z_array = np.array([[v if v is not None else np.nan for v in row] for row in z_matrix])\n",
    "                            \n",
    "                            im = ax.imshow(z_array, aspect='auto', cmap='viridis', vmin=25, vmax=55)\n",
    "                            \n",
    "                            # X-axis: time labels (show subset)\n",
    "                            n_xticks = min(10, len(time_labels))\n",
    "                            xtick_idx = np.linspace(0, len(time_labels)-1, n_xticks, dtype=int)\n",
    "                            ax.set_xticks(xtick_idx)\n",
    "                            ax.set_xticklabels([time_labels[i].strftime('%H:%M') for i in xtick_idx], rotation=45, ha='right')\n",
    "                            \n",
    "                            # Y-axis: satellite labels\n",
    "                            ax.set_yticks(range(len(sat_labels)))\n",
    "                            ax.set_yticklabels(sat_labels, fontsize=8)\n",
    "                            \n",
    "                            ax.set_xlabel('Time (UTC)', fontsize=12)\n",
    "                            ax.set_ylabel('Satellite PRN', fontsize=12)\n",
    "                            ax.set_title(f'CN0 Heatmap - Time vs Satellite ({len(sat_labels)} satellites)', fontsize=14, fontweight='bold')\n",
    "                            \n",
    "                            cbar = plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "                            cbar.set_label('CN0 (dB-Hz)', fontsize=10)\n",
    "                            \n",
    "                            plt.tight_layout()\n",
    "                            heatmap1_path = os.path.join(export_dir, 'heatmap_time_satellite.png')\n",
    "                            plt.savefig(heatmap1_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "                            plt.close()\n",
    "                            export_state['files'].append({'name': 'heatmap_time_satellite.png', 'title': 'Time vs Satellite Heatmap'})\n",
    "                            print(f\"   ‚úÖ heatmap_time_satellite.png\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"   ‚ö†Ô∏è Time-Satellite heatmap PNG error: {e}\")\n",
    "                            plt.close()\n",
    "                    else:\n",
    "                        print(\"   ‚ö†Ô∏è No valid satellite data for heatmap\")\n",
    "                else:\n",
    "                    print(\"   ‚ö†Ô∏è No timestamps found in satellite timeseries\")\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è No satellite timeseries data available\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Time vs Satellite heatmap error: {e}\")\n",
    "        \n",
    "        # ===== HEATMAP 2: Az/El =====\n",
    "        print(\"\\nüó∫Ô∏è CN0 Heatmap by Azimuth/Elevation\")\n",
    "        \n",
    "        try:\n",
    "            skyplot_data = result.get_skyplot_data()\n",
    "            \n",
    "            if not skyplot_data:\n",
    "                print(\"   ‚ö†Ô∏è No azimuth/elevation data available (need navigation file)\")\n",
    "            else:\n",
    "                traces = skyplot_data if isinstance(skyplot_data, list) else skyplot_data.get('traces', [])\n",
    "                \n",
    "                if not traces:\n",
    "                    print(\"   ‚ö†Ô∏è No satellite traces in skyplot data\")\n",
    "                else:\n",
    "                    az_bins = list(range(0, 361, 15))\n",
    "                    el_bins = list(range(0, 91, 5))\n",
    "                    \n",
    "                    cn0_sum = [[0.0 for _ in range(len(az_bins)-1)] for _ in range(len(el_bins)-1)]\n",
    "                    cn0_count = [[0 for _ in range(len(az_bins)-1)] for _ in range(len(el_bins)-1)]\n",
    "                    \n",
    "                    for trace in traces:\n",
    "                        if not isinstance(trace, dict):\n",
    "                            continue\n",
    "                        \n",
    "                        def parse_values(val):\n",
    "                            if isinstance(val, list):\n",
    "                                return [float(x) for x in val if x is not None]\n",
    "                            if isinstance(val, str):\n",
    "                                return [float(x.strip()) for x in val.split(',') if x.strip()]\n",
    "                            return []\n",
    "                        \n",
    "                        azimuths = parse_values(trace.get('azimuths', trace.get('azimuth', [])))\n",
    "                        elevations = parse_values(trace.get('elevations', trace.get('elevation', [])))\n",
    "                        cn0_values = parse_values(trace.get('cn0_values', trace.get('cn0', [])))\n",
    "                        \n",
    "                        for az, el, cn0 in zip(azimuths, elevations, cn0_values):\n",
    "                            if 0 <= az <= 360 and 0 <= el <= 90:\n",
    "                                az_idx = min(int(az / 15), len(az_bins) - 2)\n",
    "                                el_idx = min(int(el / 5), len(el_bins) - 2)\n",
    "                                cn0_sum[el_idx][az_idx] += cn0\n",
    "                                cn0_count[el_idx][az_idx] += 1\n",
    "                    \n",
    "                    cn0_grid = []\n",
    "                    has_data = False\n",
    "                    for el_idx in range(len(el_bins) - 1):\n",
    "                        row = []\n",
    "                        for az_idx in range(len(az_bins) - 1):\n",
    "                            if cn0_count[el_idx][az_idx] > 0:\n",
    "                                row.append(cn0_sum[el_idx][az_idx] / cn0_count[el_idx][az_idx])\n",
    "                                has_data = True\n",
    "                            else:\n",
    "                                row.append(None)\n",
    "                        cn0_grid.append(row)\n",
    "                    \n",
    "                    if has_data:\n",
    "                        # Plotly display\n",
    "                        fig2 = go.Figure(go.Heatmap(\n",
    "                            z=cn0_grid,\n",
    "                            x=[f\"{az_bins[i]}-{az_bins[i+1]}\" for i in range(len(az_bins)-1)],\n",
    "                            y=[f\"{el_bins[i]}-{el_bins[i+1]}\" for i in range(len(el_bins)-1)],\n",
    "                            colorscale='Viridis',\n",
    "                            colorbar=dict(title='CN0 (dB-Hz)'),\n",
    "                            hoverongaps=False,\n",
    "                            zmin=30, zmax=55\n",
    "                        ))\n",
    "                        \n",
    "                        fig2.update_layout(\n",
    "                            title='CN0 Heatmap by Azimuth/Elevation',\n",
    "                            xaxis_title='Azimuth (¬∞)',\n",
    "                            yaxis_title='Elevation (¬∞)',\n",
    "                            width=850, height=500\n",
    "                        )\n",
    "                        fig2.show()\n",
    "                        \n",
    "                        # ===== SAVE PNG =====\n",
    "                        try:\n",
    "                            fig_h2, ax = plt.subplots(figsize=(12, 6))\n",
    "                            \n",
    "                            z_array = np.array([[v if v is not None else np.nan for v in row] for row in cn0_grid])\n",
    "                            \n",
    "                            im = ax.imshow(z_array, aspect='auto', cmap='viridis', vmin=30, vmax=55, origin='lower')\n",
    "                            \n",
    "                            # X-axis: azimuth\n",
    "                            ax.set_xticks(range(len(az_bins)-1))\n",
    "                            ax.set_xticklabels([f\"{az_bins[i]}\" for i in range(len(az_bins)-1)], rotation=45, ha='right', fontsize=8)\n",
    "                            \n",
    "                            # Y-axis: elevation\n",
    "                            ax.set_yticks(range(len(el_bins)-1))\n",
    "                            ax.set_yticklabels([f\"{el_bins[i]}\" for i in range(len(el_bins)-1)], fontsize=8)\n",
    "                            \n",
    "                            ax.set_xlabel('Azimuth (¬∞)', fontsize=12)\n",
    "                            ax.set_ylabel('Elevation (¬∞)', fontsize=12)\n",
    "                            ax.set_title('CN0 Heatmap by Azimuth/Elevation', fontsize=14, fontweight='bold')\n",
    "                            \n",
    "                            cbar = plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "                            cbar.set_label('CN0 (dB-Hz)', fontsize=10)\n",
    "                            \n",
    "                            plt.tight_layout()\n",
    "                            heatmap2_path = os.path.join(export_dir, 'heatmap_azel.png')\n",
    "                            plt.savefig(heatmap2_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "                            plt.close()\n",
    "                            export_state['files'].append({'name': 'heatmap_azel.png', 'title': 'Az/El Heatmap'})\n",
    "                            print(f\"   ‚úÖ heatmap_azel.png\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"   ‚ö†Ô∏è Az/El heatmap PNG error: {e}\")\n",
    "                            plt.close()\n",
    "                    else:\n",
    "                        print(\"   ‚ö†Ô∏è No Az/El data points found in traces\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Az/El heatmap error: {e}\")\n",
    "        \n",
    "        print(f\"\\nüìÅ Files saved to: {export_dir}/\")\n",
    "\n",
    "btn_heatmap.on_click(show_heatmaps)\n",
    "print(\"‚úÖ Heatmap function ready (v6 - with PNG export)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SNR Graphs ready (v6 - parallel processing)\n"
     ]
    }
   ],
   "source": [
    "# === SHOW SNR GRAPHS (v6 - optimized with parallel processing) ===\n",
    "def show_snr_graphs(btn):\n",
    "    \"\"\"Show CN0 timeseries and save PNG - with parallel processing\"\"\"\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import concurrent.futures\n",
    "    import multiprocessing\n",
    "    import time\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        n_cores = multiprocessing.cpu_count()\n",
    "        print(\"üìà Generating SNR timeseries...\")\n",
    "        print(f\"   ‚ö° Using {n_cores} CPU cores for parallel processing\")\n",
    "    \n",
    "    result = analysis_results.get('data')\n",
    "    if not result:\n",
    "        result = run_core_analysis()\n",
    "    if not result:\n",
    "        return\n",
    "    \n",
    "    export_dir = get_export_dir()\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        \n",
    "        n_cores = multiprocessing.cpu_count()\n",
    "        print(\"üìà Generating SNR timeseries...\")\n",
    "        print(f\"   ‚ö° Using {n_cores} CPU cores for parallel processing\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Get JSON data\n",
    "        json_start = time.time()\n",
    "        result_json = json.loads(result.to_json())\n",
    "        sat_ts = result_json.get('timeseries', {}).get('satellite_timeseries', {})\n",
    "        if not sat_ts:\n",
    "            sat_ts = result_json.get('satellite_timeseries', {})\n",
    "        json_time = time.time() - json_start\n",
    "        print(f\"   ‚è±Ô∏è JSON parse: {json_time:.2f}s ({len(sat_ts)} satellites)\")\n",
    "        \n",
    "        if not sat_ts:\n",
    "            print(\"‚ö†Ô∏è No timeseries data available\")\n",
    "            return\n",
    "        \n",
    "        # ========== PARALLEL DATA EXTRACTION ==========\n",
    "        extract_start = time.time()\n",
    "        \n",
    "        def extract_satellite_data(item):\n",
    "            \"\"\"Extract data from single satellite - runs in parallel\"\"\"\n",
    "            sat_id, sat_data = item\n",
    "            if not isinstance(sat_data, dict):\n",
    "                return None\n",
    "            \n",
    "            sys_code = sat_id[0] if sat_id else 'X'\n",
    "            sys_name = SYS_CODE_MAP.get(sys_code, sys_code)\n",
    "            \n",
    "            points = []\n",
    "            sat_times = []\n",
    "            sat_cn0 = []\n",
    "            \n",
    "            # Try cn0_series first\n",
    "            cn0_series = sat_data.get('cn0_series', sat_data.get('series', []))\n",
    "            if isinstance(cn0_series, list):\n",
    "                for p in cn0_series:\n",
    "                    if isinstance(p, dict):\n",
    "                        t = p.get('timestamp', p.get('time', ''))\n",
    "                        v = p.get('value', p.get('cn0'))\n",
    "                        if t and v is not None and v > 0:\n",
    "                            points.append((t, float(v), sys_name))\n",
    "                            sat_times.append(t)\n",
    "                            sat_cn0.append(float(v))\n",
    "            \n",
    "            # Also try timestamps + cn0 arrays\n",
    "            if not points:\n",
    "                timestamps = sat_data.get('timestamps', [])\n",
    "                cn0_arr = sat_data.get('cn0', [])\n",
    "                if timestamps and cn0_arr and len(timestamps) == len(cn0_arr):\n",
    "                    for t, v in zip(timestamps, cn0_arr):\n",
    "                        if t and v is not None and v > 0:\n",
    "                            points.append((t, float(v), sys_name))\n",
    "                            sat_times.append(t)\n",
    "                            sat_cn0.append(float(v))\n",
    "            \n",
    "            return {\n",
    "                'sat_id': sat_id,\n",
    "                'sys_code': sys_code,\n",
    "                'sys_name': sys_name,\n",
    "                'points': points,\n",
    "                'times': sat_times,\n",
    "                'cn0': sat_cn0\n",
    "            }\n",
    "        \n",
    "        # Process satellites in parallel\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=n_cores) as executor:\n",
    "            extracted = list(executor.map(extract_satellite_data, sat_ts.items()))\n",
    "        \n",
    "        # Filter None results\n",
    "        extracted = [e for e in extracted if e is not None and e['points']]\n",
    "        \n",
    "        extract_time = time.time() - extract_start\n",
    "        print(f\"   ‚è±Ô∏è Parallel extraction: {extract_time:.2f}s ({len(extracted)} satellites with data)\")\n",
    "        \n",
    "        if not extracted:\n",
    "            print(\"‚ö†Ô∏è No CN0 data found in any satellite\")\n",
    "            return\n",
    "        \n",
    "        # Combine all points\n",
    "        all_points = []\n",
    "        for e in extracted:\n",
    "            all_points.extend(e['points'])\n",
    "        \n",
    "        # Create DataFrame with vectorized operations\n",
    "        df_start = time.time()\n",
    "        df = pd.DataFrame(all_points, columns=['timestamp', 'cn0', 'constellation'])\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df = df.sort_values('timestamp')\n",
    "        \n",
    "        # Aggregate by 30-second bins (vectorized)\n",
    "        df['time_bin'] = df['timestamp'].dt.floor('30s')\n",
    "        overall = df.groupby('time_bin').agg(\n",
    "            cn0_mean=('cn0', 'mean'),\n",
    "            cn0_std=('cn0', 'std'),\n",
    "            sat_count=('cn0', 'count')\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Per-constellation aggregation\n",
    "        const_agg = {}\n",
    "        for const in df['constellation'].unique():\n",
    "            cdf = df[df['constellation'] == const]\n",
    "            cagg = cdf.groupby('time_bin')['cn0'].mean().reset_index()\n",
    "            const_agg[const] = cagg\n",
    "        \n",
    "        df_time = time.time() - df_start\n",
    "        print(f\"   ‚è±Ô∏è DataFrame ops: {df_time:.2f}s ({len(overall)} bins, {len(df)} points)\")\n",
    "        print(f\"   üì° Constellations: {', '.join(sorted(const_agg.keys()))}\")\n",
    "        \n",
    "        # ========== PLOTLY DISPLAY (Overall) ==========\n",
    "        plot_start = time.time()\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=1,\n",
    "            shared_xaxes=True,\n",
    "            row_heights=[0.7, 0.3],\n",
    "            vertical_spacing=0.05,\n",
    "            subplot_titles=('Mean CN0 Over Time', 'Satellite Count')\n",
    "        )\n",
    "        \n",
    "        # Overall mean\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=overall['time_bin'], y=overall['cn0_mean'],\n",
    "            mode='lines', name='Overall',\n",
    "            line=dict(color='black', width=2.5)\n",
    "        ), row=1, col=1)\n",
    "        \n",
    "        # Per-constellation lines\n",
    "        for const, cdf in const_agg.items():\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=cdf['time_bin'], y=cdf['cn0'],\n",
    "                mode='lines', name=const,\n",
    "                line=dict(color=SYSTEM_COLORS.get(const, '#888'), width=1.5)\n",
    "            ), row=1, col=1)\n",
    "        \n",
    "        # Satellite count\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=overall['time_bin'], y=overall['sat_count'],\n",
    "            marker=dict(color='#48bb78'), showlegend=False\n",
    "        ), row=2, col=1)\n",
    "        \n",
    "        # Threshold lines\n",
    "        fig.add_hline(y=45, line_dash='dash', line_color='green', annotation_text='Excellent', row=1, col=1)\n",
    "        fig.add_hline(y=35, line_dash='dash', line_color='orange', annotation_text='Good', row=1, col=1)\n",
    "        fig.add_hline(y=25, line_dash='dash', line_color='red', annotation_text='Marginal', row=1, col=1)\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='CN0 Time Series with SNR Thresholds',\n",
    "            height=550, width=1000,\n",
    "            legend=dict(orientation='h', y=1.12)\n",
    "        )\n",
    "        fig.update_yaxes(title_text='CN0 (dB-Hz)', row=1, col=1)\n",
    "        fig.update_yaxes(title_text='Satellites', row=2, col=1)\n",
    "        fig.update_xaxes(title_text='Time (UTC)', row=2, col=1)\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        plot_time = time.time() - plot_start\n",
    "        print(f\"   ‚è±Ô∏è Overall plot: {plot_time:.2f}s\")\n",
    "        \n",
    "        # ========== SAVE OVERALL PNG ==========\n",
    "        print(f\"\\nüìÅ Saving to: {export_dir}/\")\n",
    "        \n",
    "        try:\n",
    "            fig_ts, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8), gridspec_kw={'height_ratios': [3, 1]}, sharex=True)\n",
    "            \n",
    "            ax1.plot(overall['time_bin'], overall['cn0_mean'], 'k-', linewidth=2, label='Overall Mean')\n",
    "            if 'cn0_std' in overall.columns:\n",
    "                ax1.fill_between(overall['time_bin'], \n",
    "                    overall['cn0_mean'] - overall['cn0_std'].fillna(0),\n",
    "                    overall['cn0_mean'] + overall['cn0_std'].fillna(0),\n",
    "                    alpha=0.2, color='blue')\n",
    "            \n",
    "            for const, cdf in const_agg.items():\n",
    "                ax1.plot(cdf['time_bin'], cdf['cn0'], '-', linewidth=1.5,\n",
    "                    color=SYSTEM_COLORS.get(const, '#888'), label=const, alpha=0.8)\n",
    "            \n",
    "            ax1.axhline(y=45, color='green', linestyle='--', linewidth=2, label='Excellent (45)')\n",
    "            ax1.axhline(y=35, color='orange', linestyle='--', linewidth=2, label='Good (35)')\n",
    "            ax1.axhline(y=25, color='red', linestyle='--', linewidth=2, label='Marginal (25)')\n",
    "            \n",
    "            ax1.set_ylabel('CN0 (dB-Hz)', fontsize=12)\n",
    "            ax1.set_title('CN0 Time Series with SNR Quality Thresholds', fontsize=14, fontweight='bold')\n",
    "            ax1.legend(loc='upper right', ncol=3, fontsize=9)\n",
    "            ax1.grid(alpha=0.3)\n",
    "            ax1.set_ylim(20, 55)\n",
    "            \n",
    "            ax2.bar(overall['time_bin'], overall['sat_count'], width=0.0003, color='#48bb78', alpha=0.8)\n",
    "            ax2.set_ylabel('Satellites', fontsize=12)\n",
    "            ax2.set_xlabel('Time (UTC)', fontsize=12)\n",
    "            ax2.grid(alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            ts_path = os.path.join(export_dir, 'cn0_timeseries.png')\n",
    "            plt.savefig(ts_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "            plt.close()\n",
    "            export_state['files'].append({'name': 'cn0_timeseries.png', 'title': 'CN0 Timeseries'})\n",
    "            print(f\"   ‚úÖ cn0_timeseries.png\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Timeseries PNG error: {e}\")\n",
    "        \n",
    "        # ========== PER-CONSTELLATION GRAPHS (PARALLEL) ==========\n",
    "        print(\"\\nüì° Per-Constellation SNR Graphs (parallel):\")\n",
    "        \n",
    "        # Group extracted data by constellation\n",
    "        by_const = {}\n",
    "        for e in extracted:\n",
    "            sys_name = e['sys_name']\n",
    "            if sys_name not in by_const:\n",
    "                by_const[sys_name] = []\n",
    "            by_const[sys_name].append(e)\n",
    "        \n",
    "        def process_constellation(const_name):\n",
    "            \"\"\"Process single constellation - runs in parallel\"\"\"\n",
    "            sats = by_const.get(const_name, [])\n",
    "            if not sats:\n",
    "                return None\n",
    "            \n",
    "            # Build Plotly figure\n",
    "            fig_const = go.Figure()\n",
    "            \n",
    "            for sat_data in sorted(sats, key=lambda x: x['sat_id']):\n",
    "                sat_id = sat_data['sat_id']\n",
    "                sat_times = sat_data['times']\n",
    "                sat_cn0 = sat_data['cn0']\n",
    "                \n",
    "                if sat_times and len(sat_times) > 5:\n",
    "                    # Downsample if too many points\n",
    "                    max_points = 500\n",
    "                    if len(sat_times) > max_points:\n",
    "                        step = len(sat_times) // max_points\n",
    "                        sat_times = sat_times[::step]\n",
    "                        sat_cn0 = sat_cn0[::step]\n",
    "                    \n",
    "                    fig_const.add_trace(go.Scatter(\n",
    "                        x=pd.to_datetime(sat_times),\n",
    "                        y=sat_cn0,\n",
    "                        mode='lines',\n",
    "                        name=sat_id,\n",
    "                        line=dict(width=1.5),\n",
    "                        opacity=0.8\n",
    "                    ))\n",
    "            \n",
    "            if len(fig_const.data) == 0:\n",
    "                return None\n",
    "            \n",
    "            fig_const.add_hline(y=45, line_dash='dash', line_color='green', annotation_text='Excellent')\n",
    "            fig_const.add_hline(y=35, line_dash='dash', line_color='orange', annotation_text='Good')\n",
    "            fig_const.add_hline(y=25, line_dash='dash', line_color='red', annotation_text='Marginal')\n",
    "            \n",
    "            fig_const.update_layout(\n",
    "                title=f'{const_name} - Per-Satellite CN0 Timeseries',\n",
    "                xaxis_title='Time (UTC)',\n",
    "                yaxis_title='CN0 (dB-Hz)',\n",
    "                height=450, width=1100, margin=dict(r=120),\n",
    "                legend=dict(\n",
    "                    orientation='v',  # Vertical on right\n",
    "                    yanchor='top',\n",
    "                    y=1.0,\n",
    "                    xanchor='left', \n",
    "                    x=1.02,\n",
    "                    font=dict(size=8),\n",
    "                    tracegroupgap=2\n",
    "                ),\n",
    "                yaxis=dict(range=[20, 55])\n",
    "            )\n",
    "            \n",
    "            return {'name': const_name, 'fig': fig_const, 'sats': sats}\n",
    "        \n",
    "        # Process constellations in parallel\n",
    "        const_start = time.time()\n",
    "        const_names = sorted(by_const.keys())\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=n_cores) as executor:\n",
    "            const_results = list(executor.map(process_constellation, const_names))\n",
    "        \n",
    "        const_results = [r for r in const_results if r is not None]\n",
    "        \n",
    "        const_time = time.time() - const_start\n",
    "        print(f\"   ‚è±Ô∏è Parallel constellation processing: {const_time:.2f}s\")\n",
    "        \n",
    "        # Display and save each constellation\n",
    "        for const_result in const_results:\n",
    "            const_name = const_result['name']\n",
    "            fig_const = const_result['fig']\n",
    "            sats = const_result['sats']\n",
    "            \n",
    "            # Display Plotly\n",
    "            fig_const.show()\n",
    "            \n",
    "            # Save PNG\n",
    "            try:\n",
    "                fig_png, ax = plt.subplots(figsize=(12, 5))\n",
    "                \n",
    "                for sat_data in sorted(sats, key=lambda x: x['sat_id']):\n",
    "                    sat_id = sat_data['sat_id']\n",
    "                    sat_times = sat_data['times']\n",
    "                    sat_cn0 = sat_data['cn0']\n",
    "                    \n",
    "                    if sat_times and len(sat_times) > 5:\n",
    "                        # Downsample\n",
    "                        max_points = 500\n",
    "                        if len(sat_times) > max_points:\n",
    "                            step = len(sat_times) // max_points\n",
    "                            sat_times = sat_times[::step]\n",
    "                            sat_cn0 = sat_cn0[::step]\n",
    "                        \n",
    "                        ax.plot(pd.to_datetime(sat_times), sat_cn0, '-', linewidth=1, label=sat_id, alpha=0.7)\n",
    "                \n",
    "                ax.axhline(y=45, color='green', linestyle='--', linewidth=2, label='Excellent (45)')\n",
    "                ax.axhline(y=35, color='orange', linestyle='--', linewidth=2, label='Good (35)')\n",
    "                ax.axhline(y=25, color='red', linestyle='--', linewidth=2, label='Marginal (25)')\n",
    "                \n",
    "                ax.set_ylabel('CN0 (dB-Hz)', fontsize=12)\n",
    "                ax.set_xlabel('Time (UTC)', fontsize=12)\n",
    "                ax.set_title(f'{const_name} - Per-Satellite CN0 with SNR Thresholds', fontsize=14, fontweight='bold')\n",
    "                ax.legend(loc='upper right', ncol=4, fontsize=8)\n",
    "                ax.grid(alpha=0.3)\n",
    "                ax.set_ylim(20, 55)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                const_filename = f'cn0_{const_name.lower().replace(\" \", \"_\")}.png'\n",
    "                const_path = os.path.join(export_dir, const_filename)\n",
    "                plt.savefig(const_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "                plt.close()\n",
    "                export_state['files'].append({'name': const_filename, 'title': f'{const_name} CN0'})\n",
    "                print(f\"   ‚úÖ {const_filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ö†Ô∏è {const_name} PNG error: {e}\")\n",
    "                plt.close()\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\n   ‚úÖ Total time: {total_time:.2f}s\")\n",
    "        print(f\"üìÅ Files saved to: {export_dir}/\")\n",
    "\n",
    "btn_snr.on_click(show_snr_graphs)\n",
    "print(\"‚úÖ SNR Graphs ready (v6 - parallel processing)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Skyplot ready (v6 - parallel processing, CN0-only satellites)\n"
     ]
    }
   ],
   "source": [
    "# === SHOW SKYPLOT (v6 - optimized with parallel processing) ===\n",
    "def show_skyplot(btn):\n",
    "    \"\"\"Show satellite skyplot - REQUIRES navigation file for az/el data\n",
    "    \n",
    "    ‚ö†Ô∏è NOTE: Only satellites with CN0/SNR measurements are displayed.\n",
    "    Uses parallel processing with all available CPU cores for speed.\n",
    "    \"\"\"\n",
    "    import concurrent.futures\n",
    "    import multiprocessing\n",
    "    import numpy as np\n",
    "    import time\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        n_cores = multiprocessing.cpu_count()\n",
    "        print(\"üõ∞Ô∏è Generating skyplot...\")\n",
    "        print(f\"   ‚ö° Using {n_cores} CPU cores for parallel processing\")\n",
    "        print(\"   ‚ÑπÔ∏è Only satellites with CN0/SNR data will be shown\")\n",
    "    \n",
    "    result = analysis_results.get('data')\n",
    "    if not result:\n",
    "        result = run_core_analysis()\n",
    "    \n",
    "    if not result:\n",
    "        return\n",
    "    \n",
    "    export_dir = get_export_dir()\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        \n",
    "        n_cores = multiprocessing.cpu_count()\n",
    "        print(\"üõ∞Ô∏è Generating skyplot...\")\n",
    "        print(f\"   ‚ö° Using {n_cores} CPU cores for parallel processing\")\n",
    "        print(\"   ‚ÑπÔ∏è Only satellites with CN0/SNR data will be shown\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            skyplot_data = result.get_skyplot_data()\n",
    "            fetch_time = time.time() - start_time\n",
    "            print(f\"   ‚è±Ô∏è Data fetch: {fetch_time:.2f}s\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error getting skyplot data: {e}\")\n",
    "            skyplot_data = None\n",
    "        \n",
    "        if not skyplot_data:\n",
    "            print(\"\")\n",
    "            print(\"‚ö†Ô∏è No skyplot data available\")\n",
    "            print(\"\")\n",
    "            print(\"üìã Skyplot requires:\")\n",
    "            print(\"   1. A navigation file (.nav/.rnx) OR auto-download BRDC enabled\")\n",
    "            print(\"   2. Satellites with CN0/SNR measurements\")\n",
    "            print(\"\")\n",
    "            print(\"   To fix:\")\n",
    "            print(\"   ‚Ä¢ Enable 'Auto-download BRDC' checkbox and reload\")\n",
    "            print(\"   ‚Ä¢ OR load a .nav file manually\")\n",
    "            return\n",
    "        \n",
    "        # Handle both list and dict formats\n",
    "        traces = skyplot_data if isinstance(skyplot_data, list) else skyplot_data.get('traces', [])\n",
    "        \n",
    "        if not traces:\n",
    "            print(\"‚ö†Ô∏è No satellite traces in skyplot data\")\n",
    "            return\n",
    "        \n",
    "        print(f\"   üì° Processing {len(traces)} satellites...\")\n",
    "        \n",
    "        # ========== PARALLEL PROCESSING ==========\n",
    "        def parse_values_np(val):\n",
    "            \"\"\"Parse values using numpy for speed\"\"\"\n",
    "            if val is None:\n",
    "                return np.array([])\n",
    "            if isinstance(val, (list, np.ndarray)):\n",
    "                arr = np.array([x for x in val if x is not None], dtype=np.float64)\n",
    "                return arr\n",
    "            if isinstance(val, str) and val.strip():\n",
    "                try:\n",
    "                    return np.array([float(x.strip()) for x in val.split(',') if x.strip()], dtype=np.float64)\n",
    "                except:\n",
    "                    return np.array([])\n",
    "            return np.array([])\n",
    "        \n",
    "        def process_satellite(trace):\n",
    "            \"\"\"Process single satellite - runs in parallel\"\"\"\n",
    "            if not isinstance(trace, dict):\n",
    "                return None\n",
    "            \n",
    "            sat_id = trace.get('satellite', trace.get('name', ''))\n",
    "            system = trace.get('system', sat_id[0] if sat_id else 'X')\n",
    "            \n",
    "            azimuths = parse_values_np(trace.get('azimuths', trace.get('azimuth', [])))\n",
    "            elevations = parse_values_np(trace.get('elevations', trace.get('elevation', [])))\n",
    "            cn0_values = parse_values_np(trace.get('cn0_values', trace.get('cn0', [])))\n",
    "            \n",
    "            # Skip satellites without data\n",
    "            if len(azimuths) == 0 or len(elevations) == 0:\n",
    "                return None\n",
    "            \n",
    "            # Vectorized computation\n",
    "            min_len = min(len(azimuths), len(elevations))\n",
    "            r_vals = 90 - elevations[:min_len]\n",
    "            az_vals = azimuths[:min_len]\n",
    "            \n",
    "            # Handle CN0 - if missing, skip this satellite (CN0-only display)\n",
    "            if len(cn0_values) >= min_len:\n",
    "                cn0_list = cn0_values[:min_len]\n",
    "            elif len(cn0_values) > 0:\n",
    "                # Pad with last known value\n",
    "                cn0_list = np.pad(cn0_values, (0, min_len - len(cn0_values)), \n",
    "                                  mode='edge')[:min_len]\n",
    "            else:\n",
    "                # No CN0 data - skip satellite\n",
    "                return None\n",
    "            \n",
    "            # Downsample if too many points (>300 per satellite)\n",
    "            max_points = 300\n",
    "            if min_len > max_points:\n",
    "                step = min_len // max_points\n",
    "                r_vals = r_vals[::step]\n",
    "                az_vals = az_vals[::step]\n",
    "                cn0_list = cn0_list[::step]\n",
    "            \n",
    "            return {\n",
    "                'sat_id': sat_id,\n",
    "                'system': system,\n",
    "                'r_vals': r_vals.tolist(),\n",
    "                'az_vals': az_vals.tolist(),\n",
    "                'cn0_list': cn0_list.tolist()\n",
    "            }\n",
    "        \n",
    "        # Process satellites in parallel using ThreadPoolExecutor\n",
    "        process_start = time.time()\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=n_cores) as executor:\n",
    "            processed = list(executor.map(process_satellite, traces))\n",
    "        \n",
    "        # Filter out None (satellites without CN0)\n",
    "        processed = [p for p in processed if p is not None]\n",
    "        \n",
    "        process_time = time.time() - process_start\n",
    "        print(f\"   ‚è±Ô∏è Parallel processing: {process_time:.2f}s ({len(processed)}/{len(traces)} with CN0)\")\n",
    "        \n",
    "        if not processed:\n",
    "            print(\"\")\n",
    "            print(\"‚ö†Ô∏è No satellites with CN0/SNR data to display\")\n",
    "            print(\"   The skyplot only shows satellites that have signal strength measurements.\")\n",
    "            return\n",
    "        \n",
    "        # ========== BUILD PLOTLY FIGURE ==========\n",
    "        plot_start = time.time()\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        const_colors = {'G': '#3b82f6', 'R': '#ef4444', 'E': '#22c55e', 'C': '#f59e0b', 'J': '#8b5cf6', 'I': '#ec4899'}\n",
    "        \n",
    "        for idx, sat_data in enumerate(processed):\n",
    "            sat_id = sat_data['sat_id']\n",
    "            system = sat_data['system']\n",
    "            const_color = const_colors.get(system, '#888')\n",
    "            \n",
    "            fig.add_trace(go.Scatterpolar(\n",
    "                r=sat_data['r_vals'],\n",
    "                theta=sat_data['az_vals'],\n",
    "                mode='markers+lines',\n",
    "                marker=dict(\n",
    "                    size=5,\n",
    "                    color=sat_data['cn0_list'],\n",
    "                    colorscale='Viridis',\n",
    "                    cmin=25, cmax=55,\n",
    "                    showscale=(idx == 0),\n",
    "                    colorbar=dict(\n",
    "                        title='CN0<br>(dB-Hz)',\n",
    "                        x=-0.15,  # Position on LEFT side\n",
    "                        xanchor='right',\n",
    "                        y=0.5,\n",
    "                        yanchor='middle',\n",
    "                        len=0.6,\n",
    "                        thickness=15\n",
    "                    ) if idx == 0 else None\n",
    "                ),\n",
    "                line=dict(width=1.5, color=const_color),\n",
    "                name=str(sat_id),\n",
    "                hovertemplate=f'{sat_id}<br>Az: %{{theta}}¬∞<br>El: %{{customdata}}¬∞<br>CN0: %{{marker.color:.1f}}<extra></extra>',\n",
    "                customdata=[90 - r for r in sat_data['r_vals']]\n",
    "            ))\n",
    "        \n",
    "        plot_time = time.time() - plot_start\n",
    "        print(f\"   ‚è±Ô∏è Plot building: {plot_time:.2f}s\")\n",
    "        \n",
    "        # Layout\n",
    "        try:\n",
    "            coverage = result.skyplot_coverage\n",
    "            title = f'üõ∞Ô∏è Satellite Skyplot ({len(processed)} sats with CN0, Coverage: {coverage:.1f}%)'\n",
    "        except:\n",
    "            title = f'üõ∞Ô∏è Satellite Skyplot ({len(processed)} satellites with CN0 data)'\n",
    "        \n",
    "        # Legend outside to right, scrollable for many satellites\n",
    "        fig.update_layout(\n",
    "            polar=dict(\n",
    "                radialaxis=dict(visible=True, range=[0, 90],\n",
    "                               tickvals=[0, 30, 60, 90],\n",
    "                               ticktext=['90¬∞', '60¬∞', '30¬∞', '0¬∞']),\n",
    "                angularaxis=dict(direction='clockwise', rotation=90,\n",
    "                                tickvals=[0, 45, 90, 135, 180, 225, 270, 315],\n",
    "                                ticktext=['N', 'NE', 'E', 'SE', 'S', 'SW', 'W', 'NW'])\n",
    "            ),\n",
    "            title=dict(text=title, x=0.5, font=dict(size=14)),\n",
    "            showlegend=True,\n",
    "            legend=dict(\n",
    "                orientation='v',  # Vertical legend on right side\n",
    "                yanchor='top',\n",
    "                y=1.0,\n",
    "                xanchor='left',\n",
    "                x=1.05,  # Position to the right of the plot (offset from colorbar)\n",
    "                font=dict(size=8),\n",
    "                itemsizing='constant',\n",
    "                tracegroupgap=2,\n",
    "            ),\n",
    "            height=700,\n",
    "            width=950,  # Wider to accommodate legend on right\n",
    "            margin=dict(l=100, r=180)  # Right margin for legend\n",
    "        )\n",
    "        fig.show()\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\n   ‚úÖ Total time: {total_time:.2f}s\")\n",
    "        print(f\"   ‚ÑπÔ∏è {len(traces) - len(processed)} satellites without CN0 not shown\")\n",
    "        \n",
    "        # ========== SAVE PNG ==========\n",
    "        print(f\"\\nüìÅ Saving to: {export_dir}/\")\n",
    "        \n",
    "        try:\n",
    "            import matplotlib\n",
    "            matplotlib.use('Agg')\n",
    "            import matplotlib.pyplot as plt\n",
    "            \n",
    "            fig_sky, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
    "            \n",
    "            for sat_data in processed:\n",
    "                theta_rad = np.radians(sat_data['az_vals'])\n",
    "                r_vals = sat_data['r_vals']\n",
    "                cn0_vals = sat_data['cn0_list']\n",
    "                system = sat_data['system']\n",
    "                \n",
    "                color = const_colors.get(system, '#888')\n",
    "                ax.plot(theta_rad, r_vals, '-', color=color, linewidth=1, alpha=0.5)\n",
    "                sc = ax.scatter(theta_rad, r_vals, c=cn0_vals, cmap='viridis',\n",
    "                               s=12, vmin=25, vmax=55, alpha=0.8, zorder=5)\n",
    "            \n",
    "            ax.set_theta_zero_location('N')\n",
    "            ax.set_theta_direction(-1)\n",
    "            ax.set_ylim(0, 90)\n",
    "            ax.set_yticks([0, 30, 60, 90])\n",
    "            ax.set_yticklabels(['90¬∞', '60¬∞', '30¬∞', '0¬∞'])\n",
    "            ax.set_title(f'Satellite Skyplot ({len(processed)} satellites with CN0)', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            cbar = plt.colorbar(sc, ax=ax, shrink=0.8, pad=0.1)\n",
    "            cbar.set_label('CN0 (dB-Hz)', fontsize=10)\n",
    "            \n",
    "            # Constellation legend\n",
    "            from matplotlib.lines import Line2D\n",
    "            legend_items = [(n, c) for n, c in [('GPS', '#3b82f6'), ('GLONASS', '#ef4444'),\n",
    "                            ('Galileo', '#22c55e'), ('BeiDou', '#f59e0b'), ('QZSS', '#8b5cf6')]]\n",
    "            legend_elements = [Line2D([0], [0], color=c, linewidth=2, label=n) for n, c in legend_items]\n",
    "            ax.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            skyplot_path = os.path.join(export_dir, 'skyplot.png')\n",
    "            plt.savefig(skyplot_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "            plt.close()\n",
    "            export_state['files'].append({'name': 'skyplot.png', 'title': 'Satellite Skyplot'})\n",
    "            print(f\"   ‚úÖ skyplot.png\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è PNG error: {e}\")\n",
    "\n",
    "btn_skyplot.on_click(show_skyplot)\n",
    "print(\"‚úÖ Skyplot ready (v6 - parallel processing, CN0-only satellites)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Anomaly function ready\n"
     ]
    }
   ],
   "source": [
    "# === SHOW ANOMALIES ===\n",
    "def show_anomalies(btn):\n",
    "    \"\"\"Show anomaly timeline\"\"\"\n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        print(\"‚ö†Ô∏è Generating anomaly timeline...\")\n",
    "    \n",
    "    result = analysis_results.get('data')\n",
    "    if not result:\n",
    "        result = run_core_analysis()\n",
    "    \n",
    "    if not result:\n",
    "        return\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        \n",
    "        anomalies = result.get_anomalies()\n",
    "        \n",
    "        if not anomalies:\n",
    "            print(\"‚úÖ No anomalies detected!\")\n",
    "            fig = go.Figure()\n",
    "            fig.add_annotation(\n",
    "                text='‚úÖ No anomalies detected',\n",
    "                xref='paper', yref='paper',\n",
    "                x=0.5, y=0.5, showarrow=False,\n",
    "                font=dict(size=24, color='green')\n",
    "            )\n",
    "            fig.update_layout(height=300, title='Anomaly Timeline')\n",
    "            fig.show()\n",
    "            return\n",
    "        \n",
    "        print(f\"‚ö†Ô∏è Found {len(anomalies)} anomalies\")\n",
    "        \n",
    "        severity_colors = {\n",
    "            'critical': '#ef4444', 'high': '#f97316',\n",
    "            'medium': '#eab308', 'low': '#22c55e',\n",
    "            'Critical': '#ef4444', 'High': '#f97316',\n",
    "            'Medium': '#eab308', 'Low': '#22c55e'\n",
    "        }\n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        parsed_data = []\n",
    "        for a in anomalies:\n",
    "            try:\n",
    "                ts_str = a.get('start_time') or a.get('timestamp') or ''\n",
    "                if ts_str:\n",
    "                    ts = pd.to_datetime(ts_str)\n",
    "                    severity = a.get('severity', 'Low')\n",
    "                    anom_type = a.get('anomaly_type', a.get('type', 'Unknown'))\n",
    "                    cn0_drop = float(a.get('cn0_drop', a.get('cn0_drop_db', 0)) or 0)\n",
    "                    \n",
    "                    parsed_data.append({\n",
    "                        'time': ts,\n",
    "                        'severity': severity,\n",
    "                        'type': anom_type,\n",
    "                        'cn0_drop': cn0_drop,\n",
    "                        'satellites': a.get('affected_satellites', '')\n",
    "                    })\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # Group by severity\n",
    "        by_severity = defaultdict(list)\n",
    "        for p in parsed_data:\n",
    "            by_severity[p['severity']].append(p)\n",
    "        \n",
    "        for severity, data in by_severity.items():\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=[d['time'] for d in data],\n",
    "                y=[d['cn0_drop'] for d in data],\n",
    "                mode='markers',\n",
    "                name=severity,\n",
    "                marker=dict(\n",
    "                    size=12,\n",
    "                    color=severity_colors.get(severity, '#888'),\n",
    "                    symbol='diamond'\n",
    "                ),\n",
    "                text=[f\"{d['type']}: {d['satellites']}\" for d in data],\n",
    "                hovertemplate='%{text}<br>CN0 Drop: %{y:.1f} dB<br>Time: %{x}'\n",
    "            ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=f'Anomaly Timeline ({len(parsed_data)} events)',\n",
    "            xaxis_title='Time (UTC)',\n",
    "            yaxis_title='CN0 Drop (dB)',\n",
    "            height=450, width=1000,\n",
    "            showlegend=True\n",
    "        )\n",
    "        fig.show()\n",
    "        \n",
    "        # Summary table\n",
    "        print(\"\\nAnomaly Summary:\")\n",
    "        for severity in ['Critical', 'High', 'Medium', 'Low']:\n",
    "            count = len([p for p in parsed_data if p['severity'].lower() == severity.lower()])\n",
    "            if count > 0:\n",
    "                print(f\"   {severity}: {count}\")\n",
    "\n",
    "btn_anomaly.on_click(show_anomalies)\n",
    "print(\"‚úÖ Anomaly function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Download Report handler ready\n"
     ]
    }
   ],
   "source": [
    "# === DOWNLOAD REPORT (v6 - generates HTML from saved files) ===\n",
    "def download_report(btn):\n",
    "    \"\"\"Generate HTML report from saved PNG files\"\"\"\n",
    "    import base64\n",
    "    \n",
    "    with results_out:\n",
    "        clear_output()\n",
    "        \n",
    "        result = analysis_results.get('data')\n",
    "        if not result:\n",
    "            print(\"‚ö†Ô∏è Run analysis first (click Summary button)\")\n",
    "            return\n",
    "        \n",
    "        export_dir = get_export_dir()\n",
    "        qs = result.quality_score\n",
    "        \n",
    "        print(f\"üìÑ Generating HTML report from: {export_dir}/\")\n",
    "        \n",
    "        # Embed PNGs as base64\n",
    "        def embed_png(filename):\n",
    "            filepath = os.path.join(export_dir, filename)\n",
    "            if os.path.exists(filepath):\n",
    "                with open(filepath, 'rb') as f:\n",
    "                    b64 = base64.b64encode(f.read()).decode()\n",
    "                return f'<img src=\"data:image/png;base64,{b64}\" style=\"max-width:100%; margin:10px 0;\">'\n",
    "            return f'<p style=\"color:gray;\">[{filename} not found - click corresponding button first]</p>'\n",
    "        \n",
    "        # Get constellation data\n",
    "        const_html = ''\n",
    "        for sys_name in result.constellations:\n",
    "            stats = result.get_constellation_summary(sys_name)\n",
    "            if stats:\n",
    "                cn0_mean = float(stats['cn0_mean'])\n",
    "                sats_obs = int(stats['satellites_observed'])\n",
    "                sats_exp = int(stats.get('satellites_expected', 10))\n",
    "                status = 'ok' if cn0_mean >= 40 else 'warn' if cn0_mean >= 30 else 'bad'\n",
    "                const_html += f'<tr><td>{sys_name}</td><td>{sats_obs}/{sats_exp}</td><td class=\"{status}\">{cn0_mean:.1f}</td></tr>'\n",
    "        \n",
    "        # Get anomalies\n",
    "        anomalies = result.get_anomalies() or []\n",
    "        anom_html = '<p style=\"color:green;\">‚úÖ No anomalies detected</p>'\n",
    "        if anomalies:\n",
    "            anom_html = ''.join([f'<div class=\"anomaly\"><b>{a.get(\"anomaly_type\",\"Unknown\")}</b> [{a.get(\"severity\",\"low\")}] - {a.get(\"start_time\",\"\")}</div>' for a in anomalies[:20]])\n",
    "        \n",
    "        html = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>CN0 Analysis Report - {result.filename}</title>\n",
    "    <style>\n",
    "        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 0; padding: 40px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; }}\n",
    "        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 40px; border-radius: 15px; box-shadow: 0 10px 40px rgba(0,0,0,0.3); }}\n",
    "        h1 {{ color: #1a365d; border-bottom: 3px solid #3182ce; padding-bottom: 15px; }}\n",
    "        h2 {{ color: #2c5282; margin-top: 35px; padding-left: 10px; border-left: 4px solid #3182ce; }}\n",
    "        .score-box {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 15px; text-align: center; margin: 25px 0; }}\n",
    "        .score-value {{ font-size: 64px; font-weight: bold; }}\n",
    "        .score-rating {{ font-size: 24px; opacity: 0.9; }}\n",
    "        .grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 20px 0; }}\n",
    "        .card {{ background: #f7fafc; padding: 20px; border-radius: 10px; border-left: 4px solid #3182ce; }}\n",
    "        .card-value {{ font-size: 24px; font-weight: bold; color: #2d3748; }}\n",
    "        .card-label {{ color: #718096; font-size: 13px; text-transform: uppercase; }}\n",
    "        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}\n",
    "        th {{ background: #3182ce; color: white; padding: 12px; }}\n",
    "        td {{ padding: 12px; border-bottom: 1px solid #e2e8f0; }}\n",
    "        .ok {{ color: #38a169; font-weight: bold; }}\n",
    "        .warn {{ color: #d69e2e; font-weight: bold; }}\n",
    "        .bad {{ color: #e53e3e; font-weight: bold; }}\n",
    "        .anomaly {{ background: #fff5f5; border-left: 4px solid #e53e3e; padding: 10px; margin: 5px 0; border-radius: 4px; }}\n",
    "        .graph {{ text-align: center; margin: 20px 0; }}\n",
    "        .footer {{ margin-top: 40px; padding-top: 20px; border-top: 2px solid #e2e8f0; color: #718096; font-size: 12px; text-align: center; }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "<div class=\"container\">\n",
    "    <h1>üì° GNSS CN0 Analysis Report</h1>\n",
    "    \n",
    "    <h2>üìÅ File Information</h2>\n",
    "    <div class=\"grid\">\n",
    "        <div class=\"card\"><div class=\"card-label\">Filename</div><div class=\"card-value\" style=\"font-size:14px;\">{result.filename}</div></div>\n",
    "        <div class=\"card\"><div class=\"card-label\">Duration</div><div class=\"card-value\">{result.duration_hours:.2f} h</div></div>\n",
    "        <div class=\"card\"><div class=\"card-label\">Epochs</div><div class=\"card-value\">{result.epoch_count:,}</div></div>\n",
    "    </div>\n",
    "    \n",
    "    <h2>üèÜ Quality Score</h2>\n",
    "    <div class=\"score-box\">\n",
    "        <div class=\"score-value\">{qs.overall:.0f}/100</div>\n",
    "        <div class=\"score-rating\">{qs.rating}</div>\n",
    "    </div>\n",
    "    <div class=\"grid\">\n",
    "        <div class=\"card\"><div class=\"card-label\">CN0 Quality</div><div class=\"card-value\">{qs.cn0_quality:.0f}</div></div>\n",
    "        <div class=\"card\"><div class=\"card-label\">Availability</div><div class=\"card-value\">{qs.availability:.0f}</div></div>\n",
    "        <div class=\"card\"><div class=\"card-label\">Continuity</div><div class=\"card-value\">{qs.continuity:.0f}</div></div>\n",
    "        <div class=\"card\"><div class=\"card-label\">Stability</div><div class=\"card-value\">{qs.stability:.0f}</div></div>\n",
    "        <div class=\"card\"><div class=\"card-label\">Diversity</div><div class=\"card-value\">{qs.diversity:.0f}</div></div>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"graph\">\n",
    "        <h3>Quality Radar</h3>\n",
    "        {embed_png('quality_radar.png')}\n",
    "    </div>\n",
    "    \n",
    "    <h2>üì∂ Signal Quality</h2>\n",
    "    <div class=\"grid\">\n",
    "        <div class=\"card\"><div class=\"card-label\">Average CN0</div><div class=\"card-value\">{result.avg_cn0:.1f} dB-Hz</div></div>\n",
    "        <div class=\"card\"><div class=\"card-label\">Std Dev</div><div class=\"card-value\">¬±{result.cn0_std_dev:.1f}</div></div>\n",
    "        <div class=\"card\"><div class=\"card-label\">Range</div><div class=\"card-value\">{result.min_cn0:.1f} - {result.max_cn0:.1f}</div></div>\n",
    "    </div>\n",
    "    <p><b>SNR Thresholds:</b> Excellent ‚â•45 | Good ‚â•35 | Marginal ‚â•25 | Poor &lt;25 dB-Hz</p>\n",
    "    \n",
    "    <div class=\"graph\">\n",
    "        <h3>CN0 Distribution by Constellation</h3>\n",
    "        {embed_png('cn0_boxplot.png')}\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"graph\">\n",
    "        <h3>Satellite Count (Observed vs Expected)</h3>\n",
    "        {embed_png('satellite_count.png')}\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"graph\">\n",
    "        <h3>CN0 Timeseries</h3>\n",
    "        {embed_png('cn0_timeseries.png')}\n",
    "    </div>\n",
    "    \n",
    "    <h2>üõ∞Ô∏è Constellation Summary</h2>\n",
    "    <table>\n",
    "        <tr><th>Constellation</th><th>Satellites (Obs/Exp)</th><th>CN0 Mean (dB-Hz)</th></tr>\n",
    "        {const_html}\n",
    "    </table>\n",
    "    \n",
    "    <h2>üõ°Ô∏è Threat Assessment</h2>\n",
    "    <div class=\"grid\">\n",
    "        <div class=\"card\"><div class=\"card-label\">Jamming</div><div class=\"card-value {'bad' if result.jamming_detected else 'ok'}\">{'üö® DETECTED' if result.jamming_detected else '‚úÖ Clear'}</div></div>\n",
    "        <div class=\"card\"><div class=\"card-label\">Spoofing</div><div class=\"card-value {'bad' if result.spoofing_detected else 'ok'}\">{'üö® DETECTED' if result.spoofing_detected else '‚úÖ Clear'}</div></div>\n",
    "        <div class=\"card\"><div class=\"card-label\">Interference</div><div class=\"card-value {'warn' if result.interference_detected else 'ok'}\">{'‚ö†Ô∏è Detected' if result.interference_detected else '‚úÖ Clear'}</div></div>\n",
    "    </div>\n",
    "    \n",
    "    <h2>‚ö†Ô∏è Anomalies ({len(anomalies)})</h2>\n",
    "    {anom_html}\n",
    "    \n",
    "    <div class=\"footer\">\n",
    "        <p><b>GeoVeil CN0 Analysis Widget v6</b></p>\n",
    "        <p>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "    </div>\n",
    "</div>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "        \n",
    "        # Save HTML\n",
    "        html_path = os.path.join(export_dir, 'report.html')\n",
    "        with open(html_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(html)\n",
    "        \n",
    "        print(f\"\\n‚úÖ HTML report saved: {html_path}\")\n",
    "        print(f\"\\nüì• Download files:\")\n",
    "        for f in sorted(os.listdir(export_dir)):\n",
    "            filepath = os.path.join(export_dir, f)\n",
    "            if os.path.isfile(filepath):  # Skip directories\n",
    "                display(FileLink(filepath))\n",
    "\n",
    "btn_report.on_click(download_report)\n",
    "print(\"‚úÖ Download Report handler ready\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Display Widget Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>üõ∞Ô∏è GeoVeil CN0 Analysis Widget v6</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>üìÇ Load RINEX Files</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b>Option A - Upload:</b></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf1390d37674e5fbc3e62bf7863ae8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FileUpload(value=(), accept='.obs,.rnx,.crx,.24o,.23o,.gz', description='OBS File'), FileUpload‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b>Option B - Path:</b></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca56bcc04da4040a6dfe8b9f3e6e6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='OBS Path:', layout=Layout(width='500px'), placeholder='Or enter path: /path/to/fil‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000da8508b23466aaeb3212890fc5a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='NAV Path:', layout=Layout(width='500px'), placeholder='Optional: /path/to/file.nav‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66167b1b5fa4b7eb5ed586127e1c6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Checkbox(value=True, description='Auto-download BRDC if missing', layout=Layout(width='250px'),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb261bf31ef549608e765b58ce25013f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>‚öôÔ∏è Analysis Settings</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696ae49ae79c494fa94a4c085dfdc3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Preset:', layout=Layout(width='250px'), options=('Full Analysis', 'Quick Overview', 'Int‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>üìä Output</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1031255e94a34a6c994f6894315d6547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='primary', description='üìä Summary', style=ButtonStyle(), tooltip='Quality s‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a2d19e4c8644bcb0f25b186d6dc562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úÖ Widget ready! (v6 - auto-export)\n",
      "\n",
      "üìã Instructions:\n",
      "   1. Load RINEX observation file (upload or path)\n",
      "   2. NAV file will auto-download if checkbox enabled\n",
      "   3. Select analysis preset\n",
      "   4. Click output buttons:\n",
      "      üìä Summary - Quality score, constellation overview\n",
      "      üó∫Ô∏è Heatmaps - Time vs Satellite + Az/El heatmaps\n",
      "      üìà SNR Graphs - Overall + per-constellation timeseries\n",
      "      üõ∞Ô∏è Skyplot - Satellite positions colored by CN0\n",
      "      ‚ö†Ô∏è Anomalies - Jamming/spoofing/interference events\n",
      "      üíæ Export - Log, CSV, JSON files\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# === DISPLAY INTERFACE ===\n",
    "display(HTML(\"<h2>üõ∞Ô∏è GeoVeil CN0 Analysis Widget v6</h2>\"))\n",
    "display(HTML(\"<hr>\"))\n",
    "\n",
    "display(HTML(\"<h4>üìÇ Load RINEX Files</h4>\"))\n",
    "display(HTML(\"<p><b>Option A - Upload:</b></p>\"))\n",
    "display(widgets.HBox([obs_upload, nav_upload]))\n",
    "display(HTML(\"<p><b>Option B - Path:</b></p>\"))\n",
    "display(obs_path)\n",
    "display(nav_path)\n",
    "display(widgets.HBox([auto_download_nav, load_btn]))\n",
    "display(status_out)\n",
    "\n",
    "display(HTML(\"<hr>\"))\n",
    "display(HTML(\"<h4>‚öôÔ∏è Analysis Settings</h4>\"))\n",
    "display(preset_dropdown)\n",
    "\n",
    "display(HTML(\"<hr>\"))\n",
    "display(HTML(\"<h4>üìä Output</h4>\"))\n",
    "display(widgets.HBox([btn_summary, btn_heatmap, btn_snr, btn_skyplot, btn_anomaly, btn_report]))\n",
    "display(HTML(\"<hr>\"))\n",
    "display(results_out)\n",
    "\n",
    "print(\"\")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úÖ Widget ready! (v6 - auto-export)\")\n",
    "print(\"\")\n",
    "print(\"üìã Instructions:\")\n",
    "print(\"   1. Load RINEX observation file (upload or path)\")\n",
    "print(\"   2. NAV file will auto-download if checkbox enabled\")\n",
    "print(\"   3. Select analysis preset\")\n",
    "print(\"   4. Click output buttons:\")\n",
    "print(\"      üìä Summary - Quality score, constellation overview\")\n",
    "print(\"      üó∫Ô∏è Heatmaps - Time vs Satellite + Az/El heatmaps\")\n",
    "print(\"      üìà SNR Graphs - Overall + per-constellation timeseries\")\n",
    "print(\"      üõ∞Ô∏è Skyplot - Satellite positions colored by CN0\")\n",
    "print(\"      ‚ö†Ô∏è Anomalies - Jamming/spoofing/interference events\")\n",
    "print(\"      üíæ Export - Log, CSV, JSON files\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
